<?xml version="1.0"?>
<doc>
    <assembly>
        "FFmpegInteropX"
    </assembly>
    <members>
        <member name="M:FFmpegInteropX.implementation.VideoStreamInfo.FramesPerSecondOverride(System.Double)">
            <summary>Override the frame rate of the video stream.</summary>
            <remarks>
This must be set before calling CreatePlaybackItem().
Setting this can cause A/V desync, since it will only affect this stream.
</remarks>
        </member>
        <member name="M:FFmpegInteropX.implementation.MediaSourceConfig.KeepMetadataOnMediaSourceClosed">
            <summary>Keep metadata available after MediaSource was closed.</summary>
            <remarks>Set this to false to cleanup more memory automatically, if you are sure you don't need metadata after playback end.</remarks>
        </member>
        <member name="M:FFmpegInteropX.implementation.MediaSourceConfig.AutoExtendDuration">
            <summary>Automatically extend the duration of the MediaStreamSource, if the file unexpectedly contains additional data.</summary>
        </member>
        <member name="M:FFmpegInteropX.implementation.MediaSourceConfig.DownmixAudioStreamsToStereo">
            <summary>Downmix multi-channel audio streams to stereo format.</summary>
        </member>
        <member name="M:FFmpegInteropX.implementation.MediaSourceConfig.FFmpegAudioFilters">
            <summary>Initial FFmpeg audio filters. Might be changed later through FFmpegMediaSource.SetFFmpegAudioFilters().</summary>
        </member>
        <member name="M:FFmpegInteropX.implementation.MediaSourceConfig.FFmpegVideoFilters">
            <summary>Initial FFmpeg video filters. Might be changed later through FFmpegMediaSource.SetFFmpegVideoFilters().</summary>
            <remarks>Using FFmpeg video filters will degrade playback performance, since they run on the CPU and not on the GPU.</remarks>
        </member>
        <member name="M:FFmpegInteropX.implementation.MediaSourceConfig.PreventModifiedSubtitleDurationOverlap">
            <summary>Try to prevent overlapping subtitles when extending durations.</summary>
        </member>
        <member name="M:FFmpegInteropX.implementation.MediaSourceConfig.AdditionalSubtitleDuration">
            <summary>Each subtitle's duration is extended by this amount. Default is 0.</summary>
        </member>
        <member name="M:FFmpegInteropX.implementation.MediaSourceConfig.MinimumSubtitleDuration">
            <summary>The minimum amount of time a subtitle should be shown. Default is 0.</summary>
        </member>
        <member name="M:FFmpegInteropX.implementation.MediaSourceConfig.AttachmentCacheFolderName">
            <summary>The folder where attachments such as fonts are stored (inside the app's temp folder).</summary>
        </member>
        <member name="M:FFmpegInteropX.implementation.MediaSourceConfig.UseEmbeddedSubtitleFonts">
            <summary>Use subtitle font files that are embedded in the media file.</summary>
        </member>
        <member name="M:FFmpegInteropX.implementation.MediaSourceConfig.DefaultExternalSubtitleStreamName">
            <summary>The default name to use for external subtitle streams.</summary>
        </member>
        <member name="M:FFmpegInteropX.implementation.MediaSourceConfig.DefaultSubtitleStreamName">
            <summary>The default name to use for subtitle streams.</summary>
        </member>
        <member name="M:FFmpegInteropX.implementation.MediaSourceConfig.DefaultAudioStreamName">
            <summary>The default name to use for audio streams.</summary>
        </member>
        <member name="M:FFmpegInteropX.implementation.MediaSourceConfig.FastSeekSmartStreamSwitching">
            <summary>Try to improve stream switching times when FastSeek is enabled.</summary>
        </member>
        <member name="M:FFmpegInteropX.implementation.MediaSourceConfig.FastSeekCleanAudio">
            <summary>Ensure that audio plays without artifacts after fast seeking.</summary>
            <remarks>This will slightly reduce the speed of fast seeking. Enabled by default.</remarks>
        </member>
        <member name="M:FFmpegInteropX.implementation.MediaSourceConfig.FastSeek">
            <summary>FFmpegMediaSource will seek to the closest video keyframe, if set to true.</summary>
            <remarks>
For FastSeek to work, you must use the MediaPlayer for playback, and assign
MediaPlayer.PlaybackSession to the FFmpegMediaSource.PlaybackSession property.
</remarks>
        </member>
        <member name="M:FFmpegInteropX.implementation.MediaSourceConfig.DefaultSubtitleDelay">
            <summary>The subtitle delay will be initially applied to all subtitle tracks.
Use SetSubtitleDelay() on the FFmpegMediaSource instance if you want to change the delay during playback.</summary>
        </member>
        <member name="M:FFmpegInteropX.implementation.MediaSourceConfig.ExternalSubtitleAnsiEncoding">
            <summary>
The character encoding to use if ANSI encoding is detected for external subtitle files.
</summary>
        </member>
        <member name="M:FFmpegInteropX.implementation.MediaSourceConfig.ExternalSubtitleEncoding">
            <summary>
The character encoding used for external subtitle files.

When null, auto detection is used. This is the default and recommended.
If ANSI encoding is auto detected, will use ExternalSubtitleAnsiEncoding.
</summary>
        </member>
        <member name="M:FFmpegInteropX.implementation.MediaSourceConfig.SubtitleStyle">
            <summary>Default style to use for subtitles.</summary>
        </member>
        <member name="M:FFmpegInteropX.implementation.MediaSourceConfig.SubtitleRegion">
            <summary>Default region to use for subtitles.</summary>
        </member>
        <member name="M:FFmpegInteropX.implementation.MediaSourceConfig.OverrideSubtitleStyles">
            <summary>Use SubtitleRegion and SubtitleStyle from config class, even if custom styles are defined for a subtitle.</summary>
        </member>
        <member name="M:FFmpegInteropX.implementation.MediaSourceConfig.AutoSelectForcedSubtitles">
            <summary>Automatically select subtitles when they have the 'forced' flag set.</summary>
        </member>
        <member name="M:FFmpegInteropX.implementation.MediaSourceConfig.ReadAheadBufferDuration">
            <summary>The maximum duration to buffer ahead per stream.</summary>
            <remarks>This value can be changed any time during playback.</remarks>
        </member>
        <member name="M:FFmpegInteropX.implementation.MediaSourceConfig.ReadAheadBufferSize">
            <summary>The maximum number of bytes to buffer ahead per stream.</summary>
            <remarks>This value can be changed any time during playback.</remarks>
        </member>
        <member name="M:FFmpegInteropX.implementation.MediaSourceConfig.ReadAheadBufferEnabled">
            <summary>Enables or disables the read-ahead buffer.</summary>
            <remarks>This value can be changed any time during playback.</remarks>
        </member>
        <member name="M:FFmpegInteropX.implementation.MediaSourceConfig.DefaultBufferTimeUri">
            <summary>The default BufferTime that gets assigned to the MediaStreamSource for URI sources.</summary>
            <remarks>Deprecated due to framework bugs and memory consumption. Use ReadAheadBufferSize and ReadAheadBufferDuration instead.</remarks>
        </member>
        <member name="M:FFmpegInteropX.implementation.MediaSourceConfig.DefaultBufferTime">
            <summary>The default BufferTime that gets assigned to the MediaStreamSource for Windows.Storage.Streams.IRandomAccessStream sources.</summary>
            <remarks>Deprecated due to framework bugs and memory consumption. Use ReadAheadBufferSize and ReadAheadBufferDuration instead.</remarks>
        </member>
        <member name="M:FFmpegInteropX.implementation.MediaSourceConfig.FFmpegOptions">
            <summary>Additional options to use when creating the ffmpeg AVFormatContext.</summary>
        </member>
        <member name="M:FFmpegInteropX.implementation.MediaSourceConfig.FileStreamReadSize">
            <summary>The maximum number of bytes to read in one chunk for Windows.Storage.Streams.IRandomAccessStream sources.</summary>
        </member>
        <member name="M:FFmpegInteropX.implementation.MediaSourceConfig.StreamBufferSize">
            <summary>The buffer size in bytes to use for Windows.Storage.Streams.IRandomAccessStream sources.</summary>
        </member>
        <member name="M:FFmpegInteropX.implementation.MediaSourceConfig.MaxSupportedPlaybackRate">
            <summary>The maximum supported playback rate. This is set on the media stream source itself. 
This does not modify what the transport control default UI shows as available playback speeds. Custom UI is necessary!</summary>
        </member>
        <member name="M:FFmpegInteropX.implementation.MediaSourceConfig.MaxAudioThreads">
            <summary>The maximum number of audio decoding threads. Setting to means using the number of logical CPU cores.</summary>
        </member>
        <member name="M:FFmpegInteropX.implementation.MediaSourceConfig.MaxVideoThreads">
            <summary>The maximum number of video decoding threads. Setting to means using the number of logical CPU cores.</summary>
        </member>
        <member name="M:FFmpegInteropX.implementation.MediaSourceConfig.SkipErrors">
            <summary>The maximum number of broken frames or packets to skip in a stream before stopping decoding.</summary>
        </member>
        <member name="M:FFmpegInteropX.implementation.MediaSourceConfig.VideoOutputAllowNv12">
            <summary>Allow video output in NV12 format.</summary>
        </member>
        <member name="M:FFmpegInteropX.implementation.MediaSourceConfig.VideoOutputAllowBgra8">
            <summary>Allow video output in BGRA format - required for video transparency.</summary>
        </member>
        <member name="M:FFmpegInteropX.implementation.MediaSourceConfig.VideoOutputAllow10bit">
            <summary>Allow video output in 10bit formats.</summary>
        </member>
        <member name="M:FFmpegInteropX.implementation.MediaSourceConfig.VideoOutputAllowIyuv">
            <summary>Allow video output in IYuv format.</summary>
        </member>
        <member name="M:FFmpegInteropX.implementation.MediaSourceConfig.SystemDecoderHEVCMaxLevel">
            <summary>Max level allowed for HEVC system decoder. Default: Disabled (-1).</summary>
            <remarks>Encoded as: 30*Major + 3*Minor. So Level 6.0 = 30*6 = 180, 5.1 = 30*5 + 3*1 = 163, 4.1 = 123.
Many HEVC HW decoders support even very high levels, so we disable the check by default.</remarks>
        </member>
        <member name="M:FFmpegInteropX.implementation.MediaSourceConfig.SystemDecoderHEVCMaxProfile">
            <summary>Max profile allowed for HEVC system decoder. Default: High10 Profile (2). See FF_PROFILE_HEVC_* values.</summary>
        </member>
        <member name="M:FFmpegInteropX.implementation.MediaSourceConfig.SystemDecoderH264MaxLevel">
            <summary>Max level allowed for H264 system decoder. Default: Level 4.1 (41). Use -1 to disable level check.</summary>
            <remarks>Most H264 HW decoders only support Level 4.1, so this is the default.</remarks>
        </member>
        <member name="M:FFmpegInteropX.implementation.MediaSourceConfig.SystemDecoderH264MaxProfile">
            <summary>Max profile allowed for H264 system decoder. Default: High Profile (100). See FF_PROFILE_H264_* values.</summary>
        </member>
        <member name="M:FFmpegInteropX.implementation.MediaSourceConfig.HdrSupport">
            <summary>Sets the HDR color support mode. Default is Automatic.</summary>
        </member>
        <member name="M:FFmpegInteropX.implementation.MediaSourceConfig.VideoDecoderMode">
            <summary>Sets the video decoder mode. Default is Automatic.</summary>
        </member>
        <member name="M:FFmpegInteropX.implementation.MediaSourceConfig.PassthroughAudioAAC">
            <summary>Enable passthrough for AAC audio to system decoder.</summary>
            <remarks>This could allow hardware decoding on some platforms (e.g. Windows Phone).</remarks>
        </member>
        <member name="M:FFmpegInteropX.implementation.MediaSourceConfig.PassthroughAudioMP3">
            <summary>Enable passthrough for MP3 audio to system decoder.</summary>
            <remarks>This could allow hardware decoding on some platforms (e.g. Windows Phone).</remarks>
        </member>
        <member name="M:av_write_image_line2(System.Void,System.Byte**,System.Int32,AVPixFmtDescriptor,System.Int32,System.Int32,System.Int32,System.Int32,System.Int32)">
 Write the values from src to the pixel format component c of an
 image line.

 @param src array containing the values to write
 @param data the array containing the pointers to the planes of the
 image to write into. It is supposed to be zeroed.
 @param linesize the array containing the linesizes of the image
 @param desc the pixel format descriptor for the image
 @param x the horizontal coordinate of the first pixel to write
 @param y the vertical coordinate of the first pixel to write
 @param w the width of the line to write, that is the number of
 values to write to the image line
 @param src_element_size size of elements in src array (2 or 4 byte)

</member>
        <member name="M:av_read_image_line2(System.Void*,System.Byte*,System.Int32,AVPixFmtDescriptor,System.Int32,System.Int32,System.Int32,System.Int32,System.Int32,System.Int32)">
 Read a line from an image, and write the values of the
 pixel format component c to dst.

 @param data the array containing the pointers to the planes of the image
 @param linesize the array containing the linesizes of the image
 @param desc the pixel format descriptor for the image
 @param x the horizontal coordinate of the first pixel to read
 @param y the vertical coordinate of the first pixel to read
 @param w the width of the line to read, that is the number of
 values to write to dst
 @param read_pal_component if not zero and the format is a paletted
 format writes the values corresponding to the palette
 component c in data[1] to dst, rather than the palette indexes in
 data[0]. The behavior is undefined if the format is not paletted.
 @param dst_element_size size of elements in dst array (2 or 4 byte)

</member>
        <member name="M:av_chroma_location_from_name(System.SByte!System.Runtime.CompilerServices.IsSignUnspecifiedByte)">
@return the AVChromaLocation value for name or an AVError if not found.

</member>
        <member name="M:av_color_space_from_name(System.SByte!System.Runtime.CompilerServices.IsSignUnspecifiedByte)">
@return the AVColorSpace value for name or an AVError if not found.

</member>
        <member name="M:av_color_transfer_from_name(System.SByte!System.Runtime.CompilerServices.IsSignUnspecifiedByte)">
@return the AVColorTransferCharacteristic value for name or an AVError if not found.

</member>
        <member name="M:av_color_primaries_from_name(System.SByte!System.Runtime.CompilerServices.IsSignUnspecifiedByte)">
@return the AVColorPrimaries value for name or an AVError if not found.

</member>
        <member name="M:av_color_range_from_name(System.SByte!System.Runtime.CompilerServices.IsSignUnspecifiedByte)">
@return the AVColorRange value for name or an AVError if not found.

</member>
        <member name="M:av_pix_fmt_desc_next(AVPixFmtDescriptor)">
 Iterate over all pixel format descriptors known to libavutil.

 @param prev previous descriptor. NULL to get the first descriptor.

 @return next descriptor or NULL after the last descriptor

</member>
        <member name="M:av_get_padded_bits_per_pixel(AVPixFmtDescriptor)">
Return the number of bits per pixel for the pixel format
described by pixdesc, including any padding or unused bits.

</member>
        <member name="M:av_get_bits_per_pixel(AVPixFmtDescriptor)">
Pixel format is big-endian.

Pixel format has a palette in data[1], values are indexes in this palette.

All values of a component are bit-wise packed end to end.

Pixel format is an HW accelerated format.

At least one pixel component is not in the first data plane.

The pixel format contains RGB-like data (as opposed to YUV/grayscale).

 The pixel format has an alpha channel. This is set on all formats that
 support alpha in some way, including AV_PIX_FMT_PAL8. The alpha is always
 straight, never pre-multiplied.

 If a codec or a filter does not support alpha, it should set all alpha to
 opaque, or use the equivalent pixel formats without alpha component, e.g.
 AV_PIX_FMT_RGB0 (or AV_PIX_FMT_RGB24 etc.) instead of AV_PIX_FMT_RGBA.

The pixel format is following a Bayer pattern

The pixel format contains IEEE-754 floating point values. Precision (double,
single, or half) should be determined by the pixel size (64, 32, or 16 bits).

 Return the number of bits per pixel used by the pixel format
 described by pixdesc. Note that this is not the same as the number
 of bits per sample.

 The returned number of bits refers to the number of bits actually
 used for storing the pixel information, that is padding bits are
 not counted.

</member>
        <member name="F:AVPixFmtDescriptor.alias">
Alternative comma-separated names.

</member>
        <member name="F:AVPixFmtDescriptor.comp">
 Parameters that describe how pixels are packed.
 If the format has 1 or 2 components, then luma is 0.
 If the format has 3 or 4 components:
   if the RGB flag is set then 0 is red, 1 is green and 2 is blue;
   otherwise 0 is luma, 1 is chroma-U and 2 is chroma-V.

 If present, the Alpha channel is always the last component.

</member>
        <member name="F:AVPixFmtDescriptor.flags">
Combination of AV_PIX_FMT_FLAG_... flags.

</member>
        <member name="F:AVPixFmtDescriptor.log2_chroma_h">
Amount to shift the luma height right to find the chroma height.
For YV12 this is 1 for example.
chroma_height= AV_CEIL_RSHIFT(luma_height, log2_chroma_h)
The note above is needed to ensure rounding up.
This value only refers to the chroma components.

</member>
        <member name="F:AVPixFmtDescriptor.log2_chroma_w">
Amount to shift the luma width right to find the chroma width.
For YV12 this is 1 for example.
chroma_width = AV_CEIL_RSHIFT(luma_width, log2_chroma_w)
The note above is needed to ensure rounding up.
This value only refers to the chroma components.

</member>
        <member name="T:AVPixFmtDescriptor">
 Descriptor that unambiguously describes how the bits of a pixel are
 stored in the up to 4 data planes of an image. It also stores the
 subsampling factors and number of components.

 @note This is separate of the colorspace (RGB, YCbCr, YPbPr, JPEG-style YUV
       and all the YUV variants) AVPixFmtDescriptor just stores how values
       are stored not what these values represent.

</member>
        <member name="F:AVComponentDescriptor.depth">
Number of bits in the component.

</member>
        <member name="F:AVComponentDescriptor.shift">
Number of least significant bits that must be shifted away
to get the value.

</member>
        <member name="F:AVComponentDescriptor.offset">
Number of elements before the component of the first pixel.
Elements are bits for bitstream formats, bytes otherwise.

</member>
        <member name="F:AVComponentDescriptor.step">
Number of elements between 2 horizontally consecutive pixels.
Elements are bits for bitstream formats, bytes otherwise.

</member>
        <member name="F:AVComponentDescriptor.plane">
Which of the 4 planes contains the component.

</member>
        <member name="T:SwrDitherType">
@file
Libswresample version macros

@file
Libswresample version macros

</member>
        <member name="M:swscale_version">
@file
swscale version macros

FF_API_* defines may be placed below to indicate public API that will be
dropped at a future version bump. The defines themselves are not part of
the public API and may change, break or disappear at any time.

@file
swscale version macros

</member>
        <member name="T:AVFormatContext">
@file
@ingroup libavf
Libavformat version macros

</member>
        <member name="M:avio_accept(AVIOContext*,AVIOContext**)">
Accept and allocate a client context on a server context.
@param  s the server context
@param  c the client context, must be unallocated
@return   &gt;= 0 on success or a negative value corresponding
          to an AVERROR on failure

</member>
        <member name="M:avio_seek_time(AVIOContext*,System.Int32,System.Int64,System.Int32)">
 Seek to a given timestamp relative to some component stream.
 Only meaningful if using a network streaming protocol (e.g. MMS.).

 @param h IO context from which to call the seek function pointers
 @param stream_index The stream index that the timestamp is relative to.
        If stream_index is (-1) the timestamp should be in AV_TIME_BASE
        units from the beginning of the presentation.
        If a stream_index &gt;= 0 is used and the protocol does not support
        seeking based on component streams, the call will fail.
 @param timestamp timestamp in AVStream.time_base units
        or if there is no stream specified then in AV_TIME_BASE units.
 @param flags Optional combination of AVSEEK_FLAG_BACKWARD, AVSEEK_FLAG_BYTE
        and AVSEEK_FLAG_ANY. The protocol may silently ignore
        AVSEEK_FLAG_BACKWARD and AVSEEK_FLAG_ANY, but AVSEEK_FLAG_BYTE will
        fail if used and not supported.
 @return &gt;= 0 on success
 @see AVInputFormat::read_seek

</member>
        <member name="M:avio_pause(AVIOContext*,System.Int32)">
 Pause and resume playing - only meaningful if using a network streaming
 protocol (e.g. MMS).

 @param h     IO context from which to call the read_pause function pointer
 @param pause 1 for pause, 0 for resume

</member>
        <member name="M:avio_protocol_get_class(System.SByte!System.Runtime.CompilerServices.IsSignUnspecifiedByte)">
 Get AVClass by names of available protocols.

 @return A AVClass of input protocol name or NULL

</member>
        <member name="M:avio_enum_protocols(System.Void**,System.Int32)">
 Iterate through names of available protocols.

 @param opaque A private pointer representing current protocol.
        It must be a pointer to NULL on first iteration and will
        be updated by successive calls to avio_enum_protocols.
 @param output If set to 1, iterate over output protocols,
               otherwise over input protocols.

 @return A static string containing the name of current protocol or NULL

</member>
        <member name="M:avio_close_dyn_buf(AVIOContext*,System.Byte**)">
 Return the written size and a pointer to the buffer. The buffer
 must be freed with av_free().
 Padding of AV_INPUT_BUFFER_PADDING_SIZE is added to the buffer.

 @param s IO context
 @param pbuffer pointer to a byte buffer
 @return the length of the byte buffer

</member>
        <member name="M:avio_get_dyn_buf(AVIOContext*,System.Byte**)">
 Return the written size and a pointer to the buffer.
 The AVIOContext stream is left intact.
 The buffer must NOT be freed.
 No padding is added to the buffer.

 @param s IO context
 @param pbuffer pointer to a byte buffer
 @return the length of the byte buffer

</member>
        <member name="M:avio_open_dyn_buf(AVIOContext**)">
 Open a write only memory stream.

 @param s new IO context
 @return zero if no error.

</member>
        <member name="M:avio_open2(AVIOContext**,System.SByte!System.Runtime.CompilerServices.IsSignUnspecifiedByte,System.Int32,AVIOInterruptCB,AVDictionary**)">
 Create and initialize a AVIOContext for accessing the
 resource indicated by url.
 @note When the resource indicated by url has been opened in
 read+write mode, the AVIOContext can be used only for writing.

 @param s Used to return the pointer to the created AVIOContext.
 In case of failure the pointed to value is set to NULL.
 @param url resource to access
 @param flags flags which control how the resource indicated by url
 is to be opened
 @param int_cb an interrupt callback to be used at the protocols level
 @param options  A dictionary filled with protocol-private options. On return
 this parameter will be destroyed and replaced with a dict containing options
 that were not found. May be NULL.
 @return &gt;= 0 in case of success, a negative value corresponding to an
 AVERROR code in case of failure

</member>
        <member name="M:avio_open(AVIOContext**,System.SByte!System.Runtime.CompilerServices.IsSignUnspecifiedByte,System.Int32)">
@name URL open modes
The flags argument to avio_open must be one of the following
constants, optionally ORed with other flags.
@{

@}

Use non-blocking mode.
If this flag is set, operations on the context will return
AVERROR(EAGAIN) if they can not be performed immediately.
If this flag is not set, operations on the context will never return
AVERROR(EAGAIN).
Note that this flag does not affect the opening/connecting of the
context. Connecting a protocol will always block if necessary (e.g. on
network protocols) but never hang (e.g. on busy devices).
Warning: non-blocking protocols is work-in-progress; this flag may be
silently ignored.

Use direct mode.
avio_read and avio_write should if possible be satisfied directly
instead of going through a buffer, and avio_seek will always
call the underlying seek function directly.

 Create and initialize a AVIOContext for accessing the
 resource indicated by url.
 @note When the resource indicated by url has been opened in
 read+write mode, the AVIOContext can be used only for writing.

 @param s Used to return the pointer to the created AVIOContext.
 In case of failure the pointed to value is set to NULL.
 @param url resource to access
 @param flags flags which control how the resource indicated by url
 is to be opened
 @return &gt;= 0 in case of success, a negative value corresponding to an
 AVERROR code in case of failure

</member>
        <member name="M:avio_r8(AVIOContext*)">
 @name Functions for reading from AVIOContext
 @{

 @note return 0 if EOF, so you cannot use it if EOF handling is
       necessary

</member>
        <member name="M:avio_read_partial(AVIOContext*,System.Byte*,System.Int32)">
Read size bytes from AVIOContext into buf. Unlike avio_read(), this is allowed
to read fewer bytes than requested. The missing bytes can be read in the next
call. This always tries to read at least 1 byte.
Useful to reduce latency in certain cases.
@return number of bytes read or AVERROR

</member>
        <member name="M:avio_read(AVIOContext*,System.Byte*,System.Int32)">
Read size bytes from AVIOContext into buf.
@return number of bytes read or AVERROR

</member>
        <member name="M:avio_flush(AVIOContext*)">
Write strings (const char *) to the context.
This is a convenience macro around avio_print_string_array and it
automatically creates the string array from the variable argument list.
For simple string concatenations this function is more performant than using
avio_printf since it does not need a temporary buffer.

 Force flushing of buffered data.

 For write streams, force the buffered data to be immediately written to the output,
 without to wait to fill the internal buffer.

 For read streams, discard all currently buffered data, and advance the
 reported file position to that of the underlying stream. This does not
 read new data, and does not perform any seeks.

</member>
        <member name="M:avio_print_string_array(AVIOContext*,System.SByte!System.Runtime.CompilerServices.IsSignUnspecifiedByte*)">
Write a NULL terminated array of strings to the context.
Usually you don't need to use this function directly but its macro wrapper,
avio_print.

</member>
        <member name="M:avio_feof(AVIOContext*)">
Similar to feof() but also returns nonzero on read errors.
@return non zero if and only if at end of file or a read error happened when reading.

</member>
        <member name="M:avio_size(AVIOContext*)">
Get the filesize.
@return filesize or AVERROR

</member>
        <member name="M:avio_tell(AVIOContext*)">
ftell() equivalent for AVIOContext.
@return position or AVERROR.

</member>
        <member name="M:avio_skip(AVIOContext*,System.Int64)">
Skip given number of bytes forward
@return new position or AVERROR.

</member>
        <member name="M:avio_put_str16be(AVIOContext*,System.SByte!System.Runtime.CompilerServices.IsSignUnspecifiedByte)">
 Convert an UTF-8 string to UTF-16BE and write it.
 @param s the AVIOContext
 @param str NULL-terminated UTF-8 string

 @return number of bytes written.

</member>
        <member name="M:avio_put_str16le(AVIOContext*,System.SByte!System.Runtime.CompilerServices.IsSignUnspecifiedByte)">
 Convert an UTF-8 string to UTF-16LE and write it.
 @param s the AVIOContext
 @param str NULL-terminated UTF-8 string

 @return number of bytes written.

</member>
        <member name="M:avio_put_str(AVIOContext*,System.SByte!System.Runtime.CompilerServices.IsSignUnspecifiedByte)">
Write a NULL-terminated string.
@return number of bytes written.

</member>
        <member name="M:avio_context_free(AVIOContext**)">
 Free the supplied IO context and everything associated with it.

 @param s Double pointer to the IO context. This function will write NULL
 into s.

</member>
        <member name="M:avio_alloc_context(System.Byte*,System.Int32,System.Int32,System.Void*,=FUNC:System.Int32(System.Void*,System.Byte*,System.Int32),=FUNC:System.Int32(System.Void*,System.Byte*,System.Int32),=FUNC:System.Int64(System.Void*,System.Int64,System.Int32))">
 Allocate and initialize an AVIOContext for buffered I/O. It must be later
 freed with avio_context_free().

 @param buffer Memory block for input/output operations via AVIOContext.
        The buffer must be allocated with av_malloc() and friends.
        It may be freed and replaced with a new buffer by libavformat.
        AVIOContext.buffer holds the buffer currently in use,
        which must be later freed with av_free().
 @param buffer_size The buffer size is very important for performance.
        For protocols with fixed blocksize it should be set to this blocksize.
        For others a typical size is a cache page, e.g. 4kb.
 @param write_flag Set to 1 if the buffer should be writable, 0 otherwise.
 @param opaque An opaque pointer to user-specific data.
 @param read_packet  A function for refilling the buffer, may be NULL.
                     For stream protocols, must never return 0 but rather
                     a proper AVERROR code.
 @param write_packet A function for writing the buffer contents, may be NULL.
        The function may not change the input buffers content.
 @param seek A function for seeking to specified byte position, may be NULL.

 @return Allocated AVIOContext or NULL on failure.

</member>
        <member name="M:avio_free_directory_entry(AVIODirEntry**)">
 Free entry allocated by avio_read_dir().

 @param entry entry to be freed.

</member>
        <member name="M:avio_close_dir(AVIODirContext**)">
 Close directory.

 @note Entries created using avio_read_dir() are not deleted and must be
 freeded with avio_free_directory_entry().

 @param s         directory read context.
 @return &gt;=0 on success or negative on error.

</member>
        <member name="M:avio_read_dir(AVIODirContext*,AVIODirEntry**)">
 Get next directory entry.

 Returned entry must be freed with avio_free_directory_entry(). In particular
 it may outlive AVIODirContext.

 @param s         directory read context.
 @param[out] next next entry or NULL when no more entries.
 @return &gt;=0 on success or negative on error. End of list is not considered an
             error.

</member>
        <member name="M:avio_open_dir(AVIODirContext**,System.SByte!System.Runtime.CompilerServices.IsSignUnspecifiedByte,AVDictionary**)">
 Open directory for reading.

 @param s       directory read context. Pointer to a NULL pointer must be passed.
 @param url     directory to be listed.
 @param options A dictionary filled with protocol-private options. On return
                this parameter will be destroyed and replaced with a dictionary
                containing options that were not found. May be NULL.
 @return &gt;=0 on success or negative on error.

</member>
        <member name="M:avio_check(System.SByte!System.Runtime.CompilerServices.IsSignUnspecifiedByte,System.Int32)">
 Return AVIO_FLAG_* access flags corresponding to the access permissions
 of the resource in url, or a negative value corresponding to an
 AVERROR code in case of failure. The returned access flags are
 masked by the value in flags.

 @note This function is intrinsically unsafe, in the sense that the
 checked resource may change its existence or permission status from
 one call to another. Thus you should not trust the returned value,
 unless you are sure that no other processes are accessing the
 checked resource.

</member>
        <member name="M:avio_find_protocol_name(System.SByte!System.Runtime.CompilerServices.IsSignUnspecifiedByte)">
 Return the name of the protocol that will handle the passed URL.

 NULL is returned if no protocol could be found for the given URL.

 @return Name of the protocol or NULL.

</member>
        <member name="F:AVIOContext.bytes_written">
Read-only statistic of bytes written for this AVIOContext.

</member>
        <member name="F:AVIOContext.bytes_read">
Read-only statistic of bytes read for this AVIOContext.

</member>
        <member name="F:AVIOContext.buf_ptr_max">
Maximum reached position before a backward seek in the write buffer,
used keeping track of already written data for a later flush.

</member>
        <member name="F:AVIOContext.written">
@deprecated field utilized privately by libavformat. For a public
            statistic of how many bytes were written out, see
            AVIOContext::bytes_written.

</member>
        <member name="F:AVIOContext.ignore_boundary_point">
If set, don't call write_data_type separately for AVIO_DATA_MARKER_BOUNDARY_POINT,
but ignore them and treat them as AVIO_DATA_MARKER_UNKNOWN (to avoid needlessly
small chunks of data returned from the callback).

</member>
        <member name="F:AVIOContext.protocol_blacklist">
',' separated list of disallowed protocols.

</member>
        <member name="F:AVIOContext.protocol_whitelist">
',' separated list of allowed protocols.

</member>
        <member name="F:AVIOContext.direct">
avio_read and avio_write should if possible be satisfied directly
instead of going through a buffer, and avio_seek will always
call the underlying seek function directly.

</member>
        <member name="F:AVIOContext.seekable">
A combination of AVIO_SEEKABLE_ flags or 0 when the stream is not seekable.

</member>
        <member name="F:AVIOContext.read_seek">
Seek to a given timestamp in stream with the specified stream_index.
Needed for some network streaming protocols which don't support seeking
to byte position.

</member>
        <member name="F:AVIOContext.read_pause">
Pause or resume playback for network streaming protocols - e.g. MMS.

</member>
        <member name="F:AVIOContext.av_class">
 A class for private options.

 If this AVIOContext is created by avio_open2(), av_class is set and
 passes the options down to protocols.

 If this AVIOContext is manually allocated, then av_class may be set by
 the caller.

 warning -- this field can be NULL, be sure to not pass this AVIOContext
 to any av_opt_* functions in that case.

</member>
        <member name="T:AVIOContext">
 Bytestream IO Context.
 New public fields can be added with minor version bumps.
 Removal, reordering and changes to existing public fields require
 a major version bump.
 sizeof(AVIOContext) must not be used outside libav*.

 @note None of the function pointers in AVIOContext should be called
       directly, they should only be set by the client application
       when implementing custom I/O. Normally these are set to the
       function pointers specified in avio_alloc_context()

</member>
        <member name="T:AVIODataMarkerType">
Different data types that can be returned via the AVIO
write_data_type callback.


A callback that is used instead of write_packet.


 Mark the written bytestream as a specific type.

 Zero-length ranges are omitted from the output.

 @param time the stream time the current bytestream pos corresponds to
             (in AV_TIME_BASE units), or AV_NOPTS_VALUE if unknown or not
             applicable
 @param type the kind of data written starting at the current pos

</member>
        <member name="F:AVIO_DATA_MARKER_FLUSH_POINT">
A point in the output bytestream where the underlying AVIOContext might
flush the buffer depending on latency or buffering requirements. Typically
means the end of a packet.

</member>
        <member name="F:AVIO_DATA_MARKER_TRAILER">
Trailer data, which doesn't contain actual content, but only for
finalizing the output file.

</member>
        <member name="F:AVIO_DATA_MARKER_UNKNOWN">
This is any, unlabelled data. It can either be a muxer not marking
any positions at all, it can be an actual boundary/sync point
that the muxer chooses not to mark, or a later part of a packet/fragment
that is cut into multiple write callbacks due to limited IO buffer size.

</member>
        <member name="F:AVIO_DATA_MARKER_BOUNDARY_POINT">
A point in the output bytestream where a demuxer can start parsing
(for non self synchronizing bytestream formats). That is, any
non-keyframe packet start point.

</member>
        <member name="F:AVIO_DATA_MARKER_SYNC_POINT">
A point in the output bytestream where a decoder can start decoding
(i.e. a keyframe). A demuxer/decoder given the data flagged with
AVIO_DATA_MARKER_HEADER, followed by any AVIO_DATA_MARKER_SYNC_POINT,
should give decodeable results.

</member>
        <member name="F:AVIO_DATA_MARKER_HEADER">
Header data; this needs to be present for the stream to be decodeable.

</member>
        <member name="T:AVIODirEntry">
 Describes single entry of the directory.

 Only name and type fields are guaranteed be set.
 Rest of fields are protocol or/and platform dependent and might be unknown.

</member>
        <member name="T:AVIODirEntryType">
Directory entry types.

</member>
        <member name="T:AVIOInterruptCB">
@file
@ingroup lavf_io
Buffered I/O operations

@file
@ingroup libavf
Libavformat version macros

 FF_API_* defines may be placed below to indicate public API that will be
 dropped at a future version bump. The defines themselves are not part of
 the public API and may change, break or disappear at any time.

 @note, when bumping the major version it is recommended to manually
 disable each FF_API_* in its own commit instead of disabling them all
 at once through the bump. This improves the git bisect-ability of the change.


Seeking works like for a local file.

Seeking by timestamp with avio_seek_time() is possible.

 Callback for checking whether to abort blocking functions.
 AVERROR_EXIT is returned in this case by the interrupted
 function. During blocking operations, callback is called with
 opaque as parameter. If the callback returns 1, the
 blocking operation will be aborted.

 No members can be added to this struct without a major bump, if
 new elements have been added after this struct in AVFormatContext
 or AVIOContext.

</member>
        <member name="T:RcOverride">
@}

@file
@ingroup libavc
Libavcodec version macros.

</member>
        <member name="M:av_packet_rescale_ts(AVPacket*,AVRational,AVRational)">
 Convert valid timing fields (timestamps / durations) in a packet from one
 timebase to another. Timestamps with unknown values (AV_NOPTS_VALUE) will be
 ignored.

 @param pkt packet on which the conversion will be performed
 @param tb_src source timebase, in which the timing fields in pkt are
               expressed
 @param tb_dst destination timebase, to which the timing fields will be
               converted

</member>
        <member name="M:av_packet_make_writable(AVPacket*)">
 Create a writable reference for the data described by a given packet,
 avoiding data copy if possible.

 @param pkt Packet whose data should be made writable.

 @return 0 on success, a negative AVERROR on failure. On failure, the
         packet is unchanged.

</member>
        <member name="M:av_packet_make_refcounted(AVPacket*)">
 Ensure the data described by a given packet is reference counted.

 @note This function does not ensure that the reference will be writable.
       Use av_packet_make_writable instead for that purpose.

 @see av_packet_ref
 @see av_packet_make_writable

 @param pkt packet whose data should be made reference counted.

 @return 0 on success, a negative AVERROR on error. On failure, the
         packet is unchanged.

</member>
        <member name="M:av_packet_copy_props(AVPacket*,AVPacket)">
 Copy only "properties" fields from src to dst.

 Properties for the purpose of this function are all the fields
 beside those related to the packet data (buf, data, size)

 @param dst Destination packet
 @param src Source packet

 @return 0 on success AVERROR on failure.

</member>
        <member name="M:av_packet_move_ref(AVPacket*,AVPacket*)">
 Move every field in src to dst and reset src.

 @see av_packet_unref

 @param src Source packet, will be reset
 @param dst Destination packet

</member>
        <member name="M:av_packet_unref(AVPacket*)">
 Wipe the packet.

 Unreference the buffer referenced by the packet and reset the
 remaining packet fields to their default values.

 @param pkt The packet to be unreferenced.

</member>
        <member name="M:av_packet_ref(AVPacket*,AVPacket)">
 Setup a new reference to the data described by a given packet

 If src is reference-counted, setup dst as a new reference to the
 buffer in src. Otherwise allocate a new buffer in dst and copy the
 data from src into it.

 All the other fields are copied from src.

 @see av_packet_unref

 @param dst Destination packet. Will be completely overwritten.
 @param src Source packet

 @return 0 on success, a negative AVERROR on error. On error, dst
         will be blank (as if returned by av_packet_alloc()).

</member>
        <member name="M:av_packet_free_side_data(AVPacket*)">
 Convenience function to free all the side data stored.
 All the other fields stay untouched.

 @param pkt packet

</member>
        <member name="M:av_packet_pack_dictionary(AVDictionary*,System.UInt64*)">
 Pack a dictionary for use in side_data.

 @param dict The dictionary to pack.
 @param size pointer to store the size of the returned data
 @return pointer to data if successful, NULL otherwise

</member>
        <member name="M:av_packet_from_data(AVPacket*,System.Byte*,System.Int32)">
 Initialize a reference-counted packet from av_malloc()ed data.

 @param pkt packet to be initialized. This function will set the data, size,
        and buf fields, all others are left untouched.
 @param data Data allocated by av_malloc() to be used as packet data. If this
        function returns successfully, the data is owned by the underlying AVBuffer.
        The caller may not access the data through other means.
 @param size size of data in bytes, without the padding. I.e. the full buffer
        size is assumed to be size + AV_INPUT_BUFFER_PADDING_SIZE.

 @return 0 on success, a negative AVERROR on error

</member>
        <member name="M:av_grow_packet(AVPacket*,System.Int32)">
 Increase packet size, correctly zeroing padding

 @param pkt packet
 @param grow_by number of bytes by which to increase the size of the packet

</member>
        <member name="M:av_shrink_packet(AVPacket*,System.Int32)">
 Reduce packet size, correctly zeroing padding

 @param pkt packet
 @param size new size

</member>
        <member name="M:av_new_packet(AVPacket*,System.Int32)">
 Allocate the payload of a packet and initialize its fields with
 default values.

 @param pkt packet
 @param size wanted payload size
 @return 0 if OK, AVERROR_xxx otherwise

</member>
        <member name="M:av_init_packet(AVPacket*)">
 * Initialize optional fields of a packet with default values.
 *
 * Note, this does not touch the data and size members, which have to be
 * initialized separately.
 *
 * @param pkt packet
 *
 * @see av_packet_alloc
 * @see av_packet_unref
 *
 * @deprecated This function is deprecated. Once it's removed,
               sizeof(AVPacket) will not be a part of the ABI anymore.

</member>
        <member name="M:av_packet_free(AVPacket**)">
 Free the packet, if the packet is reference counted, it will be
 unreferenced first.

 @param pkt packet to be freed. The pointer will be set to NULL.
 @note passing NULL is a no-op.

</member>
        <member name="M:av_packet_clone(AVPacket)">
 Create a new packet that references the same data as src.

 This is a shortcut for av_packet_alloc()+av_packet_ref().

 @return newly created AVPacket on success, NULL on error.

 @see av_packet_alloc
 @see av_packet_ref

</member>
        <member name="M:av_packet_alloc">
 Allocate an AVPacket and set its fields to default values.  The resulting
 struct must be freed using av_packet_free().

 @return An AVPacket filled with default values or NULL on failure.

 @note this only allocates the AVPacket itself, not the data buffers. Those
 must be allocated through other means such as av_new_packet.

 @see av_new_packet

</member>
        <member name="T:AVSideDataParamChangeFlags">
 Flag is used to discard packets which are required to maintain valid
 decoder state but are not required for output and should be dropped
 after decoding.

 The packet comes from a trusted source.

 Otherwise-unsafe constructs such as arbitrary pointers to data
 outside the packet may be followed.

Flag is used to indicate packets that contain frames that can
be discarded by the decoder.  I.e. Non-reference frames.

</member>
        <member name="F:AV_SIDE_DATA_PARAM_CHANGE_CHANNEL_COUNT">
@deprecated those are not used by any decoder

</member>
        <member name="F:AVPacket.time_base">
Time base of the packet's timestamps.
In the future, this field may be set on packets output by encoders or
demuxers, but its value will be by default ignored on input to decoders
or muxers.

</member>
        <member name="F:AVPacket.opaque_ref">
 AVBufferRef for free use by the API user. FFmpeg will never check the
 contents of the buffer ref. FFmpeg calls av_buffer_unref() on it when
 the packet is unreferenced. av_packet_copy_props() calls create a new
 reference with av_buffer_ref() for the target packet's opaque_ref field.

 This is unrelated to the opaque field, although it serves a similar
 purpose.

</member>
        <member name="F:AVPacket.opaque">
for some private data of the user

</member>
        <member name="F:AVPacket.duration">
Duration of this packet in AVStream-&gt;time_base units, 0 if unknown.
Equals next_pts - this_pts in presentation order.

</member>
        <member name="F:AVPacket.side_data">
Additional packet data that can be provided by the container.
Packet can contain several types of side information.

</member>
        <member name="F:AVPacket.flags">
A combination of AV_PKT_FLAG values

</member>
        <member name="F:AVPacket.dts">
Decompression timestamp in AVStream-&gt;time_base units; the time at which
the packet is decompressed.
Can be AV_NOPTS_VALUE if it is not stored in the file.

</member>
        <member name="F:AVPacket.pts">
Presentation timestamp in AVStream-&gt;time_base units; the time at which
the decompressed packet will be presented to the user.
Can be AV_NOPTS_VALUE if it is not stored in the file.
pts MUST be larger or equal to dts as presentation cannot happen before
decompression, unless one wants to view hex dumps. Some formats misuse
the terms dts and pts/cts to mean something different. Such timestamps
must be converted to true pts/dts before they are stored in AVPacket.

</member>
        <member name="F:AVPacket.buf">
A reference to the reference-counted buffer where the packet data is
stored.
May be NULL, then the packet data is not reference-counted.

</member>
        <member name="T:AVPacket">
 This structure stores compressed data. It is typically exported by demuxers
 and then passed as input to decoders, or received as output from encoders and
 then passed to muxers.

 For video, it should typically contain one compressed frame. For audio it may
 contain several compressed frames. Encoders are allowed to output empty
 packets, with no compressed data, containing only side data
 (e.g. to update some stream parameters at the end of encoding).

 The semantics of data ownership depends on the buf field.
 If it is set, the packet data is dynamically allocated and is
 valid indefinitely until a call to av_packet_unref() reduces the
 reference count to 0.

 If the buf field is not set av_packet_ref() would make a copy instead
 of increasing the reference count.

 The side data is always allocated with av_malloc(), copied by
 av_packet_ref() and freed by av_packet_unref().

 sizeof(AVPacket) being a part of the public ABI is deprecated. once
 av_init_packet() is removed, new packets will only be able to be allocated
 with av_packet_alloc(), and new fields may be added to the end of the struct
 with a minor bump.

 @see av_packet_alloc
 @see av_packet_ref
 @see av_packet_unref

</member>
        <member name="T:AVPacketSideDataType">
 @defgroup lavc_packet AVPacket

 Types and functions for working with AVPacket.
 @{


 Allocate new information of a packet.

 @param pkt packet
 @param type side information type
 @param size side information size
 @return pointer to fresh allocated data or NULL otherwise


 Wrap an existing array as a packet side data.

 @param pkt packet
 @param type side information type
 @param data the side data array. It must be allocated with the av_malloc()
             family of functions. The ownership of the data is transferred to
             pkt.
 @param size side information size
 @return a non-negative number on success, a negative AVERROR code on
         failure. On failure, the packet is unchanged and the data remains
         owned by the caller.


 Get side information from packet.

 @param pkt packet
 @param type desired side information type
 @param size If supplied, *size will be set to the size of the side data
             or to zero if the desired side data is not present.
 @return pointer to data if present or NULL otherwise

</member>
        <member name="F:AV_PKT_DATA_NB">
The number of side data types.
This is not part of the public API/ABI in the sense that it may
change when new side data types are added.
This must stay the last enum value.
If its value becomes huge, some code using it
needs to be updated as it assumes it to be smaller than other limits.

</member>
        <member name="F:AV_PKT_DATA_DYNAMIC_HDR10_PLUS">
HDR10+ dynamic metadata associated with a video frame. The metadata is in
the form of the AVDynamicHDRPlus struct and contains
information for color volume transform - application 4 of
SMPTE 2094-40:2016 standard.

</member>
        <member name="F:AV_PKT_DATA_S12M_TIMECODE">
Timecode which conforms to SMPTE ST 12-1:2014. The data is an array of 4 uint32_t
where the first uint32_t describes how many (1-3) of the other timecodes are used.
The timecode format is described in the documentation of av_timecode_get_smpte_from_framenum()
function in libavutil/timecode.h.

</member>
        <member name="F:AV_PKT_DATA_DOVI_CONF">
DOVI configuration
ref:
dolby-vision-bitstreams-within-the-iso-base-media-file-format-v2.1.2, section 2.2
dolby-vision-bitstreams-in-mpeg-2-transport-stream-multiplex-v1.2, section 3.3
Tags are stored in struct AVDOVIDecoderConfigurationRecord.

</member>
        <member name="F:AV_PKT_DATA_ICC_PROFILE">
ICC profile data consisting of an opaque octet buffer following the
format described by ISO 15076-1.

</member>
        <member name="F:AV_PKT_DATA_PRFT">
Producer Reference Time data corresponding to the AVProducerReferenceTime struct,
usually exported by some encoders (on demand through the prft flag set in the
AVCodecContext export_side_data field).

</member>
        <member name="F:AV_PKT_DATA_AFD">
Active Format Description data consisting of a single byte as specified
in ETSI TS 101 154 using AVActiveFormatDescription enum.

</member>
        <member name="F:AV_PKT_DATA_ENCRYPTION_INFO">
This side data contains encryption info for how to decrypt the packet.
The format is not part of ABI, use av_encryption_info_* methods to access.

</member>
        <member name="F:AV_PKT_DATA_ENCRYPTION_INIT_INFO">
This side data is encryption initialization data.
The format is not part of ABI, use av_encryption_init_info_* methods to
access.

</member>
        <member name="F:AV_PKT_DATA_A53_CC">
ATSC A53 Part 4 Closed Captions. This metadata should be associated with
a video stream. A53 CC bitstream is stored as uint8_t in AVPacketSideData.data.
The number of bytes of CC data is AVPacketSideData.size.

</member>
        <member name="F:AV_PKT_DATA_CONTENT_LIGHT_LEVEL">
Content light level (based on CTA-861.3). This metadata should be
associated with a video stream and contains data in the form of the
AVContentLightMetadata struct.

</member>
        <member name="F:AV_PKT_DATA_SPHERICAL">
This side data should be associated with a video stream and corresponds
to the AVSphericalMapping structure.

</member>
        <member name="F:AV_PKT_DATA_MASTERING_DISPLAY_METADATA">
Mastering display metadata (based on SMPTE-2086:2014). This metadata
should be associated with a video stream and contains data in the form
of the AVMasteringDisplayMetadata struct.

</member>
        <member name="F:AV_PKT_DATA_MPEGTS_STREAM_ID">
MPEGTS stream ID as uint8_t, this is required to pass the stream ID
information from the demuxer to the corresponding muxer.

</member>
        <member name="F:AV_PKT_DATA_METADATA_UPDATE">
A list of zero terminated key/value strings. There is no end marker for
the list, so it is required to rely on the side data size to stop. This
side data includes updated metadata which appeared in the stream.

</member>
        <member name="F:AV_PKT_DATA_WEBVTT_SETTINGS">
The optional settings (rendering instructions) that immediately
follow the timestamp specifier of a WebVTT cue.

</member>
        <member name="F:AV_PKT_DATA_WEBVTT_IDENTIFIER">
The optional first identifier line of a WebVTT cue.

</member>
        <member name="F:AV_PKT_DATA_MATROSKA_BLOCKADDITIONAL">
Data found in BlockAdditional element of matroska container. There is
no end marker for the data, so it is required to rely on the side data
size to recognize the end. 8 byte id (as found in BlockAddId) followed
by data.

</member>
        <member name="F:AV_PKT_DATA_SUBTITLE_POSITION">
Subtitle event position
@code
u32le x1
u32le y1
u32le x2
u32le y2
@endcode

</member>
        <member name="F:AV_PKT_DATA_STRINGS_METADATA">
A list of zero terminated key/value strings. There is no end marker for
the list, so it is required to rely on the side data size to stop.

</member>
        <member name="F:AV_PKT_DATA_JP_DUALMONO">
An AV_PKT_DATA_JP_DUALMONO side data packet indicates that
the packet may contain "dual mono" audio specific to Japanese DTV
and if it is true, recommends only the selected channel to be used.
@code
u8    selected channels (0=mail/left, 1=sub/right, 2=both)
@endcode

</member>
        <member name="F:AV_PKT_DATA_SKIP_SAMPLES">
Recommmends skipping the specified number of samples
@code
u32le number of samples to skip from start of this packet
u32le number of samples to skip from end of this packet
u8    reason for start skip
u8    reason for end   skip (0=padding silence, 1=convergence)
@endcode

</member>
        <member name="F:AV_PKT_DATA_CPB_PROPERTIES">
This side data corresponds to the AVCPBProperties struct.

</member>
        <member name="F:AV_PKT_DATA_FALLBACK_TRACK">
This side data contains an integer value representing the stream index
of a "fallback" track.  A fallback track indicates an alternate
track to use when the current track can not be decoded for some reason.
e.g. no decoder available for codec.

</member>
        <member name="F:AV_PKT_DATA_QUALITY_STATS">
This side data contains quality related information from the encoder.
@code
u32le quality factor of the compressed frame. Allowed range is between 1 (good) and FF_LAMBDA_MAX (bad).
u8    picture type
u8    error count
u16   reserved
u64le[error count] sum of squared differences between encoder in and output
@endcode

</member>
        <member name="F:AV_PKT_DATA_AUDIO_SERVICE_TYPE">
This side data should be associated with an audio stream and corresponds
to enum AVAudioServiceType.

</member>
        <member name="F:AV_PKT_DATA_STEREO3D">
This side data should be associated with a video stream and contains
Stereoscopic 3D information in form of the AVStereo3D struct.

</member>
        <member name="F:AV_PKT_DATA_DISPLAYMATRIX">
 This side data contains a 3x3 transformation matrix describing an affine
 transformation that needs to be applied to the decoded video frames for
 correct presentation.

 See libavutil/display.h for a detailed description of the data.

</member>
        <member name="F:AV_PKT_DATA_REPLAYGAIN">
This side data should be associated with an audio stream and contains
ReplayGain information in form of the AVReplayGain struct.

</member>
        <member name="F:AV_PKT_DATA_H263_MB_INFO">
An AV_PKT_DATA_H263_MB_INFO side data packet contains a number of
structures with info about macroblocks relevant to splitting the
packet into smaller packets on macroblock edges (e.g. as for RFC 2190).
That is, it does not necessarily contain info about all macroblocks,
as long as the distance between macroblocks in the info is smaller
than the target payload size.
Each MB info structure is 12 bytes, and is laid out as follows:
@code
u32le bit offset from the start of the packet
u8    current quantizer at the start of the macroblock
u8    GOB number
u16le macroblock address within the GOB
u8    horizontal MV predictor
u8    vertical MV predictor
u8    horizontal MV predictor for block number 3
u8    vertical MV predictor for block number 3
@endcode

</member>
        <member name="F:AV_PKT_DATA_NEW_EXTRADATA">
The AV_PKT_DATA_NEW_EXTRADATA is used to notify the codec or the format
that the extradata buffer was changed and the receiving side should
act upon it appropriately. The new extradata is embedded in the side
data buffer and should be immediately used for processing the current
frame or packet.

</member>
        <member name="F:AV_PKT_DATA_PALETTE">
An AV_PKT_DATA_PALETTE side data packet contains exactly AVPALETTE_SIZE
bytes worth of palette. This side data signals that a new palette is
present.

</member>
        <member name="M:av_xiphlacing(System.Byte*,System.UInt32)">
 Encode extradata length to a buffer. Used by xiph codecs.

 @param s buffer to write to; must be at least (v/255+1) bytes long
 @param v size of extradata in bytes
 @return number of bytes written to the buffer.

</member>
        <member name="F:AVProducerReferenceTime.wallclock">
A UTC timestamp, in microseconds, since Unix epoch (e.g, av_gettime()).

</member>
        <member name="T:AVProducerReferenceTime">
This structure supplies correlation between a packet timestamp and a wall clock
production time. The definition follows the Producer Reference Time ('prft')
as defined in ISO/IEC 14496-12

</member>
        <member name="M:av_cpb_properties_alloc(System.UInt64*)">
 Allocate a CPB properties structure and initialize its fields to default
 values.

 @param size if non-NULL, the size of the allocated struct will be written
             here. This is useful for embedding it in side data.

 @return the newly allocated struct or NULL on failure

</member>
        <member name="F:AVCPBProperties.vbv_delay">
 The delay between the time the packet this structure is associated with
 is received and the time when it should be decoded, in periods of a 27MHz
 clock.

 UINT64_MAX when unknown or unspecified.

</member>
        <member name="F:AVCPBProperties.buffer_size">
The size of the buffer to which the ratecontrol is applied, in bits.
Zero if unknown or unspecified.

</member>
        <member name="F:AVCPBProperties.avg_bitrate">
Average bitrate of the stream, in bits per second.
Zero if unknown or unspecified.

</member>
        <member name="F:AVCPBProperties.min_bitrate">
Minimum bitrate of the stream, in bits per second.
Zero if unknown or unspecified.

</member>
        <member name="F:AVCPBProperties.max_bitrate">
Maximum bitrate of the stream, in bits per second.
Zero if unknown or unspecified.

</member>
        <member name="T:AVCPBProperties">
This structure describes the bitrate properties of an encoded bitstream. It
roughly corresponds to a subset the VBV parameters for MPEG-2 or HRD
parameters for H.264/HEVC.

</member>
        <member name="F:AVPanScan.position">
position of the top left corner in 1/16 pel for up to 3 fields/frames
- encoding: Set by user.
- decoding: Set by libavcodec.

</member>
        <member name="F:AVPanScan.width">
width and height in 1/16 pel
- encoding: Set by user.
- decoding: Set by libavcodec.

</member>
        <member name="F:AVPanScan.id">
id
- encoding: Set by user.
- decoding: Set by libavcodec.

</member>
        <member name="T:AVPanScan">
Pan Scan area.
This specifies the area which should be displayed.
Note there may be multiple such areas for one frame.

</member>
        <member name="M:av_get_audio_frame_duration2(AVCodecParameters*,System.Int32)">
This function is the same as av_get_audio_frame_duration(), except it works
with AVCodecParameters instead of an AVCodecContext.

</member>
        <member name="M:avcodec_parameters_copy(AVCodecParameters*,AVCodecParameters)">
 Copy the contents of src to dst. Any allocated fields in dst are freed and
 replaced with newly allocated duplicates of the corresponding fields in src.

 @return &gt;= 0 on success, a negative AVERROR code on failure.

</member>
        <member name="M:avcodec_parameters_free(AVCodecParameters**)">
Free an AVCodecParameters instance and everything associated with it and
write NULL to the supplied pointer.

</member>
        <member name="M:avcodec_parameters_alloc">
Allocate a new AVCodecParameters and set its fields to default values
(unknown/invalid/0). The returned struct must be freed with
avcodec_parameters_free().

</member>
        <member name="F:AVCodecParameters.ch_layout">
Audio only. The channel layout and number of channels.

</member>
        <member name="F:AVCodecParameters.seek_preroll">
Audio only. Number of samples to skip after a discontinuity.

</member>
        <member name="F:AVCodecParameters.trailing_padding">
Audio only. The amount of padding (in samples) appended by the encoder to
the end of the audio. I.e. this number of decoded samples must be
discarded by the caller from the end of the stream to get the original
audio without any trailing padding.

</member>
        <member name="F:AVCodecParameters.initial_padding">
Audio only. The amount of padding (in samples) inserted by the encoder at
the beginning of the audio. I.e. this number of leading decoded samples
must be discarded by the caller to get the original audio without leading
padding.

</member>
        <member name="F:AVCodecParameters.frame_size">
Audio only. Audio frame size, if known. Required by some formats to be static.

</member>
        <member name="F:AVCodecParameters.block_align">
 Audio only. The number of bytes per coded audio frame, required by some
 formats.

 Corresponds to nBlockAlign in WAVEFORMATEX.

</member>
        <member name="F:AVCodecParameters.sample_rate">
Audio only. The number of audio samples per second.

</member>
        <member name="F:AVCodecParameters.channels">
Audio only. The number of audio channels.
@deprecated use ch_layout.nb_channels

</member>
        <member name="F:AVCodecParameters.channel_layout">
Audio only. The channel layout bitmask. May be 0 if the channel layout is
unknown or unspecified, otherwise the number of bits set must be equal to
the channels field.
@deprecated use ch_layout

</member>
        <member name="F:AVCodecParameters.video_delay">
Video only. Number of delayed frames.

</member>
        <member name="F:AVCodecParameters.sample_aspect_ratio">
 Video only. The aspect ratio (width / height) which a single pixel
 should have when displayed.

 When the aspect ratio is unknown / undefined, the numerator should be
 set to 0 (the denominator may have any value).

</member>
        <member name="F:AVCodecParameters.width">
Video only. The dimensions of the video frame in pixels.

</member>
        <member name="F:AVCodecParameters.profile">
Codec-specific bitstream restrictions that the stream conforms to.

</member>
        <member name="F:AVCodecParameters.bits_per_raw_sample">
 This is the number of valid bits in each output sample. If the
 sample format has more bits, the least significant bits are additional
 padding bits, which are always 0. Use right shifts to reduce the sample
 to its actual size. For example, audio formats with 24 bit samples will
 have bits_per_raw_sample set to 24, and format set to AV_SAMPLE_FMT_S32.
 To get the original sample use "(int32_t)sample &gt;&gt; 8"."

 For ADPCM this might be 12 or 16 or similar
 Can be 0

</member>
        <member name="F:AVCodecParameters.bits_per_coded_sample">
 The number of bits per sample in the codedwords.

 This is basically the bitrate per sample. It is mandatory for a bunch of
 formats to actually decode them. It's the number of bits for one sample in
 the actual coded bitstream.

 This could be for example 4 for ADPCM
 For PCM formats this matches bits_per_raw_sample
 Can be 0

</member>
        <member name="F:AVCodecParameters.bit_rate">
The average bitrate of the encoded data (in bits per second).

</member>
        <member name="F:AVCodecParameters.format">
- video: the pixel format, the value corresponds to enum AVPixelFormat.
- audio: the sample format, the value corresponds to enum AVSampleFormat.

</member>
        <member name="F:AVCodecParameters.extradata_size">
Size of the extradata content in bytes.

</member>
        <member name="F:AVCodecParameters.extradata">
 Extra binary data needed for initializing the decoder, codec-dependent.

 Must be allocated with av_malloc() and will be freed by
 avcodec_parameters_free(). The allocated size of extradata must be at
 least extradata_size + AV_INPUT_BUFFER_PADDING_SIZE, with the padding
 bytes zeroed.

</member>
        <member name="F:AVCodecParameters.codec_tag">
Additional information about the codec (corresponds to the AVI FOURCC).

</member>
        <member name="T:AVCodecParameters">
 This struct describes the properties of an encoded stream.

 sizeof(AVCodecParameters) is not a part of the public ABI, this struct must
 be allocated with avcodec_parameters_alloc() and freed with
 avcodec_parameters_free().

</member>
        <member name="T:AVFieldOrder">
@}

@addtogroup lavc_core


Video only. The order of the fields in interlaced video.

</member>
        <member name="M:avcodec_descriptor_get_by_name(System.SByte!System.Runtime.CompilerServices.IsSignUnspecifiedByte)">
@return codec descriptor with the given name or NULL if no such descriptor
        exists.

</member>
        <member name="M:avcodec_descriptor_next(AVCodecDescriptor)">
 Iterate over all codec descriptors known to libavcodec.

 @param prev previous descriptor. NULL to get the first descriptor.

 @return next descriptor or NULL after the last descriptor

</member>
        <member name="F:AVCodecDescriptor.mime_types">
MIME type(s) associated with the codec.
May be NULL; if not, a NULL-terminated array of MIME types.
The first item is always non-NULL and is the preferred MIME type.

</member>
        <member name="F:AVCodecDescriptor.props">
Codec properties, a combination of AV_CODEC_PROP_* flags.

</member>
        <member name="F:AVCodecDescriptor.long_name">
A more descriptive name for this codec. May be NULL.

</member>
        <member name="F:AVCodecDescriptor.name">
Name of the codec described by this descriptor. It is non-empty and
unique for each codec descriptor. It should contain alphanumeric
characters and '_' only.

</member>
        <member name="T:AVCodecDescriptor">
@}

@addtogroup lavc_core
@{

This struct describes the properties of a single codec described by an
AVCodecID.
@see avcodec_descriptor_get()

</member>
        <member name="M:avcodec_get_hw_config(AVCodec,System.Int32)">
 Retrieve supported hardware configurations for a codec.

 Values of index from zero to some maximum return the indexed configuration
 descriptor; all other values return NULL.  If the codec does not support
 any hardware configurations then it will always return NULL.

</member>
        <member name="F:AVCodecHWConfig.methods">
Bit set of AV_CODEC_HW_CONFIG_METHOD_* flags, describing the possible
setup methods which can be used with this configuration.

</member>
        <member name="F:AV_CODEC_HW_CONFIG_METHOD_AD_HOC">
 The codec supports this format by some ad-hoc method.

 Additional settings and/or function calls are required.  See the
 codec-specific documentation for details.  (Methods requiring
 this sort of configuration are deprecated and others should be
 used in preference.)

</member>
        <member name="F:AV_CODEC_HW_CONFIG_METHOD_INTERNAL">
 The codec supports this format by some internal method.

 This format can be selected without any additional configuration -
 no device or frames context is required.

</member>
        <member name="F:AV_CODEC_HW_CONFIG_METHOD_HW_FRAMES_CTX">
 The codec supports this format via the hw_frames_ctx interface.

 When selecting this format for a decoder,
 AVCodecContext.hw_frames_ctx should be set to a suitable frames
 context inside the get_format() callback.  The frames context
 must have been created on a device of the specified type.

 When selecting this format for an encoder,
 AVCodecContext.hw_frames_ctx should be set to the context which
 will be used for the input frames before calling avcodec_open2().

</member>
        <member name="F:AV_CODEC_HW_CONFIG_METHOD_HW_DEVICE_CTX">
 The codec supports this format via the hw_device_ctx interface.

 When selecting this format, AVCodecContext.hw_device_ctx should
 have been set to a device of the specified type before calling
 avcodec_open2().

</member>
        <member name="M:av_get_profile_name(AVCodec,System.Int32)">
 Return a name for the specified profile, if available.

 @param codec the codec that is searched for the given profile
 @param profile the profile value for which a name is requested
 @return A name for the profile if found, NULL otherwise.

</member>
        <member name="M:av_codec_is_decoder(AVCodec)">
@return a non-zero number if codec is a decoder, zero otherwise

</member>
        <member name="M:av_codec_is_encoder(AVCodec)">
@return a non-zero number if codec is an encoder, zero otherwise

</member>
        <member name="M:avcodec_find_encoder_by_name(System.SByte!System.Runtime.CompilerServices.IsSignUnspecifiedByte)">
 Find a registered encoder with the specified name.

 @param name name of the requested encoder
 @return An encoder if one was found, NULL otherwise.

</member>
        <member name="M:avcodec_find_decoder_by_name(System.SByte!System.Runtime.CompilerServices.IsSignUnspecifiedByte)">
 Find a registered decoder with the specified name.

 @param name name of the requested decoder
 @return A decoder if one was found, NULL otherwise.

</member>
        <member name="M:av_codec_iterate(System.Void**)">
 Iterate over all registered codecs.

 @param opaque a pointer where libavcodec will store the iteration state. Must
               point to NULL to start the iteration.

 @return the next registered codec or NULL when the iteration is
         finished

</member>
        <member name="F:AVCodec.ch_layouts">
Array of supported channel layouts, terminated with a zeroed layout.

</member>
        <member name="F:AVCodec.channel_layouts">
@deprecated use ch_layouts instead

</member>
        <member name="F:AVCodec.capabilities">
Codec capabilities.
see AV_CODEC_CAP_*

</member>
        <member name="F:AVCodec.long_name">
Descriptive name for the codec, meant to be more human readable than name.
You should use the NULL_IF_CONFIG_SMALL() macro to define it.

</member>
        <member name="F:AVCodec.name">
Name of the codec implementation.
The name is globally unique among encoders and among decoders (but an
encoder and a decoder can share the same name).
This is the primary way to find a codec from the user perspective.

</member>
        <member name="T:AVCodec">
AVCodec.

</member>
        <member name="T:AVProfile">
@}

@file
@ingroup libavc
Libavcodec version macros.

 FF_API_* defines may be placed below to indicate public API that will be
 dropped at a future version bump. The defines themselves are not part of
 the public API and may change, break or disappear at any time.

 @note, when bumping the major version it is recommended to manually
 disable each FF_API_* in its own commit instead of disabling them all
 at once through the bump. This improves the git bisect-ability of the change.

@addtogroup lavc_core
@{

Decoder can use draw_horiz_band callback.

Codec uses get_buffer() or get_encode_buffer() for allocating buffers and
supports custom allocators.
If not set, it might not use get_buffer() or get_encode_buffer() at all, or
use operations that assume the buffer was allocated by
avcodec_default_get_buffer2 or avcodec_default_get_encode_buffer.

@deprecated Use parsers to always send proper frames.

 Encoder or decoder requires flushing with NULL input at the end in order to
 give the complete and correct output.

 NOTE: If this flag is not set, the codec is guaranteed to never be fed with
       with NULL data. The user can still send NULL data to the public encode
       or decode function, but libavcodec will not pass it along to the codec
       unless this flag is set.

 Decoders:
 The decoder has a non-zero delay and needs to be fed with avpkt-&gt;data=NULL,
 avpkt-&gt;size=0 at the end to get the delayed data until the decoder no longer
 returns frames.

 Encoders:
 The encoder needs to be fed with NULL data at the end of encoding until the
 encoder no longer returns data.

 NOTE: For encoders implementing the AVCodec.encode2() function, setting this
       flag also means that the encoder must set the pts and duration for
       each output packet. If this flag is not set, the pts and duration will
       be determined by libavcodec from the input frame.

Codec can be fed a final frame with a smaller size.
This can be used to prevent truncation of the last audio samples.

Codec can output multiple frames per AVPacket
Normally demuxers return one frame at a time, demuxers which do not do
are connected to a parser to split what they return into proper frames.
This flag is reserved to the very rare category of codecs which have a
bitstream that cannot be split into frames without timeconsuming
operations like full decoding. Demuxers carrying such bitstreams thus
may return multiple frames in a packet. This has many disadvantages like
prohibiting stream copy in many cases thus it should only be considered
as a last resort.

Codec is experimental and is thus avoided in favor of non experimental
encoders

Codec should fill in channel configuration and samplerate instead of container

Codec supports frame-level multithreading.

Codec supports slice-based (or partition-based) multithreading.

Codec supports changed parameters at any point.

Codec supports multithreading through a method other than slice- or
frame-level multithreading. Typically this marks wrappers around
multithreading-capable external libraries.

Audio encoder supports receiving a different number of samples in each call.

Decoder is not a preferred choice for probing.
This indicates that the decoder is not a good choice for probing.
It could for example be an expensive to spin up hardware decoder,
or it could simply not provide a lot of useful information about
the stream.
A decoder marked with this flag should only be used as last resort
choice for probing.

Deprecated and unused. Use AVCodecDescriptor.props instead

Deprecated and unused. Use AVCodecDescriptor.props instead

Codec is backed by a hardware implementation. Typically used to
identify a non-hwaccel hardware decoder. For information about hwaccels, use
avcodec_get_hw_config() instead.

Codec is potentially backed by a hardware implementation, but not
necessarily. This is used instead of AV_CODEC_CAP_HARDWARE, if the
implementation provides some sort of internal fallback.

This codec takes the reordered_opaque field from input AVFrames
and returns it in the corresponding field in AVCodecContext after
encoding.

This encoder can be flushed using avcodec_flush_buffers(). If this flag is
not set, the encoder must be closed and reopened to ensure that no frames
remain pending.

AVProfile.


If non-NULL, an array of profiles recognized for this codec.
Terminated with FF_PROFILE_UNKNOWN.

</member>
        <member name="T:AVCodecID">
@addtogroup lavc_core
@{

 Identify the syntax and semantics of the bitstream.
 The principle is roughly:
 Two decoders with the same ID can decode the same streams.
 Two encoders with the same ID can encode compatible streams.
 There may be slight deviations from the principle due to implementation
 details.

 If you add a codec ID to this list, add it so that
 1. no value of an existing codec ID changes (that would break ABI),
 2. it is as close as possible to similar codecs

 After adding new codec IDs, do not forget to add an entry to the codec
 descriptor list and bump libavcodec minor version.


Get the name of a codec.
@return  a static string identifying the codec; never NULL


 Return codec bits per sample.

 @param[in] codec_id the codec
 @return Number of bits per sample or zero if unknown for the given codec.


 Return codec bits per sample.
 Only return non-zero if the bits per sample is exactly correct, not an
 approximation.

 @param[in] codec_id the codec
 @return Number of bits per sample or zero if unknown for the given codec.


 Return a name for the specified profile, if available.

 @param codec_id the ID of the codec to which the requested profile belongs
 @param profile the profile value for which a name is requested
 @return A name for the profile if found, NULL otherwise.

 @note unlike av_get_profile_name(), which searches a list of profiles
       supported by a specific decoder or encoder implementation, this
       function searches the list of profiles from the AVCodecDescriptor


Return the PCM codec associated with a sample format.
@param be  endianness, 0 for little, 1 for big,
           -1 (or anything else) for native
@return  AV_CODEC_ID_PCM_* or AV_CODEC_ID_NONE


 Find a registered decoder with a matching codec ID.

 @param id AVCodecID of the requested decoder
 @return A decoder if one was found, NULL otherwise.


 Find a registered encoder with a matching codec ID.

 @param id AVCodecID of the requested encoder
 @return An encoder if one was found, NULL otherwise.


Codec uses only intra compression.
Video and audio codecs only.

Codec supports lossy compression. Audio and video codecs only.
@note a codec may support both lossy and lossless
compression modes

Codec supports lossless compression. Audio and video codecs only.

 Codec supports frame reordering. That is, the coded order (the order in which
 the encoded packets are output by the encoders / stored / input to the
 decoders) may be different from the presentation order of the corresponding
 frames.

 For codecs that do not have this property set, PTS and DTS should always be
 equal.

Subtitle codec is bitmap based
Decoded AVSubtitle data can be read from the AVSubtitleRect-&gt;pict field.

Subtitle codec is text based.
Decoded AVSubtitle data can be read from the AVSubtitleRect-&gt;ass field.

@return descriptor for given codec ID or NULL if no descriptor exists.


Specific type of the encoded data (the codec used).

</member>
        <member name="M:av_hwframe_map(AVFrame*,AVFrame,System.Int32)">
 Map a hardware frame.

 This has a number of different possible effects, depending on the format
 and origin of the src and dst frames.  On input, src should be a usable
 frame with valid buffers and dst should be blank (typically as just created
 by av_frame_alloc()).  src should have an associated hwframe context, and
 dst may optionally have a format and associated hwframe context.

 If src was created by mapping a frame from the hwframe context of dst,
 then this function undoes the mapping - dst is replaced by a reference to
 the frame that src was originally mapped from.

 If both src and dst have an associated hwframe context, then this function
 attempts to map the src frame from its hardware context to that of dst and
 then fill dst with appropriate data to be usable there.  This will only be
 possible if the hwframe contexts and associated devices are compatible -
 given compatible devices, av_hwframe_ctx_create_derived() can be used to
 create a hwframe context for dst in which mapping should be possible.

 If src has a hwframe context but dst does not, then the src frame is
 mapped to normal memory and should thereafter be usable as a normal frame.
 If the format is set on dst, then the mapping will attempt to create dst
 with that format and fail if it is not possible.  If format is unset (is
 AV_PIX_FMT_NONE) then dst will be mapped with whatever the most appropriate
 format to use is (probably the sw_format of the src hwframe context).

 A return value of AVERROR(ENOSYS) indicates that the mapping is not
 possible with the given arguments and hwframe setup, while other return
 values indicate that it failed somehow.

 On failure, the destination frame will be left blank, except for the
 hw_frames_ctx/format fields thay may have been set by the caller - those will
 be preserved as they were.

 @param dst Destination frame, to contain the mapping.
 @param src Source frame, to be mapped.
 @param flags Some combination of AV_HWFRAME_MAP_* flags.
 @return Zero on success, negative AVERROR code on failure.

</member>
        <member name="F:AV_HWFRAME_MAP_DIRECT">
The mapping must be direct.  That is, there must not be any copying in
the map or unmap steps.  Note that performance of direct mappings may
be much lower than normal memory.

</member>
        <member name="F:AV_HWFRAME_MAP_OVERWRITE">
The mapped frame will be overwritten completely in subsequent
operations, so the current frame data need not be loaded.  Any values
which are not overwritten are unspecified.

</member>
        <member name="F:AV_HWFRAME_MAP_WRITE">
The mapping must be writeable.

</member>
        <member name="F:AV_HWFRAME_MAP_READ">
The mapping must be readable.

</member>
        <member name="M:av_hwframe_constraints_free(AVHWFramesConstraints**)">
 Free an AVHWFrameConstraints structure.

 @param constraints The (filled or unfilled) AVHWFrameConstraints structure.

</member>
        <member name="M:av_hwdevice_get_hwframe_constraints(AVBufferRef*,System.Void)">
 Get the constraints on HW frames given a device and the HW-specific
 configuration to be used with that device.  If no HW-specific
 configuration is provided, returns the maximum possible capabilities
 of the device.

 @param ref a reference to the associated AVHWDeviceContext.
 @param hwconfig a filled HW-specific configuration structure, or NULL
        to return the maximum possible capabilities of the device.
 @return AVHWFramesConstraints structure describing the constraints
         on the device, or NULL if not available.

</member>
        <member name="M:av_hwdevice_hwconfig_alloc(AVBufferRef*)">
 Allocate a HW-specific configuration structure for a given HW device.
 After use, the user must free all members as required by the specific
 hardware structure being used, then free the structure itself with
 av_free().

 @param device_ctx a reference to the associated AVHWDeviceContext.
 @return The newly created HW-specific configuration structure on
         success or NULL on failure.

</member>
        <member name="F:AVHWFramesConstraints.max_width">
The maximum size of frames in this hw_frames_ctx.
(INT_MAX if not known / no limit.)

</member>
        <member name="F:AVHWFramesConstraints.min_width">
The minimum size of frames in this hw_frames_ctx.
(Zero if not known.)

</member>
        <member name="T:AVHWFramesConstraints">
This struct describes the constraints on hardware frames attached to
a given device with a hardware-specific configuration.  This is returned
by av_hwdevice_get_hwframe_constraints() and must be freed by
av_hwframe_constraints_free() after use.

</member>
        <member name="T:AVHWFrameTransferDirection">
 Get a list of possible source or target formats usable in
 av_hwframe_transfer_data().

 @param hwframe_ctx the frame context to obtain the information for
 @param dir the direction of the transfer
 @param formats the pointer to the output format list will be written here.
                The list is terminated with AV_PIX_FMT_NONE and must be freed
                by the caller when no longer needed using av_free().
                If this function returns successfully, the format list will
                have at least one item (not counting the terminator).
                On failure, the contents of this pointer are unspecified.
 @param flags currently unused, should be set to zero
 @return 0 on success, a negative AVERROR code on failure.

</member>
        <member name="F:AV_HWFRAME_TRANSFER_DIRECTION_TO">
Transfer the data to the queried hw frame.

</member>
        <member name="F:AV_HWFRAME_TRANSFER_DIRECTION_FROM">
Transfer the data from the queried hw frame.

</member>
        <member name="M:av_hwframe_transfer_data(AVFrame*,AVFrame,System.Int32)">
 Copy data to or from a hw surface. At least one of dst/src must have an
 AVHWFramesContext attached.

 If src has an AVHWFramesContext attached, then the format of dst (if set)
 must use one of the formats returned by av_hwframe_transfer_get_formats(src,
 AV_HWFRAME_TRANSFER_DIRECTION_FROM).
 If dst has an AVHWFramesContext attached, then the format of src must use one
 of the formats returned by av_hwframe_transfer_get_formats(dst,
 AV_HWFRAME_TRANSFER_DIRECTION_TO)

 dst may be "clean" (i.e. with data/buf pointers unset), in which case the
 data buffers will be allocated by this function using av_frame_get_buffer().
 If dst-&gt;format is set, then this format will be used, otherwise (when
 dst-&gt;format is AV_PIX_FMT_NONE) the first acceptable format will be chosen.

 The two frames must have matching allocated dimensions (i.e. equal to
 AVHWFramesContext.width/height), since not all device types support
 transferring a sub-rectangle of the whole surface. The display dimensions
 (i.e. AVFrame.width/height) may be smaller than the allocated dimensions, but
 also have to be equal for both frames. When the display dimensions are
 smaller than the allocated dimensions, the content of the padding in the
 destination frame is unspecified.

 @param dst the destination frame. dst is not touched on failure.
 @param src the source frame.
 @param flags currently unused, should be set to zero
 @return 0 on success, a negative AVERROR error code on failure.

</member>
        <member name="M:av_hwframe_get_buffer(AVBufferRef*,AVFrame*,System.Int32)">
 Allocate a new frame attached to the given AVHWFramesContext.

 @param hwframe_ctx a reference to an AVHWFramesContext
 @param frame an empty (freshly allocated or unreffed) frame to be filled with
              newly allocated buffers.
 @param flags currently unused, should be set to zero
 @return 0 on success, a negative AVERROR code on failure

</member>
        <member name="M:av_hwframe_ctx_init(AVBufferRef*)">
 Finalize the context before use. This function must be called after the
 context is filled with all the required information and before it is attached
 to any frames.

 @param ref a reference to the AVHWFramesContext
 @return 0 on success, a negative AVERROR code on failure

</member>
        <member name="M:av_hwframe_ctx_alloc(AVBufferRef*)">
 Allocate an AVHWFramesContext tied to a given device context.

 @param device_ctx a reference to a AVHWDeviceContext. This function will make
                   a new reference for internal use, the one passed to the
                   function remains owned by the caller.
 @return a reference to the newly created AVHWFramesContext on success or NULL
         on failure.

</member>
        <member name="M:av_hwdevice_ctx_init(AVBufferRef*)">
 Finalize the device context before use. This function must be called after
 the context is filled with all the required information and before it is
 used in any way.

 @param ref a reference to the AVHWDeviceContext
 @return 0 on success, a negative AVERROR code on failure

</member>
        <member name="F:AVHWFramesContext.width">
 The allocated dimensions of the frames in this pool.

 Must be set by the user before calling av_hwframe_ctx_init().

</member>
        <member name="F:AVHWFramesContext.initial_pool_size">
 Initial size of the frame pool. If a device type does not support
 dynamically resizing the pool, then this is also the maximum pool size.

 May be set by the caller before calling av_hwframe_ctx_init(). Must be
 set if pool is NULL and the device type does not support dynamic pools.

</member>
        <member name="F:AVHWFramesContext.pool">
 A pool from which the frames are allocated by av_hwframe_get_buffer().
 This field may be set by the caller before calling av_hwframe_ctx_init().
 The buffers returned by calling av_buffer_pool_get() on this pool must
 have the properties described in the documentation in the corresponding hw
 type's header (hwcontext_*.h). The pool will be freed strictly before
 this struct's free() callback is invoked.

 This field may be NULL, then libavutil will attempt to allocate a pool
 internally. Note that certain device types enforce pools allocated at
 fixed size (frame count), which cannot be extended dynamically. In such a
 case, initial_pool_size must be set appropriately.

</member>
        <member name="F:AVHWFramesContext.user_opaque">
Arbitrary user data, to be used e.g. by the free() callback.

</member>
        <member name="F:AVHWFramesContext.hwctx">
 The format-specific data, allocated and freed automatically along with
 this context.

 Should be cast by the user to the format-specific context defined in the
 corresponding header (hwframe_*.h) and filled as described in the
 documentation before calling av_hwframe_ctx_init().

 After any frames using this context are created, the contents of this
 struct should not be modified by the caller.

</member>
        <member name="F:AVHWFramesContext.device_ctx">
 The parent AVHWDeviceContext. This is simply a pointer to
 device_ref-&gt;data provided for convenience.

 Set by libavutil in av_hwframe_ctx_init().

</member>
        <member name="F:AVHWFramesContext.device_ref">
A reference to the parent AVHWDeviceContext. This reference is owned and
managed by the enclosing AVHWFramesContext, but the caller may derive
additional references from it.

</member>
        <member name="F:AVHWFramesContext.internal">
Private data used internally by libavutil. Must not be accessed in any
way by the caller.

</member>
        <member name="F:AVHWFramesContext.av_class">
A class for logging.

</member>
        <member name="T:AVHWFramesContext">
 This struct describes a set or pool of "hardware" frames (i.e. those with
 data not located in normal system memory). All the frames in the pool are
 assumed to be allocated in the same way and interchangeable.

 This struct is reference-counted with the AVBuffer mechanism and tied to a
 given AVHWDeviceContext instance. The av_hwframe_ctx_alloc() constructor
 yields a reference, whose data field points to the actual AVHWFramesContext
 struct.


 This field may be set by the caller before calling av_hwframe_ctx_init().

 If non-NULL, this callback will be called when the last reference to
 this context is unreferenced, immediately before it is freed.

</member>
        <member name="F:AVHWDeviceContext.user_opaque">
Arbitrary user data, to be used e.g. by the free() callback.

</member>
        <member name="F:AVHWDeviceContext.hwctx">
 The format-specific data, allocated and freed by libavutil along with
 this context.

 Should be cast by the user to the format-specific context defined in the
 corresponding header (hwcontext_*.h) and filled as described in the
 documentation before calling av_hwdevice_ctx_init().

 After calling av_hwdevice_ctx_init() this struct should not be modified
 by the caller.

</member>
        <member name="F:AVHWDeviceContext.internal">
Private data used internally by libavutil. Must not be accessed in any
way by the caller.

</member>
        <member name="F:AVHWDeviceContext.av_class">
A class for logging. Set by av_hwdevice_ctx_alloc().

</member>
        <member name="T:AVHWDeviceContext">
 This struct aggregates all the (hardware/vendor-specific) "high-level" state,
 i.e. state that is not tied to a concrete processing configuration.
 E.g., in an API that supports hardware-accelerated encoding and decoding,
 this struct will (if possible) wrap the state that is common to both encoding
 and decoding and from which specific instances of encoders or decoders can be
 derived.

 This struct is reference-counted with the AVBuffer mechanism. The
 av_hwdevice_ctx_alloc() constructor yields a reference, whose data field
 points to the actual AVHWDeviceContext. Further objects derived from
 AVHWDeviceContext (such as AVHWFramesContext, describing a frame pool with
 specific properties) will hold an internal reference to it. After all the
 references are released, the AVHWDeviceContext itself will be freed,
 optionally invoking a user-specified callback for uninitializing the hardware
 state.


 This field may be set by the caller before calling av_hwdevice_ctx_init().

 If non-NULL, this callback will be called when the last reference to
 this context is unreferenced, immediately before it is freed.

 @note when other objects (e.g an AVHWFramesContext) are derived from this
       struct, this callback will be invoked after all such child objects
       are fully uninitialized and their respective destructors invoked.

</member>
        <member name="T:AVHWDeviceType">
@}


 This field identifies the underlying API used for hardware access.

 This field is set when this struct is allocated and never changed
 afterwards.


 Look up an AVHWDeviceType by name.

 @param name String name of the device type (case-insensitive).
 @return The type from enum AVHWDeviceType, or AV_HWDEVICE_TYPE_NONE if
         not found.


Get the string name of an AVHWDeviceType.
 *
 * @param type Type from enum AVHWDeviceType.
 * @return Pointer to a static string containing the name, or NULL if the type
 *         is not valid.


 Iterate over supported device types.

 @param type AV_HWDEVICE_TYPE_NONE initially, then the previous type
             returned by this function in subsequent iterations.
 @return The next usable device type from enum AVHWDeviceType, or
         AV_HWDEVICE_TYPE_NONE if there are no more.


 Allocate an AVHWDeviceContext for a given hardware type.

 @param type the type of the hardware device to allocate.
 @return a reference to the newly created AVHWDeviceContext on success or NULL
         on failure.


 Open a device of the specified type and create an AVHWDeviceContext for it.

 This is a convenience function intended to cover the simple cases. Callers
 who need to fine-tune device creation/management should open the device
 manually and then wrap it in an AVHWDeviceContext using
 av_hwdevice_ctx_alloc()/av_hwdevice_ctx_init().

 The returned context is already initialized and ready for use, the caller
 should not call av_hwdevice_ctx_init() on it. The user_opaque/free fields of
 the created AVHWDeviceContext are set by this function and should not be
 touched by the caller.

 @param device_ctx On success, a reference to the newly-created device context
                   will be written here. The reference is owned by the caller
                   and must be released with av_buffer_unref() when no longer
                   needed. On failure, NULL will be written to this pointer.
 @param type The type of the device to create.
 @param device A type-specific string identifying the device to open.
 @param opts A dictionary of additional (type-specific) options to use in
             opening the device. The dictionary remains owned by the caller.
 @param flags currently unused

 @return 0 on success, a negative AVERROR code on failure.


 Create a new device of the specified type from an existing device.

 If the source device is a device of the target type or was originally
 derived from such a device (possibly through one or more intermediate
 devices of other types), then this will return a reference to the
 existing device of the same type as is requested.

 Otherwise, it will attempt to derive a new device from the given source
 device.  If direct derivation to the new type is not implemented, it will
 attempt the same derivation from each ancestor of the source device in
 turn looking for an implemented derivation method.

 @param dst_ctx On success, a reference to the newly-created
                AVHWDeviceContext.
 @param type    The type of the new device to create.
 @param src_ctx A reference to an existing AVHWDeviceContext which will be
                used to create the new device.
 @param flags   Currently unused; should be set to zero.
 @return        Zero on success, a negative AVERROR code on failure.


 Create a new device of the specified type from an existing device.

 This function performs the same action as av_hwdevice_ctx_create_derived,
 however, it is able to set options for the new device to be derived.

 @param dst_ctx On success, a reference to the newly-created
                AVHWDeviceContext.
 @param type    The type of the new device to create.
 @param src_ctx A reference to an existing AVHWDeviceContext which will be
                used to create the new device.
 @param options Options for the new device to create, same format as in
                av_hwdevice_ctx_create.
 @param flags   Currently unused; should be set to zero.
 @return        Zero on success, a negative AVERROR code on failure.


 The device type associated with the configuration.

 Must be set for AV_CODEC_HW_CONFIG_METHOD_HW_DEVICE_CTX and
 AV_CODEC_HW_CONFIG_METHOD_HW_FRAMES_CTX, otherwise unused.

</member>
        <member name="M:av_frame_apply_cropping(AVFrame*,System.Int32)">
 Crop the given video AVFrame according to its crop_left/crop_top/crop_right/
 crop_bottom fields. If cropping is successful, the function will adjust the
 data pointers and the width/height fields, and set the crop fields to 0.

 In all cases, the cropping boundaries will be rounded to the inherent
 alignment of the pixel format. In some cases, such as for opaque hwaccel
 formats, the left/top cropping is ignored. The crop fields are set to 0 even
 if the cropping was rounded or ignored.

 @param frame the frame which should be cropped
 @param flags Some combination of AV_FRAME_CROP_* flags, or 0.

 @return &gt;= 0 on success, a negative AVERROR on error. If the cropping fields
 were invalid, AVERROR(ERANGE) is returned, and nothing is changed.

</member>
        <member name="F:AV_FRAME_CROP_UNALIGNED">
Apply the maximum possible cropping, even if it requires setting the
AVFrame.data[] entries to unaligned pointers. Passing unaligned data
to FFmpeg API is generally not allowed, and causes undefined behavior
(such as crashes). You can pass unaligned data only to FFmpeg APIs that
are explicitly documented to accept it. Use this flag only if you
absolutely know what you are doing.

</member>
        <member name="M:av_frame_get_plane_buffer(AVFrame*,System.Int32)">
 Get the buffer reference a given data plane is stored in.

 @param plane index of the data plane of interest in frame-&gt;extended_data.

 @return the buffer reference that contains the plane or NULL if the input
 frame is not valid.

</member>
        <member name="M:av_frame_copy_props(AVFrame*,AVFrame)">
 Copy only "metadata" fields from src to dst.

 Metadata for the purpose of this function are those fields that do not affect
 the data layout in the buffers.  E.g. pts, sample rate (for audio) or sample
 aspect ratio (for video), but not width/height or channel layout.
 Side data is also copied.

</member>
        <member name="M:av_frame_copy(AVFrame*,AVFrame)">
 Copy the frame data from src to dst.

 This function does not allocate anything, dst must be already initialized and
 allocated with the same parameters as src.

 This function only copies the frame data (i.e. the contents of the data /
 extended data arrays), not any other properties.

 @return &gt;= 0 on success, a negative AVERROR on error.

</member>
        <member name="M:av_frame_make_writable(AVFrame*)">
 Ensure that the frame data is writable, avoiding data copy if possible.

 Do nothing if the frame is writable, allocate new buffers and copy the data
 if it is not.

 @return 0 on success, a negative AVERROR on error.

 @see av_frame_is_writable(), av_buffer_is_writable(),
 av_buffer_make_writable()

</member>
        <member name="M:av_frame_is_writable(AVFrame*)">
 Check if the frame data is writable.

 @return A positive value if the frame data is writable (which is true if and
 only if each of the underlying buffers has only one reference, namely the one
 stored in this frame). Return 0 otherwise.

 If 1 is returned the answer is valid until av_buffer_ref() is called on any
 of the underlying AVBufferRefs (e.g. through av_frame_ref() or directly).

 @see av_frame_make_writable(), av_buffer_is_writable()

</member>
        <member name="M:av_frame_get_buffer(AVFrame*,System.Int32)">
 Allocate new buffer(s) for audio or video data.

 The following fields must be set on frame before calling this function:
 - format (pixel format for video, sample format for audio)
 - width and height for video
 - nb_samples and ch_layout for audio

 This function will fill AVFrame.data and AVFrame.buf arrays and, if
 necessary, allocate and fill AVFrame.extended_data and AVFrame.extended_buf.
 For planar formats, one buffer will be allocated for each plane.

 @warning: if frame already has been allocated, calling this function will
           leak memory. In addition, undefined behavior can occur in certain
           cases.

 @param frame frame in which to store the new buffers.
 @param align Required buffer size alignment. If equal to 0, alignment will be
              chosen automatically for the current CPU. It is highly
              recommended to pass 0 here unless you know what you are doing.

 @return 0 on success, a negative AVERROR on error.

</member>
        <member name="M:av_frame_move_ref(AVFrame*,AVFrame*)">
 Move everything contained in src to dst and reset src.

 @warning: dst is not unreferenced, but directly overwritten without reading
           or deallocating its contents. Call av_frame_unref(dst) manually
           before calling this function to ensure that no memory is leaked.

</member>
        <member name="M:av_frame_unref(AVFrame*)">
Unreference all the buffers referenced by frame and reset the frame fields.

</member>
        <member name="M:av_frame_clone(AVFrame)">
 Create a new frame that references the same data as src.

 This is a shortcut for av_frame_alloc()+av_frame_ref().

 @return newly created AVFrame on success, NULL on error.

</member>
        <member name="M:av_frame_ref(AVFrame*,AVFrame)">
 Set up a new reference to the data described by the source frame.

 Copy frame properties from src to dst and create a new reference for each
 AVBufferRef from src.

 If src is not reference counted, new buffers are allocated and the data is
 copied.

 @warning: dst MUST have been either unreferenced with av_frame_unref(dst),
           or newly allocated with av_frame_alloc() before calling this
           function, or undefined behavior will occur.

 @return 0 on success, a negative AVERROR on error

</member>
        <member name="M:av_frame_free(AVFrame**)">
 Free the frame and any dynamically allocated objects in it,
 e.g. extended_data. If the frame is reference counted, it will be
 unreferenced first.

 @param frame frame to be freed. The pointer will be set to NULL.

</member>
        <member name="M:av_frame_alloc">
 Allocate an AVFrame and set its fields to default values.  The resulting
 struct must be freed using av_frame_free().

 @return An AVFrame filled with default values or NULL on failure.

 @note this only allocates the AVFrame itself, not the data buffers. Those
 must be allocated through other means, e.g. with av_frame_get_buffer() or
 manually.

</member>
        <member name="F:AVFrame.ch_layout">
Channel layout of the audio data.

</member>
        <member name="F:AVFrame.private_ref">
@}

 AVBufferRef for internal use by a single libav* library.
 Must not be used to transfer data between libraries.
 Has to be NULL when ownership of the frame leaves the respective library.

 Code outside the FFmpeg libs should never check or change the contents of the buffer ref.

 FFmpeg calls av_buffer_unref() on it when the frame is unreferenced.
 av_frame_copy_props() calls create a new reference with av_buffer_ref()
 for the target frame's private_ref field.

</member>
        <member name="F:AVFrame.crop_top">
@anchor cropping
@name Cropping
Video frames only. The number of pixels to discard from the the
top/bottom/left/right border of the frame to obtain the sub-rectangle of
the frame intended for presentation.
@{

</member>
        <member name="F:AVFrame.opaque_ref">
 AVBufferRef for free use by the API user. FFmpeg will never check the
 contents of the buffer ref. FFmpeg calls av_buffer_unref() on it when
 the frame is unreferenced. av_frame_copy_props() calls create a new
 reference with av_buffer_ref() for the target frame's opaque_ref field.

 This is unrelated to the opaque field, although it serves a similar
 purpose.

</member>
        <member name="F:AVFrame.hw_frames_ctx">
For hwaccel-format frames, this should be a reference to the
AVHWFramesContext describing the frame.

</member>
        <member name="F:AVFrame.pkt_size">
size of the corresponding packet containing the compressed
frame.
It is set to a negative value if unknown.
- encoding: unused
- decoding: set by libavcodec, read by user.

</member>
        <member name="F:AVFrame.channels">
number of audio channels, only used for audio.
- encoding: unused
- decoding: Read by user.
@deprecated use ch_layout instead

</member>
        <member name="F:AVFrame.decode_error_flags">
decode error flags of the frame, set to a combination of
FF_DECODE_ERROR_xxx flags if the decoder produced a frame, but there
were errors during the decoding.
- encoding: unused
- decoding: set by libavcodec, read by user.

</member>
        <member name="F:AVFrame.metadata">
metadata.
- encoding: Set by user.
- decoding: Set by libavcodec.

</member>
        <member name="F:AVFrame.pkt_duration">
duration of the corresponding packet, expressed in
AVStream-&gt;time_base units, 0 if unknown.
- encoding: unused
- decoding: Read by user.

</member>
        <member name="F:AVFrame.pkt_pos">
reordered pos from the last AVPacket that has been input into the decoder
- encoding: unused
- decoding: Read by user.

</member>
        <member name="F:AVFrame.best_effort_timestamp">
frame timestamp estimated using various heuristics, in stream time base
- encoding: unused
- decoding: set by libavcodec, read by user.

</member>
        <member name="F:AVFrame.flags">
 @defgroup lavu_frame_flags AV_FRAME_FLAGS
 @ingroup lavu_frame
 Flags describing additional frame properties.

 @{

The frame data may be corrupted, e.g. due to decoding errors.

A flag to mark the frames which need to be decoded, but shouldn't be output.

@}

Frame flags, a combination of @ref lavu_frame_flags

</member>
        <member name="F:AVFrame.nb_extended_buf">
Number of elements in extended_buf.

</member>
        <member name="F:AVFrame.extended_buf">
 For planar audio which requires more than AV_NUM_DATA_POINTERS
 AVBufferRef pointers, this array will hold all the references which
 cannot fit into AVFrame.buf.

 Note that this is different from AVFrame.extended_data, which always
 contains all the pointers. This array only contains the extra pointers,
 which cannot fit into AVFrame.buf.

 This array is always allocated using av_malloc() by whoever constructs
 the frame. It is freed in av_frame_unref().

</member>
        <member name="F:AVFrame.channel_layout">
Channel layout of the audio data.
@deprecated use ch_layout instead

</member>
        <member name="F:AVFrame.sample_rate">
Sample rate of the audio data.

</member>
        <member name="F:AVFrame.reordered_opaque">
reordered opaque 64 bits (generally an integer or a double precision float
PTS but can be anything).
The user sets AVCodecContext.reordered_opaque to represent the input at
that time,
the decoder reorders values as needed and sets AVFrame.reordered_opaque
to exactly one of the values provided by the user through AVCodecContext.reordered_opaque

</member>
        <member name="F:AVFrame.palette_has_changed">
Tell user application that palette has changed from previous frame.

</member>
        <member name="F:AVFrame.top_field_first">
If the content is interlaced, is top field displayed first.

</member>
        <member name="F:AVFrame.interlaced_frame">
The content of the picture is interlaced.

</member>
        <member name="F:AVFrame.repeat_pict">
When decoding, this signals how much the picture must be delayed.
extra_delay = repeat_pict / (2*fps)

</member>
        <member name="F:AVFrame.opaque">
for some private data of the user

</member>
        <member name="F:AVFrame.quality">
quality (between 1 (good) and FF_LAMBDA_MAX (bad))

</member>
        <member name="F:AVFrame.display_picture_number">
picture number in display order

</member>
        <member name="F:AVFrame.coded_picture_number">
picture number in bitstream order

</member>
        <member name="F:AVFrame.time_base">
Time base for the timestamps in this frame.
In the future, this field may be set on frames output by decoders or
filters, but its value will be by default ignored on input to encoders
or filters.

</member>
        <member name="F:AVFrame.pkt_dts">
DTS copied from the AVPacket that triggered returning this frame. (if frame threading isn't used)
This is also the Presentation time of this AVFrame calculated from
only AVPacket.dts values without pts values.

</member>
        <member name="F:AVFrame.pts">
Presentation timestamp in time_base units (time when frame should be shown to user).

</member>
        <member name="F:AVFrame.sample_aspect_ratio">
Sample aspect ratio for the video frame, 0/1 if unknown/unspecified.

</member>
        <member name="F:AVFrame.key_frame">
1 -&gt; keyframe, 0-&gt; not

</member>
        <member name="F:AVFrame.format">
format of the frame, -1 if unknown or unset
Values correspond to enum AVPixelFormat for video frames,
enum AVSampleFormat for audio)

</member>
        <member name="F:AVFrame.nb_samples">
@}

number of audio samples (per channel) described by this frame

</member>
        <member name="F:AVFrame.width">
 @name Video dimensions
 Video frames only. The coded dimensions (in pixels) of the video frame,
 i.e. the size of the rectangle that contains some well-defined values.

 @note The part of the frame intended for display/presentation is further
 restricted by the @ref cropping "Cropping rectangle".
 @{

</member>
        <member name="F:AVFrame.extended_data">
 pointers to the data planes/channels.

 For video, this should simply point to data[].

 For planar audio, each channel has a separate data pointer, and
 linesize[0] contains the size of each channel buffer.
 For packed audio, there is just one data pointer, and linesize[0]
 contains the total size of the buffer for all channels.

 Note: Both data and extended_data should always be set in a valid frame,
 but for planar audio with more channels that can fit in data,
 extended_data must be used in order to access all channels.

</member>
        <member name="F:AVFrame.linesize">
 For video, a positive or negative value, which is typically indicating
 the size in bytes of each picture line, but it can also be:
 - the negative byte size of lines for vertical flipping
   (with data[n] pointing to the end of the data
 - a positive or negative multiple of the byte size as for accessing
   even and odd fields of a frame (possibly flipped)

 For audio, only linesize[0] may be set. For planar audio, each channel
 plane must be the same size.

 For video the linesizes should be multiples of the CPUs alignment
 preference, this is 16 or 32 for modern desktop CPUs.
 Some code requires such alignment other code can be slower without
 correct alignment, for yet other it makes no difference.

 @note The linesize may be larger than the size of usable data -- there
 may be extra padding present for performance reasons.

 @attention In case of video, line size values can be negative to achieve
 a vertically inverted iteration over image lines.

</member>
        <member name="F:AVFrame.data">
 pointer to the picture/channel planes.
 This might be different from the first allocated byte. For video,
 it could even point to the end of the image data.

 All pointers in data and extended_data must point into one of the
 AVBufferRef in buf or extended_buf.

 Some decoders access areas outside 0,0 - width,height, please
 see avcodec_align_dimensions2(). Some filters and swscale can read
 up to 16 bytes beyond the planes, if these filters are to be used,
 then 16 extra bytes must be allocated.

 NOTE: Pointers not needed by the format MUST be set to NULL.

 @attention In case of video, the data[] pointers can point to the
 end of image data in order to reverse line order, when used in
 combination with negative values in the linesize[] array.

</member>
        <member name="T:AVFrame">
 This structure describes decoded (raw) audio or video data.

 AVFrame must be allocated using av_frame_alloc(). Note that this only
 allocates the AVFrame itself, the buffers for the data must be managed
 through other means (see below).
 AVFrame must be freed with av_frame_free().

 AVFrame is typically allocated once and then reused multiple times to hold
 different data (e.g. a single AVFrame to hold frames received from a
 decoder). In such a case, av_frame_unref() will free any references held by
 the frame and reset it to its original clean state before it
 is reused again.

 The data described by an AVFrame is usually reference counted through the
 AVBuffer API. The underlying buffer references are stored in AVFrame.buf /
 AVFrame.extended_buf. An AVFrame is considered to be reference counted if at
 least one reference is set, i.e. if AVFrame.buf[0] != NULL. In such a case,
 every single data plane must be contained in one of the buffers in
 AVFrame.buf or AVFrame.extended_buf.
 There may be a single buffer for all the data, or one separate buffer for
 each plane, or anything in between.

 sizeof(AVFrame) is not a part of the public ABI, so new fields may be added
 to the end with a minor bump.

 Fields can be accessed through AVOptions, the name string used, matches the
 C structure field name for fields accessible through AVOptions. The AVClass
 for AVFrame can be obtained from avcodec_get_frame_class()

</member>
        <member name="F:AVRegionOfInterest.qoffset">
 Quantisation offset.

 Must be in the range -1 to +1.  A value of zero indicates no quality
 change.  A negative value asks for better quality (less quantisation),
 while a positive value asks for worse quality (greater quantisation).

 The range is calibrated so that the extreme values indicate the
 largest possible offset - if the rest of the frame is encoded with the
 worst possible quality, an offset of -1 indicates that this region
 should be encoded with the best possible quality anyway.  Intermediate
 values are then interpolated in some codec-dependent way.

 For example, in 10-bit H.264 the quantisation parameter varies between
 -12 and 51.  A typical qoffset value of -1/10 therefore indicates that
 this region should be encoded with a QP around one-tenth of the full
 range better than the rest of the frame.  So, if most of the frame
 were to be encoded with a QP of around 30, this region would get a QP
 of around 24 (an offset of approximately -1/10 * (51 - -12) = -6.3).
 An extreme value of -1 would indicate that this region should be
 encoded with the best possible quality regardless of the treatment of
 the rest of the frame - that is, should be encoded at a QP of -12.

</member>
        <member name="F:AVRegionOfInterest.top">
 Distance in pixels from the top edge of the frame to the top and
 bottom edges and from the left edge of the frame to the left and
 right edges of the rectangle defining this region of interest.

 The constraints on a region are encoder dependent, so the region
 actually affected may be slightly larger for alignment or other
 reasons.

</member>
        <member name="F:AVRegionOfInterest.self_size">
Must be set to the size of this data structure (that is,
sizeof(AVRegionOfInterest)).

</member>
        <member name="T:AVRegionOfInterest">
 Structure describing a single Region Of Interest.

 When multiple regions are defined in a single side-data block, they
 should be ordered from most to least important - some encoders are only
 capable of supporting a limited number of distinct regions, so will have
 to truncate the list.

 When overlapping regions are defined, the first region containing a given
 area of the frame applies.

</member>
        <member name="T:AVFrameSideData">
 Structure to hold side data for an AVFrame.

 sizeof(AVFrameSideData) is not a part of the public ABI, so new fields may be added
 to the end with a minor bump.

</member>
        <member name="T:AVFrameSideDataType">
@}
@}

 @defgroup lavu_frame AVFrame
 @ingroup lavu_data

 @{
 AVFrame is an abstraction for reference-counted raw multimedia data.


 Add a new side data to a frame.

 @param frame a frame to which the side data should be added
 @param type type of the added side data
 @param size size of the side data

 @return newly added side data on success, NULL on error


 Add a new side data to a frame from an existing AVBufferRef

 @param frame a frame to which the side data should be added
 @param type  the type of the added side data
 @param buf   an AVBufferRef to add as side data. The ownership of
              the reference is transferred to the frame.

 @return newly added side data on success, NULL on error. On failure
         the frame is unchanged and the AVBufferRef remains owned by
         the caller.


@return a pointer to the side data of a given type on success, NULL if there
is no side data with such type in this frame.


Remove and free all side data instances of the given type.


@return a string identifying the side data type

</member>
        <member name="F:AV_FRAME_DATA_DYNAMIC_HDR_VIVID">
HDR Vivid dynamic metadata associated with a video frame. The payload is
an AVDynamicHDRVivid type and contains information for color
volume transform - CUVA 005.1-2021.

</member>
        <member name="F:AV_FRAME_DATA_DOVI_METADATA">
Parsed Dolby Vision metadata, suitable for passing to a software
implementation. The payload is the AVDOVIMetadata struct defined in
libavutil/dovi_meta.h.

</member>
        <member name="F:AV_FRAME_DATA_DOVI_RPU_BUFFER">
Dolby Vision RPU raw data, suitable for passing to x265
or other libraries. Array of uint8_t, with NAL emulation
bytes intact.

</member>
        <member name="F:AV_FRAME_DATA_DETECTION_BBOXES">
Bounding boxes for object detection and classification,
as described by AVDetectionBBoxHeader.

</member>
        <member name="F:AV_FRAME_DATA_FILM_GRAIN_PARAMS">
Film grain parameters for a frame, described by AVFilmGrainParams.
Must be present for every frame which should have film grain applied.

</member>
        <member name="F:AV_FRAME_DATA_SEI_UNREGISTERED">
User data unregistered metadata associated with a video frame.
This is the H.26[45] UDU SEI message, and shouldn't be used for any other purpose
The data is stored as uint8_t in AVFrameSideData.data which is 16 bytes of
uuid_iso_iec_11578 followed by AVFrameSideData.size - 16 bytes of user_data_payload_byte.

</member>
        <member name="F:AV_FRAME_DATA_VIDEO_ENC_PARAMS">
Encoding parameters for a video frame, as described by AVVideoEncParams.

</member>
        <member name="F:AV_FRAME_DATA_REGIONS_OF_INTEREST">
Regions Of Interest, the data is an array of AVRegionOfInterest type, the number of
array element is implied by AVFrameSideData.size / AVRegionOfInterest.self_size.

</member>
        <member name="F:AV_FRAME_DATA_DYNAMIC_HDR_PLUS">
HDR dynamic metadata associated with a video frame. The payload is
an AVDynamicHDRPlus type and contains information for color
volume transform - application 4 of SMPTE 2094-40:2016 standard.

</member>
        <member name="F:AV_FRAME_DATA_S12M_TIMECODE">
Timecode which conforms to SMPTE ST 12-1. The data is an array of 4 uint32_t
where the first uint32_t describes how many (1-3) of the other timecodes are used.
The timecode format is described in the documentation of av_timecode_get_smpte_from_framenum()
function in libavutil/timecode.h.

</member>
        <member name="F:AV_FRAME_DATA_ICC_PROFILE">
The data contains an ICC profile as an opaque octet buffer following the
format described by ISO 15076-1 with an optional name defined in the
metadata key entry "name".

</member>
        <member name="F:AV_FRAME_DATA_CONTENT_LIGHT_LEVEL">
Content light level (based on CTA-861.3). This payload contains data in
the form of the AVContentLightMetadata struct.

</member>
        <member name="F:AV_FRAME_DATA_SPHERICAL">
The data represents the AVSphericalMapping structure defined in
libavutil/spherical.h.

</member>
        <member name="F:AV_FRAME_DATA_GOP_TIMECODE">
The GOP timecode in 25 bit timecode format. Data format is 64-bit integer.
This is set on the first frame of a GOP that has a temporal reference of 0.

</member>
        <member name="F:AV_FRAME_DATA_MASTERING_DISPLAY_METADATA">
Mastering display metadata associated with a video frame. The payload is
an AVMasteringDisplayMetadata type and contains information about the
mastering display color volume.

</member>
        <member name="F:AV_FRAME_DATA_AUDIO_SERVICE_TYPE">
This side data must be associated with an audio frame and corresponds to
enum AVAudioServiceType defined in avcodec.h.

</member>
        <member name="F:AV_FRAME_DATA_SKIP_SAMPLES">
Recommmends skipping the specified number of samples. This is exported
only if the "skip_manual" AVOption is set in libavcodec.
This has the same format as AV_PKT_DATA_SKIP_SAMPLES.
@code
u32le number of samples to skip from start of this packet
u32le number of samples to skip from end of this packet
u8    reason for start skip
u8    reason for end   skip (0=padding silence, 1=convergence)
@endcode

</member>
        <member name="F:AV_FRAME_DATA_MOTION_VECTORS">
Motion vectors exported by some codecs (on demand through the export_mvs
flag set in the libavcodec AVCodecContext flags2 option).
The data is the AVMotionVector struct defined in
libavutil/motion_vector.h.

</member>
        <member name="F:AV_FRAME_DATA_AFD">
Active Format Description data consisting of a single byte as specified
in ETSI TS 101 154 using AVActiveFormatDescription enum.

</member>
        <member name="F:AV_FRAME_DATA_DISPLAYMATRIX">
 This side data contains a 3x3 transformation matrix describing an affine
 transformation that needs to be applied to the frame for correct
 presentation.

 See libavutil/display.h for a detailed description of the data.

</member>
        <member name="F:AV_FRAME_DATA_REPLAYGAIN">
ReplayGain information in the form of the AVReplayGain struct.

</member>
        <member name="F:AV_FRAME_DATA_DOWNMIX_INFO">
Metadata relevant to a downmix procedure.
The data is the AVDownmixInfo struct defined in libavutil/downmix_info.h.

</member>
        <member name="F:AV_FRAME_DATA_MATRIXENCODING">
The data is the AVMatrixEncoding enum defined in libavutil/channel_layout.h.

</member>
        <member name="F:AV_FRAME_DATA_STEREO3D">
Stereoscopic 3d metadata.
The data is the AVStereo3D struct defined in libavutil/stereo3d.h.

</member>
        <member name="F:AV_FRAME_DATA_A53_CC">
ATSC A53 Part 4 Closed Captions.
A53 CC bitstream is stored as uint8_t in AVFrameSideData.data.
The number of bytes of CC data is AVFrameSideData.size.

</member>
        <member name="F:AV_FRAME_DATA_PANSCAN">
The data is the AVPanScan struct defined in libavcodec.

</member>
        <member name="M:av_channel_layout_compare(AVChannelLayout,AVChannelLayout)">
 Check whether two channel layouts are semantically the same, i.e. the same
 channels are present on the same positions in both.

 If one of the channel layouts is AV_CHANNEL_ORDER_UNSPEC, while the other is
 not, they are considered to be unequal. If both are AV_CHANNEL_ORDER_UNSPEC,
 they are considered equal iff the channel counts are the same in both.

 @param chl input channel layout
 @param chl1 input channel layout
 @return 0 if chl and chl1 are equal, 1 if they are not equal. A negative
         AVERROR code if one or both are invalid.

</member>
        <member name="M:av_channel_layout_check(AVChannelLayout)">
 Check whether a channel layout is valid, i.e. can possibly describe audio
 data.

 @param channel_layout input channel layout
 @return 1 if channel_layout is valid, 0 otherwise.

</member>
        <member name="M:av_channel_layout_subset(AVChannelLayout,System.UInt64)">
 Find out what channels from a given set are present in a channel layout,
 without regard for their positions.

 @param channel_layout input channel layout
 @param mask a combination of AV_CH_* representing a set of channels
 @return a bitfield representing all the channels from mask that are present
         in channel_layout

</member>
        <member name="M:av_channel_layout_index_from_string(AVChannelLayout,System.SByte!System.Runtime.CompilerServices.IsSignUnspecifiedByte)">
 Get the index in a channel layout of a channel described by the given string.
 In case multiple channels are found, only the first match will be returned.

 This function accepts channel names in the same format as
 @ref av_channel_from_string().

 @param channel_layout input channel layout
 @return a channel index described by the given string, or a negative AVERROR
         value.

</member>
        <member name="M:av_channel_layout_describe(AVChannelLayout,System.SByte!System.Runtime.CompilerServices.IsSignUnspecifiedByte*,System.UInt64)">
 Get a human-readable string describing the channel layout properties.
 The string will be in the same format that is accepted by
 @ref av_channel_layout_from_string(), allowing to rebuild the same
 channel layout, except for opaque pointers.

 @param channel_layout channel layout to be described
 @param buf pre-allocated buffer where to put the generated string
 @param buf_size size in bytes of the buffer.
 @return amount of bytes needed to hold the output string, or a negative AVERROR
         on failure. If the returned value is bigger than buf_size, then the
         string was truncated.

</member>
        <member name="M:av_channel_layout_copy(AVChannelLayout*,AVChannelLayout)">
 Make a copy of a channel layout. This differs from just assigning src to dst
 in that it allocates and copies the map for AV_CHANNEL_ORDER_CUSTOM.

 @note the destination channel_layout will be always uninitialized before copy.

 @param dst destination channel layout
 @param src source channel layout
 @return 0 on success, a negative AVERROR on error.

</member>
        <member name="M:av_channel_layout_uninit(AVChannelLayout*)">
 Free any allocated data in the channel layout and reset the channel
 count to 0.

 @param channel_layout the layout structure to be uninitialized

</member>
        <member name="M:av_channel_layout_standard(System.Void**)">
 Iterate over all standard channel layouts.

 @param opaque a pointer where libavutil will store the iteration state. Must
               point to NULL to start the iteration.

 @return the standard channel layout or NULL when the iteration is
         finished

</member>
        <member name="M:av_channel_layout_default(AVChannelLayout*,System.Int32)">
 Get the default channel layout for a given number of channels.

 @param channel_layout the layout structure to be initialized
 @param nb_channels number of channels

</member>
        <member name="M:av_channel_layout_from_string(AVChannelLayout*,System.SByte!System.Runtime.CompilerServices.IsSignUnspecifiedByte)">
 Initialize a channel layout from a given string description.
 The input string can be represented by:
  - the formal channel layout name (returned by av_channel_layout_describe())
  - single or multiple channel names (returned by av_channel_name(), eg. "FL",
    or concatenated with "+", each optionally containing a custom name after
    a "@", eg. "FL@Left+FR@Right+LFE")
  - a decimal or hexadecimal value of a native channel layout (eg. "4" or "0x4")
  - the number of channels with default layout (eg. "4c")
  - the number of unordered channels (eg. "4C" or "4 channels")
  - the ambisonic order followed by optional non-diegetic channels (eg.
    "ambisonic 2+stereo")

 @param channel_layout input channel layout
 @param str string describing the channel layout
 @return 0 channel layout was detected, AVERROR_INVALIDATATA otherwise

</member>
        <member name="M:av_channel_layout_from_mask(AVChannelLayout*,System.UInt64)">
 Initialize a native channel layout from a bitmask indicating which channels
 are present.

 @param channel_layout the layout structure to be initialized
 @param mask bitmask describing the channel layout

 @return 0 on success
         AVERROR(EINVAL) for invalid mask values

</member>
        <member name="M:av_get_channel_description(System.UInt64)">
 Get the description of a given channel.

 @param channel  a channel layout with a single channel
 @return  channel description on success, NULL on error
 @deprecated use av_channel_description()

</member>
        <member name="M:av_get_channel_name(System.UInt64)">
 Get the name of a given channel.

 @return channel name on success, NULL on error.

 @deprecated use av_channel_name()

</member>
        <member name="M:av_channel_layout_extract_channel(System.UInt64,System.Int32)">
Get the channel with the given index in channel_layout.
@deprecated use av_channel_layout_channel_from_index()

</member>
        <member name="M:av_get_channel_layout_channel_index(System.UInt64,System.UInt64)">
 Get the index of a channel in channel_layout.

 @param channel a channel layout describing exactly one channel which must be
                present in channel_layout.

 @return index of channel in channel_layout on success, a negative AVERROR
         on error.

 @deprecated use av_channel_layout_index_from_channel()

</member>
        <member name="M:av_get_default_channel_layout(System.Int32)">
 Return default channel layout for a given number of channels.

 @deprecated use av_channel_layout_default()

</member>
        <member name="M:av_get_channel_layout_nb_channels(System.UInt64)">
Return the number of channels in the channel layout.
@deprecated use AVChannelLayout.nb_channels

</member>
        <member name="T:AVBPrint">
Append a description of a channel layout to a bprint buffer.
@deprecated use av_channel_layout_describe()


 bprint variant of av_channel_name().

 @note the string will be appended to the bprint buffer.


 bprint variant of av_channel_description().

 @note the string will be appended to the bprint buffer.


 bprint variant of av_channel_layout_describe().

 @note the string will be appended to the bprint buffer.
 @return 0 on success, or a negative AVERROR value on failure.


 Read contents of h into print buffer, up to max_size bytes, or up to EOF.

 @return 0 for success (max_size bytes read or EOF reached), negative error
 code otherwise

</member>
        <member name="M:av_get_extended_channel_layout(System.SByte!System.Runtime.CompilerServices.IsSignUnspecifiedByte,System.UInt64*,System.Int32*)">
 Return a channel layout and the number of channels based on the specified name.

 This function is similar to (@see av_get_channel_layout), but can also parse
 unknown channel layout specifications.

 @param[in]  name             channel layout specification string
 @param[out] channel_layout   parsed channel layout (0 if unknown)
 @param[out] nb_channels      number of channels

 @return 0 on success, AVERROR(EINVAL) if the parsing fails.
 @deprecated use av_channel_layout_from_string()

</member>
        <member name="M:av_get_channel_layout(System.SByte!System.Runtime.CompilerServices.IsSignUnspecifiedByte)">
 Return a channel layout id that matches name, or 0 if no match is found.

 name can be one or several of the following notations,
 separated by '+' or '|':
 - the name of an usual channel layout (mono, stereo, 4.0, quad, 5.0,
   5.0(side), 5.1, 5.1(side), 7.1, 7.1(wide), downmix);
 - the name of a single channel (FL, FR, FC, LFE, BL, BR, FLC, FRC, BC,
   SL, SR, TC, TFL, TFC, TFR, TBL, TBC, TBR, DL, DR);
 - a number of channels, in decimal, followed by 'c', yielding
   the default channel layout for that number of channels (@see
   av_get_default_channel_layout);
 - a channel layout mask, in hexadecimal starting with "0x" (see the
   AV_CH_* macros).

 Example: "stereo+FC" = "2c+FC" = "2c+1c" = "0x7"

 @deprecated use av_channel_layout_from_string()

</member>
        <member name="F:AVChannelLayout.opaque">
For some private data of the user.

</member>
        <member name="F:AVChannelLayout.nb_channels">
Number of channels in this layout. Mandatory field.

</member>
        <member name="T:AVChannelOrder">
Channel order used in this layout.
This is a mandatory field.

</member>
        <member name="T:AVChannelLayout">
 An AVChannelLayout holds information about the channel layout of audio data.

 A channel layout here is defined as a set of channels ordered in a specific
 way (unless the channel order is AV_CHANNEL_ORDER_UNSPEC, in which case an
 AVChannelLayout carries only the channel count).

 Unlike most structures in Libav, sizeof(AVChannelLayout) is a part of the
 public ABI and may be used by the caller. E.g. it may be allocated on stack
 or embedded in caller-defined structs.

 AVChannelLayout can be initialized as follows:
 - default initialization with {0}, followed by setting all used fields
   correctly;
 - by assigning one of the predefined AV_CHANNEL_LAYOUT_* initializers;
 - with a constructor function, such as av_channel_layout_default(),
   av_channel_layout_from_mask() or av_channel_layout_from_string().

 The channel layout must be unitialized with av_channel_layout_uninit()

 Copying an AVChannelLayout via assigning is forbidden,
 av_channel_layout_copy() must be used instead (and its return value should
 be checked)

 No new fields may be added to it without a major version bump, except for
 new elements of the union fitting in sizeof(uint64_t).

</member>
        <member name="T:AVChannelCustom">
@}

 An AVChannelCustom defines a single channel within a custom order layout

 Unlike most structures in FFmpeg, sizeof(AVChannelCustom) is a part of the
 public ABI.

 No new fields may be added to it without a major version bump.

</member>
        <member name="T:AVMatrixEncoding">
 @defgroup channel_masks Audio channel masks

 A channel layout is a 64-bits integer with a bit set for every channel.
 The number of bits set must be equal to the number of channels.
 The value 0 means that the channel layout is not known.
 @note this data structure is not powerful enough to handle channels
 combinations that have the same channel multiple times, such as
 dual-mono.

 @{

Channel mask value used for AVCodecContext.request_channel_layout
    to indicate that the user requests the channel order of the decoder output
    to be the native codec channel order.
    @deprecated channel order is now indicated in a special field in
                AVChannelLayout

@}
@defgroup channel_mask_c Audio channel layouts
@{

</member>
        <member name="F:AV_CHANNEL_ORDER_AMBISONIC">
 The audio is represented as the decomposition of the sound field into
 spherical harmonics. Each channel corresponds to a single expansion
 component. Channels are ordered according to ACN (Ambisonic Channel
 Number).

 The channel with the index n in the stream contains the spherical
 harmonic of degree l and order m given by
 @code{.unparsed}
   l   = floor(sqrt(n)),
   m   = n - l * (l + 1).
 @endcode

 Conversely given a spherical harmonic of degree l and order m, the
 corresponding channel index n is given by
 @code{.unparsed}
   n = l * (l + 1) + m.
 @endcode

 Normalization is assumed to be SN3D (Schmidt Semi-Normalization)
 as defined in AmbiX format $ 2.1.

</member>
        <member name="F:AV_CHANNEL_ORDER_CUSTOM">
The channel order does not correspond to any other predefined order and
is stored as an explicit map. For example, this could be used to support
layouts with 64 or more channels, or with empty/skipped (AV_CHAN_SILENCE)
channels at arbitrary positions.

</member>
        <member name="F:AV_CHANNEL_ORDER_NATIVE">
The native channel order, i.e. the channels are in the same order in
which they are defined in the AVChannel enum. This supports up to 63
different channels.

</member>
        <member name="F:AV_CHANNEL_ORDER_UNSPEC">
Only the channel count is specified, without any further information
about the channel order.

</member>
        <member name="T:AVChannel">
@}

@file
@ingroup lavu_frame
reference-counted frame API

@file
audio channel layout utility functions

@addtogroup lavu_audio
@{


 Get a human readable string in an abbreviated form describing a given channel.
 This is the inverse function of @ref av_channel_from_string().

 @param buf pre-allocated buffer where to put the generated string
 @param buf_size size in bytes of the buffer.
 @return amount of bytes needed to hold the output string, or a negative AVERROR
         on failure. If the returned value is bigger than buf_size, then the
         string was truncated.


 Get a human readable string describing a given channel.

 @param buf pre-allocated buffer where to put the generated string
 @param buf_size size in bytes of the buffer.
 @return amount of bytes needed to hold the output string, or a negative AVERROR
         on failure. If the returned value is bigger than buf_size, then the
         string was truncated.


 This is the inverse function of @ref av_channel_name().

 @return the channel with the given name
         AV_CHAN_NONE when name does not identify a known channel


 Get the channel with the given index in a channel layout.

 @param channel_layout input channel layout
 @return channel with the index idx in channel_layout on success or
         AV_CHAN_NONE on failure (if idx is not valid or the channel order is
         unspecified)


 Get the index of a given channel in a channel layout. In case multiple
 channels are found, only the first match will be returned.

 @param channel_layout input channel layout
 @return index of channel in channel_layout on success or a negative number if
         channel is not present in channel_layout.


 Get a channel described by the given string.

 This function accepts channel names in the same format as
 @ref av_channel_from_string().

 @param channel_layout input channel layout
 @return a channel described by the given string in channel_layout on success
         or AV_CHAN_NONE on failure (if the string is not valid or the channel
         order is unspecified)

</member>
        <member name="F:AV_CHAN_UNKNOWN">
Channel contains data, but its position is unknown. 
</member>
        <member name="F:AV_CHAN_UNUSED">
Channel is empty can be safely skipped. 
</member>
        <member name="F:AV_CHAN_STEREO_RIGHT">
See above. 
</member>
        <member name="F:AV_CHAN_STEREO_LEFT">
Stereo downmix. 
</member>
        <member name="M:av_dict_get_string(AVDictionary,System.SByte!System.Runtime.CompilerServices.IsSignUnspecifiedByte**,System.SByte!System.Runtime.CompilerServices.IsSignUnspecifiedByte!System.Runtime.CompilerServices.IsConst,System.SByte!System.Runtime.CompilerServices.IsSignUnspecifiedByte!System.Runtime.CompilerServices.IsConst)">
 Get dictionary entries as a string.

 Create a string containing dictionary's entries.
 Such string may be passed back to av_dict_parse_string().
 @note String is escaped with backslashes ('\').

 @param[in]  m             dictionary
 @param[out] buffer        Pointer to buffer that will be allocated with string containg entries.
                           Buffer must be freed by the caller when is no longer needed.
 @param[in]  key_val_sep   character used to separate key from value
 @param[in]  pairs_sep     character used to separate two pairs from each other
 @return                   &gt;= 0 on success, negative on error
 @warning Separators cannot be neither '\\' nor '\0'. They also cannot be the same.

</member>
        <member name="M:av_dict_free(AVDictionary**)">
Free all the memory allocated for an AVDictionary struct
and all keys and values.

</member>
        <member name="M:av_dict_copy(AVDictionary**,AVDictionary,System.Int32)">
Copy entries from one AVDictionary struct into another.
@param dst pointer to a pointer to a AVDictionary struct. If *dst is NULL,
           this function will allocate a struct for you and put it in *dst
@param src pointer to source AVDictionary struct
@param flags flags to use when setting entries in *dst
@note metadata is read using the AV_DICT_IGNORE_SUFFIX flag
@return 0 on success, negative AVERROR code on failure. If dst was allocated
          by this function, callers should free the associated memory.

</member>
        <member name="M:av_dict_parse_string(AVDictionary**,System.SByte!System.Runtime.CompilerServices.IsSignUnspecifiedByte,System.SByte!System.Runtime.CompilerServices.IsSignUnspecifiedByte,System.SByte!System.Runtime.CompilerServices.IsSignUnspecifiedByte,System.Int32)">
 Parse the key/value pairs list and add the parsed entries to a dictionary.

 In case of failure, all the successfully set entries are stored in
 *pm. You may need to manually free the created dictionary.

 @param key_val_sep  a 0-terminated list of characters used to separate
                     key from value
 @param pairs_sep    a 0-terminated list of characters used to separate
                     two pairs from each other
 @param flags        flags to use when adding to dictionary.
                     AV_DICT_DONT_STRDUP_KEY and AV_DICT_DONT_STRDUP_VAL
                     are ignored since the key/value tokens will always
                     be duplicated.
 @return             0 on success, negative AVERROR code on failure

</member>
        <member name="M:av_dict_set_int(AVDictionary**,System.SByte!System.Runtime.CompilerServices.IsSignUnspecifiedByte,System.Int64,System.Int32)">
 Convenience wrapper for av_dict_set that converts the value to a string
 and stores it.

 Note: If AV_DICT_DONT_STRDUP_KEY is set, key will be freed on error.

</member>
        <member name="M:av_dict_count(AVDictionary)">
 Get number of entries in dictionary.

 @param m dictionary
 @return  number of entries in dictionary

</member>
        <member name="M:av_dict_get(AVDictionary,System.SByte!System.Runtime.CompilerServices.IsSignUnspecifiedByte,AVDictionaryEntry,System.Int32)">
 Get a dictionary entry with matching key.

 The returned entry key or value must not be changed, or it will
 cause undefined behavior.

 To iterate through all the dictionary entries, you can set the matching key
 to the null string "" and set the AV_DICT_IGNORE_SUFFIX flag.

 @param prev Set to the previous matching element to find the next.
             If set to NULL the first matching element is returned.
 @param key matching key
 @param flags a collection of AV_DICT_* flags controlling how the entry is retrieved
 @return found entry or NULL in case no matching entry was found in the dictionary

</member>
        <member name="M:av_buffer_pool_buffer_get_opaque(AVBufferRef)">
 Query the original opaque parameter of an allocated buffer in the pool.

 @param ref a buffer reference to a buffer returned by av_buffer_pool_get.
 @return the opaque parameter set by the buffer allocator function of the
         buffer pool.

 @note the opaque parameter of ref is used by the buffer pool implementation,
 therefore you have to use this function to access the original opaque
 parameter of an allocated buffer.

</member>
        <member name="M:av_buffer_pool_get(AVBufferPool*)">
 Allocate a new AVBuffer, reusing an old buffer from the pool when available.
 This function may be called simultaneously from multiple threads.

 @return a reference to the new buffer on success, NULL on error.

</member>
        <member name="M:av_buffer_pool_uninit(AVBufferPool**)">
 Mark the pool as being available for freeing. It will actually be freed only
 once all the allocated buffers associated with the pool are released. Thus it
 is safe to call this function while some of the allocated buffers are still
 in use.

 @param pool pointer to the pool to be freed. It will be set to NULL.

</member>
        <member name="M:av_buffer_pool_init2(System.UInt64,System.Void*,=FUNC:AVBufferRef*(System.Void*,System.UInt64),=FUNC:System.Void(System.Void*))">
 Allocate and initialize a buffer pool with a more complex allocator.

 @param size size of each buffer in this pool
 @param opaque arbitrary user data used by the allocator
 @param alloc a function that will be used to allocate new buffers when the
              pool is empty. May be NULL, then the default allocator will be
              used (av_buffer_alloc()).
 @param pool_free a function that will be called immediately before the pool
                  is freed. I.e. after av_buffer_pool_uninit() is called
                  by the caller and all the frames are returned to the pool
                  and freed. It is intended to uninitialize the user opaque
                  data. May be NULL.
 @return newly created buffer pool on success, NULL on error.

</member>
        <member name="M:av_buffer_pool_init(System.UInt64,=FUNC:AVBufferRef*(System.UInt64))">
 Allocate and initialize a buffer pool.

 @param size size of each buffer in this pool
 @param alloc a function that will be used to allocate new buffers when the
 pool is empty. May be NULL, then the default allocator will be used
 (av_buffer_alloc()).
 @return newly created buffer pool on success, NULL on error.

</member>
        <member name="T:AVBufferPool">
@}

 @defgroup lavu_bufferpool AVBufferPool
 @ingroup lavu_data

 @{
 AVBufferPool is an API for a lock-free thread-safe pool of AVBuffers.

 Frequently allocating and freeing large buffers may be slow. AVBufferPool is
 meant to solve this in cases when the caller needs a set of buffers of the
 same size (the most obvious use case being buffers for raw video or audio
 frames).

 At the beginning, the user must call av_buffer_pool_init() to create the
 buffer pool. Then whenever a buffer is needed, call av_buffer_pool_get() to
 get a reference to a new buffer, similar to av_buffer_alloc(). This new
 reference works in all aspects the same way as the one created by
 av_buffer_alloc(). However, when the last reference to this buffer is
 unreferenced, it is returned to the pool instead of being freed and will be
 reused for subsequent av_buffer_pool_get() calls.

 When the caller is done with the pool and no longer needs to allocate any new
 buffers, av_buffer_pool_uninit() must be called to mark the pool as freeable.
 Once all the buffers are released, it will automatically be freed.

 Allocating and releasing buffers with this API is thread-safe as long as
 either the default alloc callback is used, or the user-supplied one is
 thread-safe.

The buffer pool. This structure is opaque and not meant to be accessed
directly. It is allocated with av_buffer_pool_init() and freed with
av_buffer_pool_uninit().

</member>
        <member name="M:av_buffer_replace(AVBufferRef**,AVBufferRef)">
 Ensure dst refers to the same data as src.

 When *dst is already equivalent to src, do nothing. Otherwise unreference dst
 and replace it with a new reference to src.

 @param dst Pointer to either a valid buffer reference or NULL. On success,
            this will point to a buffer reference equivalent to src. On
            failure, dst will be left untouched.
 @param src A buffer reference to replace dst with. May be NULL, then this
            function is equivalent to av_buffer_unref(dst).
 @return 0 on success
         AVERROR(ENOMEM) on memory allocation failure.

</member>
        <member name="M:av_buffer_realloc(AVBufferRef**,System.UInt64)">
 Reallocate a given buffer.

 @param buf  a buffer reference to reallocate. On success, buf will be
             unreferenced and a new reference with the required size will be
             written in its place. On failure buf will be left untouched. *buf
             may be NULL, then a new buffer is allocated.
 @param size required new buffer size.
 @return 0 on success, a negative AVERROR on failure.

 @note the buffer is actually reallocated with av_realloc() only if it was
 initially allocated through av_buffer_realloc(NULL) and there is only one
 reference to it (i.e. the one passed to this function). In all other cases
 a new buffer is allocated and the data is copied.

</member>
        <member name="M:av_buffer_make_writable(AVBufferRef**)">
 Create a writable reference from a given buffer reference, avoiding data copy
 if possible.

 @param buf buffer reference to make writable. On success, buf is either left
            untouched, or it is unreferenced and a new writable AVBufferRef is
            written in its place. On failure, buf is left untouched.
 @return 0 on success, a negative AVERROR on failure.

</member>
        <member name="M:av_buffer_get_opaque(AVBufferRef)">
@return the opaque parameter set by av_buffer_create.

</member>
        <member name="M:av_buffer_is_writable(AVBufferRef)">
@return 1 if the caller may write to the data referred to by buf (which is
true if and only if buf is the only reference to the underlying AVBuffer).
Return 0 otherwise.
A positive answer is valid until av_buffer_ref() is called on buf.

</member>
        <member name="M:av_buffer_unref(AVBufferRef**)">
 Free a given reference and automatically free the buffer if there are no more
 references to it.

 @param buf the reference to be freed. The pointer is set to NULL on return.

</member>
        <member name="M:av_buffer_ref(AVBufferRef)">
 Create a new reference to an AVBuffer.

 @return a new AVBufferRef referring to the same AVBuffer as buf or NULL on
 failure.

</member>
        <member name="M:av_buffer_default_free(System.Void*,System.Byte*)">
Default free callback, which calls av_free() on the buffer data.
This function is meant to be passed to av_buffer_create(), not called
directly.

</member>
        <member name="M:av_buffer_create(System.Byte*,System.UInt64,=FUNC:System.Void(System.Void*,System.Byte*),System.Void*,System.Int32)">
Always treat the buffer as read-only, even when it has only one
reference.

 Create an AVBuffer from an existing array.

 If this function is successful, data is owned by the AVBuffer. The caller may
 only access data through the returned AVBufferRef and references derived from
 it.
 If this function fails, data is left untouched.
 @param data   data array
 @param size   size of data in bytes
 @param free   a callback for freeing this buffer's data
 @param opaque parameter to be got for processing or passed to free
 @param flags  a combination of AV_BUFFER_FLAG_*

 @return an AVBufferRef referring to data on success, NULL on failure.

</member>
        <member name="M:av_buffer_allocz(System.UInt64)">
Same as av_buffer_alloc(), except the returned buffer will be initialized
to zero.

</member>
        <member name="M:av_buffer_alloc(System.UInt64)">
 Allocate an AVBuffer of the given size using av_malloc().

 @return an AVBufferRef of given size or NULL when out of memory

</member>
        <member name="F:AVBufferRef.size">
Size of data in bytes.

</member>
        <member name="F:AVBufferRef.data">
The data buffer. It is considered writable if and only if
this is the only reference to the buffer, in which case
av_buffer_is_writable() returns 1.

</member>
        <member name="T:AVBufferRef">
 A reference to a data buffer.

 The size of this struct is not a part of the public ABI and it is not meant
 to be allocated directly.

</member>
        <member name="T:AVBuffer">
@}
@}

@file
@ingroup lavu_buffer
refcounted data buffer API

 @defgroup lavu_buffer AVBuffer
 @ingroup lavu_data

 @{
 AVBuffer is an API for reference-counted data buffers.

 There are two core objects in this API -- AVBuffer and AVBufferRef. AVBuffer
 represents the data buffer itself; it is opaque and not meant to be accessed
 by the caller directly, but only through AVBufferRef. However, the caller may
 e.g. compare two AVBuffer pointers to check whether two different references
 are describing the same data buffer. AVBufferRef represents a single
 reference to an AVBuffer and it is the object that may be manipulated by the
 caller directly.

 There are two functions provided for creating a new AVBuffer with a single
 reference -- av_buffer_alloc() to just allocate a new buffer, and
 av_buffer_create() to wrap an existing array in an AVBuffer. From an existing
 reference, additional references may be created with av_buffer_ref().
 Use av_buffer_unref() to free a reference (this will automatically free the
 data once all the references are freed).

 The convention throughout this API and the rest of FFmpeg is such that the
 buffer is considered writable if there exists only one reference to it (and
 it has not been marked as read-only). The av_buffer_is_writable() function is
 provided to check whether this is true and av_buffer_make_writable() will
 automatically create a new writable buffer when necessary.
 Of course nothing prevents the calling code from violating this convention,
 however that is safe only when all the existing references are under its
 control.

 @note Referencing and unreferencing the buffers is thread-safe and thus
 may be done from multiple threads simultaneously without any need for
 additional locking.

 @note Two different references to the same buffer can point to different
 parts of the buffer (i.e. their AVBufferRef.data will not be equal).

A reference counted buffer type. It is opaque and is meant to be used through
references (AVBufferRef).

</member>
        <member name="M:av_fourcc_make_string(System.SByte!System.Runtime.CompilerServices.IsSignUnspecifiedByte*,System.UInt32)">
 Fill the provided buffer with a string containing a FourCC (four-character
 code) representation.

 @param buf    a buffer with size in bytes of at least AV_FOURCC_MAX_STRING_SIZE
 @param fourcc the fourcc to represent
 @return the buffer in input

</member>
        <member name="M:av_get_time_base_q">
Return the fractional representation of the internal time base.

</member>
        <member name="M:av_fopen_utf8(System.SByte!System.Runtime.CompilerServices.IsSignUnspecifiedByte,System.SByte!System.Runtime.CompilerServices.IsSignUnspecifiedByte)">
 Compute the length of an integer list.

 @param term  list terminator (usually 0 or -1)
 @param list  pointer to the list
 @return  length of the list, in elements, not counting the terminator

Open a file using a UTF-8 filename.
The API of this function matches POSIX fopen(), errors are returned through
errno.
@deprecated Avoid using it, as on Windows, the FILE* allocated by this
            function may be allocated with a different CRT than the caller
            who uses the FILE*. No replacement provided in public API.

</member>
        <member name="M:av_int_list_length_for_size(System.UInt32,System.Void,System.UInt64)">
 Compute the length of an integer list.

 @param elsize  size in bytes of each list element (only 1, 2, 4 or 8)
 @param term    list terminator (usually 0 or -1)
 @param list    pointer to the list
 @return  length of the list, in elements, not counting the terminator

</member>
        <member name="M:av_x_if_null(System.Void,System.Void)">
Return x default pointer in case p is NULL.

</member>
        <member name="T:AVChromaLocation">
 Location of chroma samples.

 Illustration showing the location of the first (top left) chroma sample of the
 image, the left shows only luma, the right
 shows the location of the chroma sample, the 2 could be imagined to overlay
 each other but are drawn separately due to limitations of ASCII

                1st 2nd       1st 2nd horizontal luma sample positions
                 v   v         v   v
                 ______        ______
1st luma line &gt; |X   X ...    |3 4 X ...     X are luma samples,
                |             |1 2           1-6 are possible chroma positions
2nd luma line &gt; |X   X ...    |5 6 X ...     0 is undefined/unknown position


@return the name for provided chroma location or NULL if unknown.

</member>
        <member name="T:AVColorRange">
 Visual content value range.

 These values are based on definitions that can be found in multiple
 specifications, such as ITU-T BT.709 (3.4 - Quantization of RGB, luminance
 and colour-difference signals), ITU-T BT.2020 (Table 5 - Digital
 Representation) as well as ITU-T BT.2100 (Table 9 - Digital 10- and 12-bit
 integer representation). At the time of writing, the BT.2100 one is
 recommended, as it also defines the full range representation.

 Common definitions:
   - For RGB and luma planes such as Y in YCbCr and I in ICtCp,
     'E' is the original value in range of 0.0 to 1.0.
   - For chroma planes such as Cb,Cr and Ct,Cp, 'E' is the original
     value in range of -0.5 to 0.5.
   - 'n' is the output bit depth.
   - For additional definitions such as rounding and clipping to valid n
     bit unsigned integer range, please refer to BT.2100 (Table 9).


MPEG vs JPEG YUV range.
- encoding: Set by user
- decoding: Set by libavcodec


Video only. Additional colorspace characteristics.


@return the name for provided color range or NULL if unknown.

</member>
        <member name="F:AVCOL_RANGE_JPEG">
 Full range content.

 - For RGB and luma planes:

       (2^n - 1) * E

   F.ex. the range of 0-255 for 8 bits

 - For chroma planes:

       (2^n - 1) * E + 2^(n - 1)

   F.ex. the range of 1-255 for 8 bits

</member>
        <member name="F:AVCOL_RANGE_MPEG">
 Narrow or limited range content.

 - For luma planes:

       (219 * E + 16) * 2^(n-8)

   F.ex. the range of 16-235 for 8 bits

 - For chroma planes:

       (224 * E + 128) * 2^(n-8)

   F.ex. the range of 16-240 for 8 bits

</member>
        <member name="T:AVColorSpace">
YUV colorspace type.
These values match the ones defined by ISO/IEC 23091-2_2019 subclause 8.3.


YUV colorspace type.
- encoding: Set by user
- decoding: Set by libavcodec


Get the name of a colorspace.
@return a static string identifying the colorspace; can be NULL.
@deprecated use av_color_space_name()


@return the name for provided color space or NULL if unknown.

</member>
        <member name="T:AVColorTransferCharacteristic">
Color Transfer Characteristic.
These values match the ones defined by ISO/IEC 23091-2_2019 subclause 8.2.


@return the name for provided color transfer or NULL if unknown.

</member>
        <member name="T:AVColorPrimaries">
Chromaticity coordinates of the source primaries.
These values match the ones defined by ISO/IEC 23091-2_2019 subclause 8.1 and ITU-T H.273.


@return the name for provided color primaries or NULL if unknown.

</member>
        <member name="F:AV_PIX_FMT_VULKAN">
 Vulkan hardware images.

 data[0] points to an AVVkFrame

</member>
        <member name="F:AV_PIX_FMT_OPENCL">
 Hardware surfaces for OpenCL.

 data[i] contain 2D image objects (typed in C as cl_mem, used
 in OpenCL as image2d_t) for each plane of the surface.

</member>
        <member name="F:AV_PIX_FMT_DRM_PRIME">
 DRM-managed buffers exposed through PRIME buffer sharing.

 data[0] points to an AVDRMFrameDescriptor.

</member>
        <member name="F:AV_PIX_FMT_D3D11">
 Hardware surfaces for Direct3D11.

 This is preferred over the legacy AV_PIX_FMT_D3D11VA_VLD. The new D3D11
 hwaccel API and filtering support AV_PIX_FMT_D3D11 only.

 data[0] contains a ID3D11Texture2D pointer, and data[1] contains the
 texture array index of the frame as intptr_t if the ID3D11Texture2D is
 an array texture (or always 0 if it's a normal texture).

</member>
        <member name="F:AV_PIX_FMT_CUDA">
HW acceleration through CUDA. data[i] contain CUdeviceptr pointers
exactly as for system memory frames.

</member>
        <member name="F:AV_PIX_FMT_MMAL">
HW acceleration though MMAL, data[3] contains a pointer to the
MMAL_BUFFER_HEADER_T structure.

</member>
        <member name="F:AV_PIX_FMT_QSV">
HW acceleration through QSV, data[3] contains a pointer to the
mfxFrameSurface1 structure.

</member>
        <member name="F:AV_PIX_FMT_YUV420P9BE">
The following 12 formats have the disadvantage of needing 1 format for each bit depth.
Notice that each 9/10 bits sample is stored in 16 bits with extra padding.
If you want to support multiple bit depths, then using AV_PIX_FMT_YUV420P16* with the bpp stored separately is better.

</member>
        <member name="F:AV_PIX_FMT_VAAPI">
Hardware acceleration through VA-API, data[3] contains a
VASurfaceID.

</member>
        <member name="M:av_log_set_flags(System.Int32)">
Skip repeated messages, this requires the user app to use av_log() instead of
(f)printf as the 2 would otherwise interfere and lead to
"Last message repeated x times" messages below (f)printf messages with some
bad luck.
Also to receive the last, "last repeated" line if any, the user app must
call av_log(NULL, AV_LOG_QUIET, "%s", ""); at the end

 Include the log severity in messages originating from codecs.

 Results in messages such as:
 [rawvideo @ 0xDEADBEEF] [error] encode did not produce valid pts

</member>
        <member name="M:av_log_format_line2(System.Void*,System.Int32,System.SByte!System.Runtime.CompilerServices.IsSignUnspecifiedByte,System.SByte!System.Runtime.CompilerServices.IsSignUnspecifiedByte*,System.SByte!System.Runtime.CompilerServices.IsSignUnspecifiedByte*,System.Int32,System.Int32*)">
Format a line of log the same way as the default callback.
@param line          buffer to receive the formatted line;
                     may be NULL if line_size is 0
@param line_size     size of the buffer; at most line_size-1 characters will
                     be written to the buffer, plus one null terminator
@param print_prefix  used to store whether the prefix must be printed;
                     must point to a persistent integer initially set to 1
@return Returns a negative value if an error occurred, otherwise returns
        the number of characters that would have been written for a
        sufficiently large buffer, not including the terminating null
        character. If the return value is not less than line_size, it means
        that the log message was truncated to fit the buffer.

</member>
        <member name="M:av_log_format_line(System.Void*,System.Int32,System.SByte!System.Runtime.CompilerServices.IsSignUnspecifiedByte,System.SByte!System.Runtime.CompilerServices.IsSignUnspecifiedByte*,System.SByte!System.Runtime.CompilerServices.IsSignUnspecifiedByte*,System.Int32,System.Int32*)">
Format a line of log the same way as the default callback.
@param line          buffer to receive the formatted line
@param line_size     size of the buffer
@param print_prefix  used to store whether the prefix must be printed;
                     must point to a persistent integer initially set to 1

</member>
        <member name="M:av_default_item_name(System.Void*)">
 Return the context name

 @param  ctx The AVClass context

 @return The AVClass class_name

</member>
        <member name="M:av_log_default_callback(System.Void*,System.Int32,System.SByte!System.Runtime.CompilerServices.IsSignUnspecifiedByte,System.SByte!System.Runtime.CompilerServices.IsSignUnspecifiedByte*)">
 Default logging callback

 It prints the message to stderr, optionally colorizing it.

 @param avcl A pointer to an arbitrary struct of which the first field is a
        pointer to an AVClass struct.
 @param level The importance level of the message expressed using a @ref
        lavu_log_constants "Logging Constant".
 @param fmt The format string (printf-compatible) that specifies how
        subsequent arguments are converted to output.
 @param vl The arguments referenced by the format string.

</member>
        <member name="M:av_log_set_callback(=FUNC:System.Void(System.Void*,System.Int32,System.SByte!System.Runtime.CompilerServices.IsSignUnspecifiedByte,System.SByte!System.Runtime.CompilerServices.IsSignUnspecifiedByte*))">
 Set the logging callback

 @note The callback must be thread safe, even if the application does not use
       threads itself as some codecs are multithreaded.

 @see av_log_default_callback

 @param callback A logging function with a compatible signature.

</member>
        <member name="M:av_log_set_level(System.Int32)">
 Set the log level

 @see lavu_log_constants

 @param level Logging level

</member>
        <member name="M:av_log_get_level">
 Get the current log level

 @see lavu_log_constants

 @return Current log level

</member>
        <member name="M:av_vlog(System.Void*,System.Int32,System.SByte!System.Runtime.CompilerServices.IsSignUnspecifiedByte,System.SByte!System.Runtime.CompilerServices.IsSignUnspecifiedByte*)">
 Send the specified message to the log if the level is less than or equal
 to the current av_log_level. By default, all logging messages are sent to
 stderr. This behavior can be altered by setting a different logging callback
 function.
 @see av_log_set_callback

 @param avcl A pointer to an arbitrary struct of which the first field is a
        pointer to an AVClass struct.
 @param level The importance level of the message expressed using a @ref
        lavu_log_constants "Logging Constant".
 @param fmt The format string (printf-compatible) that specifies how
        subsequent arguments are converted to output.
 @param vl The arguments referenced by the format string.

</member>
        <member name="M:av_log_once(System.Void*,System.Int32,System.Int32,System.Int32*,System.SByte!System.Runtime.CompilerServices.IsSignUnspecifiedByte,BTEllipsis)">
 Send the specified message to the log once with the initial_level and then with
 the subsequent_level. By default, all logging messages are sent to
 stderr. This behavior can be altered by setting a different logging callback
 function.
 @see av_log

 @param avcl A pointer to an arbitrary struct of which the first field is a
        pointer to an AVClass struct or NULL if general log.
 @param initial_level importance level of the message expressed using a @ref
        lavu_log_constants "Logging Constant" for the first occurance.
 @param subsequent_level importance level of the message expressed using a @ref
        lavu_log_constants "Logging Constant" after the first occurance.
 @param fmt The format string (printf-compatible) that specifies how
        subsequent arguments are converted to output.
 @param state a variable to keep trak of if a message has already been printed
        this must be initialized to 0 before the first use. The same state
        must not be accessed by 2 Threads simultaneously.

</member>
        <member name="M:av_log(System.Void*,System.Int32,System.SByte!System.Runtime.CompilerServices.IsSignUnspecifiedByte,BTEllipsis)">
 @addtogroup lavu_log

 @{

 @defgroup lavu_log_constants Logging Constants

 @{

Print no output.

Something went really wrong and we will crash now.

Something went wrong and recovery is not possible.
For example, no header was found for a format which depends
on headers or an illegal combination of parameters is used.

Something went wrong and cannot losslessly be recovered.
However, not all future data is affected.

Something somehow does not look correct. This may or may not
lead to problems. An example would be the use of '-vstrict -2'.

Standard information.

Detailed information.

Stuff which is only useful for libav* developers.

Extremely verbose debugging, useful for libav* development.

@}

 * Sets additional colors for extended debugging sessions.
 * @code
   av_log(ctx, AV_LOG_DEBUG|AV_LOG_C(134), "Message in purple\n");
   @endcode
 * Requires 256color terminal support. Uses outside debugging is not
 * recommended.

 Send the specified message to the log if the level is less than or equal
 to the current av_log_level. By default, all logging messages are sent to
 stderr. This behavior can be altered by setting a different logging callback
 function.
 @see av_log_set_callback

 @param avcl A pointer to an arbitrary struct of which the first field is a
        pointer to an AVClass struct or NULL if general log.
 @param level The importance level of the message expressed using a @ref
        lavu_log_constants "Logging Constant".
 @param fmt The format string (printf-compatible) that specifies how
        subsequent arguments are converted to output.

</member>
        <member name="F:AVClass.child_next">
Return next AVOptions-enabled child or NULL

</member>
        <member name="T:AVOptionRanges">
Callback to return the supported/allowed ranges.
available since version (52.12)

</member>
        <member name="F:AVClass.parent_log_context_offset">
Offset in the structure where a pointer to the parent context for
logging is stored. For example a decoder could pass its AVCodecContext
to eval as such a parent context, which an av_log() implementation
could then leverage to display the parent context.
The offset can be NULL.

</member>
        <member name="F:AVClass.log_level_offset_offset">
Offset in the structure where log_level_offset is stored.
0 means there is no such variable

</member>
        <member name="F:AVClass.version">
LIBAVUTIL_VERSION with which this structure was created.
This is used to allow fields to be added without requiring major
version bumps everywhere.

</member>
        <member name="T:AVOption">
 a pointer to the first option specified in the class if any or NULL

 @see av_set_default_options()

</member>
        <member name="F:AVClass.item_name">
A pointer to a function which returns the name of a context
instance ctx associated with the class.

</member>
        <member name="F:AVClass.class_name">
The name of the class; usually it is the same name as the
context structure type to which the AVClass is associated.

</member>
        <member name="T:AVClass">
Describe the class of an AVClass context structure. That is an
arbitrary struct of which the first field is a pointer to an
AVClass struct (e.g. AVCodecContext, AVFormatContext etc.).


 Iterate over the AVClasses corresponding to potential AVOptions-enabled
 children.

 @param iter pointer to opaque iteration state. The caller must initialize
             *iter to NULL before the first call.
 @return AVClass for the next AVOptions-enabled child or NULL if there are
         no more such children.

 @note The difference between child_next and this is that child_next
       iterates over _already existing_ objects, while child_class_iterate
       iterates over _all possible_ children.

</member>
        <member name="M:av_add_stable(AVRational,System.Int64,AVRational,System.Int64)">
 Add a value to a timestamp.

 This function guarantees that when the same value is repeatly added that
 no accumulation of rounding errors occurs.

 @param[in] ts     Input timestamp
 @param[in] ts_tb  Input timestamp time base
 @param[in] inc    Value to be added
 @param[in] inc_tb Time base of `inc`

</member>
        <member name="M:av_rescale_delta(AVRational,System.Int64,AVRational,System.Int32,System.Int64*,AVRational)">
 Rescale a timestamp while preserving known durations.

 This function is designed to be called per audio packet to scale the input
 timestamp to a different time base. Compared to a simple av_rescale_q()
 call, this function is robust against possible inconsistent frame durations.

 The `last` parameter is a state variable that must be preserved for all
 subsequent calls for the same stream. For the first call, `*last` should be
 initialized to #AV_NOPTS_VALUE.

 @param[in]     in_tb    Input time base
 @param[in]     in_ts    Input timestamp
 @param[in]     fs_tb    Duration time base; typically this is finer-grained
                         (greater) than `in_tb` and `out_tb`
 @param[in]     duration Duration till the next call to this function (i.e.
                         duration of the current packet/frame)
 @param[in,out] last     Pointer to a timestamp expressed in terms of
                         `fs_tb`, acting as a state variable
 @param[in]     out_tb   Output timebase
 @return        Timestamp expressed in terms of `out_tb`

 @note In the context of this function, "duration" is in term of samples, not
       seconds.

</member>
        <member name="M:av_compare_ts(System.Int64,AVRational,System.Int64,AVRational)">
 Compare two timestamps each in its own time base.

 @return One of the following values:
         - -1 if `ts_a` is before `ts_b`
         - 1 if `ts_a` is after `ts_b`
         - 0 if they represent the same position

 @warning
 The result of the function is undefined if one of the timestamps is outside
 the `int64_t` range when represented in the other's timebase.

</member>
        <member name="M:av_rescale_q(System.Int64,AVRational,AVRational)">
 Rescale a 64-bit integer by 2 rational numbers.

 The operation is mathematically equivalent to `a * bq / cq`.

 This function is equivalent to av_rescale_q_rnd() with #AV_ROUND_NEAR_INF.

 @see av_rescale(), av_rescale_rnd(), av_rescale_q_rnd()

</member>
        <member name="M:av_rescale(System.Int64,System.Int64,System.Int64)">
 Rescale a 64-bit integer with rounding to nearest.

 The operation is mathematically equivalent to `a * b / c`, but writing that
 directly can overflow.

 This function is equivalent to av_rescale_rnd() with #AV_ROUND_NEAR_INF.

 @see av_rescale_rnd(), av_rescale_q(), av_rescale_q_rnd()

</member>
        <member name="M:av_gcd(System.Int64,System.Int64)">
 Compute the greatest common divisor of two integer operands.

 @param a,b Operands
 @return GCD of a and b up to sign; if a &gt;= 0 and b &gt;= 0, return value is &gt;= 0;
 if a == 0 and b == 0, returns 0.

</member>
        <member name="T:AVRounding">
 @addtogroup lavu_math

 @{

Rounding methods.


 Rescale a 64-bit integer with specified rounding.

 The operation is mathematically equivalent to `a * b / c`, but writing that
 directly can overflow, and does not support different rounding methods.
 If the result is not representable then INT64_MIN is returned.

 @see av_rescale(), av_rescale_q(), av_rescale_q_rnd()


 Rescale a 64-bit integer by 2 rational numbers with specified rounding.

 The operation is mathematically equivalent to `a * bq / cq`.

 @see av_rescale(), av_rescale_rnd(), av_rescale_q()

</member>
        <member name="F:AV_ROUND_PASS_MINMAX">
 Flag telling rescaling functions to pass `INT64_MIN`/`MAX` through
 unchanged, avoiding special cases for #AV_NOPTS_VALUE.

 Unlike other values of the enumeration AVRounding, this value is a
 bitmask that must be used in conjunction with another value of the
 enumeration through a bitwise OR, in order to set behavior for normal
 cases.

 @code{.c}
 av_rescale_rnd(3, 1, 2, AV_ROUND_UP | AV_ROUND_PASS_MINMAX);
 // Rescaling 3:
 //     Calculating 3 * 1 / 2
 //     3 / 2 is rounded up to 2
 //     =&gt; 2

 av_rescale_rnd(AV_NOPTS_VALUE, 1, 2, AV_ROUND_UP | AV_ROUND_PASS_MINMAX);
 // Rescaling AV_NOPTS_VALUE:
 //     AV_NOPTS_VALUE == INT64_MIN
 //     AV_NOPTS_VALUE is passed through
 //     =&gt; AV_NOPTS_VALUE
 @endcode

</member>
        <member name="M:av_double2int(System.Double)">
Reinterpret a double as a 64-bit integer.

</member>
        <member name="M:av_int2double(System.UInt64)">
Reinterpret a 64-bit integer as a double.

</member>
        <member name="M:av_float2int(System.Single)">
Reinterpret a float as a 32-bit integer.

</member>
        <member name="M:av_int2float(System.UInt32)">
Reinterpret a 32-bit integer as a float.

</member>
        <member name="T:av_intfloat32">
@}

@file
@addtogroup lavu_math
Mathematical utilities for working with timestamp and time base.

</member>
        <member name="M:av_gcd_q(AVRational,AVRational,System.Int32,AVRational)">
Return the best rational so that a and b are multiple of it.
If the resulting denominator is larger than max_den, return def.

</member>
        <member name="M:av_q2intfloat(AVRational)">
 Convert an AVRational to a IEEE 32-bit `float` expressed in fixed-point
 format.

 @param q Rational to be converted
 @return Equivalent floating-point value, expressed as an unsigned 32-bit
         integer.
 @note The returned value is platform-indepedant.

</member>
        <member name="M:av_find_nearest_q_idx(AVRational,AVRational)">
 Find the value in a list of rationals nearest a given reference rational.

 @param q      Reference rational
 @param q_list Array of rationals terminated by `{0, 0}`
 @return Index of the nearest value found in the array

</member>
        <member name="M:av_nearer_q(AVRational,AVRational,AVRational)">
 Find which of the two rationals is closer to another rational.

 @param q     Rational to be compared against
 @param q1,q2 Rationals to be tested
 @return One of the following values:
         - 1 if `q1` is nearer to `q` than `q2`
         - -1 if `q2` is nearer to `q` than `q1`
         - 0 if they have the same distance

</member>
        <member name="M:av_d2q(System.Double,System.Int32)">
 Convert a double precision floating point number to a rational.

 In case of infinity, the returned value is expressed as `{1, 0}` or
 `{-1, 0}` depending on the sign.

 @param d   `double` to convert
 @param max Maximum allowed numerator and denominator
 @return `d` in AVRational form
 @see av_q2d()

</member>
        <member name="M:av_inv_q(AVRational)">
Invert a rational.
@param q value
@return 1 / q

</member>
        <member name="M:av_sub_q(AVRational,AVRational)">
Subtract one rational from another.
@param b First rational
@param c Second rational
@return b-c

</member>
        <member name="M:av_add_q(AVRational,AVRational)">
Add two rationals.
@param b First rational
@param c Second rational
@return b+c

</member>
        <member name="M:av_div_q(AVRational,AVRational)">
Divide one rational by another.
@param b First rational
@param c Second rational
@return b/c

</member>
        <member name="M:av_mul_q(AVRational,AVRational)">
Multiply two rationals.
@param b First rational
@param c Second rational
@return b*c

</member>
        <member name="M:av_q2d(AVRational)">
Convert an AVRational to a `double`.
@param a AVRational to convert
@return `a` in floating-point form
@see av_d2q()

</member>
        <member name="M:av_make_q(System.Int32,System.Int32)">
 Create an AVRational.

 Useful for compilers that do not support compound literals.

 @note The return value is not reduced.
 @see av_reduce()

</member>
        <member name="M:av_make_error_string(System.SByte!System.Runtime.CompilerServices.IsSignUnspecifiedByte*,System.UInt64,System.Int32)">
 Fill the provided buffer with a string containing an error string
 corresponding to the AVERROR code errnum.

 @param errbuf         a buffer
 @param errbuf_size    size in bytes of errbuf
 @param errnum         error code to describe
 @return the buffer in input, filled with the error description
 @see av_strerror()

</member>
        <member name="M:av_strerror(System.Int32,System.SByte!System.Runtime.CompilerServices.IsSignUnspecifiedByte*,System.UInt64)">
@}
@}

@file
error code definitions

 @addtogroup lavu_error

 @{

This is semantically identical to AVERROR_BUG
it has been introduced in Libav after our AVERROR_BUG and with a modified value.

 Put a description of the AVERROR code errnum in errbuf.
 In case of failure the global variable errno is set to indicate the
 error. Even in case of failure av_strerror() will print a generic
 error message indicating the errnum provided to errbuf.

 @param errnum      error code to describe
 @param errbuf      buffer to which description is written
 @param errbuf_size the size in bytes of errbuf
 @return 0 on success, a negative value if a description for errnum
 cannot be found

</member>
        <member name="M:av_max_alloc(System.UInt64)">
 Set the maximum size that may be allocated in one block.

 The value specified with this function is effective for all libavutil's @ref
 lavu_mem_funcs "heap management functions."

 By default, the max value is defined as `INT_MAX`.

 @param max Value to be set as the new maximum size

 @warning Exercise extreme caution when using this function. Don't touch
          this if you do not understand the full consequence of doing so.

</member>
        <member name="M:av_size_mult(System.UInt64,System.UInt64,System.UInt64*)">
@}

 @defgroup lavu_mem_misc Miscellaneous Functions

 Other functions related to memory allocation.

 @{

 Multiply two `size_t` values checking for overflow.

 @param[in]  a,b Operands of multiplication
 @param[out] r   Pointer to the result of the operation
 @return 0 on success, AVERROR(EINVAL) on overflow

</member>
        <member name="M:av_dynarray2_add(System.Void**,System.Int32*,System.UInt64,System.Byte)">
 Add an element of size `elem_size` to a dynamic array.

 The array is reallocated when its number of elements reaches powers of 2.
 Therefore, the amortized cost of adding an element is constant.

 In case of success, the pointer to the array is updated in order to
 point to the new grown array, and the number pointed to by `nb_ptr`
 is incremented.
 In case of failure, the array is freed, `*tab_ptr` is set to `NULL` and
 `*nb_ptr` is set to 0.

 @param[in,out] tab_ptr   Pointer to the array to grow
 @param[in,out] nb_ptr    Pointer to the number of elements in the array
 @param[in]     elem_size Size in bytes of an element in the array
 @param[in]     elem_data Pointer to the data of the element to add. If
                          `NULL`, the space of the newly added element is
                          allocated but left uninitialized.

 @return Pointer to the data of the element to copy in the newly allocated
         space
 @see av_dynarray_add(), av_dynarray_add_nofree()

</member>
        <member name="M:av_dynarray_add_nofree(System.Void*,System.Int32*,System.Void*)">
 Add an element to a dynamic array.

 Function has the same functionality as av_dynarray_add(),
 but it doesn't free memory on fails. It returns error code
 instead and leave current buffer untouched.

 @return &gt;=0 on success, negative otherwise
 @see av_dynarray_add(), av_dynarray2_add()

</member>
        <member name="M:av_memcpy_backptr(System.Byte*,System.Int32,System.Int32)">
 Overlapping memcpy() implementation.

 @param dst  Destination buffer
 @param back Number of bytes back to start copying (i.e. the initial size of
             the overlapping window); must be &gt; 0
 @param cnt  Number of bytes to copy; must be &gt;= 0

 @note `cnt &gt; back` is valid, this will copy the bytes we just copied,
       thus creating a repeating pattern with a period length of `back`.

</member>
        <member name="M:av_memdup(System.Void,System.UInt64)">
 Duplicate a buffer with av_malloc().

 @param p    Buffer to be duplicated
 @param size Size in bytes of the buffer copied
 @return Pointer to a newly allocated buffer containing a
         copy of `p` or `NULL` if the buffer cannot be allocated

</member>
        <member name="M:av_strndup(System.SByte!System.Runtime.CompilerServices.IsSignUnspecifiedByte,System.UInt64)">
 Duplicate a substring of a string.

 @param s   String to be duplicated
 @param len Maximum length of the resulting string (not counting the
            terminating byte)
 @return Pointer to a newly-allocated string containing a
         substring of `s` or `NULL` if the string cannot be allocated

</member>
        <member name="M:av_strdup(System.SByte!System.Runtime.CompilerServices.IsSignUnspecifiedByte)">
 Duplicate a string.

 @param s String to be duplicated
 @return Pointer to a newly-allocated string containing a
         copy of `s` or `NULL` if the string cannot be allocated
 @see av_strndup()

</member>
        <member name="M:av_free(System.Void*)">
 Free a memory block which has been allocated with a function of av_malloc()
 or av_realloc() family.

 @param ptr Pointer to the memory block which should be freed.

 @note `ptr = NULL` is explicitly allowed.
 @note It is recommended that you use av_freep() instead, to prevent leaving
       behind dangling pointers.
 @see av_freep()

</member>
        <member name="M:av_fast_mallocz(System.Void*,System.UInt32*,System.UInt64)">
 Allocate and clear a buffer, reusing the given one if large enough.

 Like av_fast_malloc(), but all newly allocated space is initially cleared.
 Reused buffer is not cleared.

 `*ptr` is allowed to be `NULL`, in which case allocation always happens if
 `size_needed` is greater than 0.

 @param[in,out] ptr      Pointer to pointer to an already allocated buffer.
                         `*ptr` will be overwritten with pointer to new
                         buffer on success or `NULL` on failure
 @param[in,out] size     Pointer to the size of buffer `*ptr`. `*size` is
                         updated to the new allocated size, in particular 0
                         in case of failure.
 @param[in]     min_size Desired minimal size of buffer `*ptr`
 @see av_fast_malloc()

</member>
        <member name="M:av_reallocp_array(System.Void*,System.UInt64,System.UInt64)">
 Allocate, reallocate an array through a pointer to a pointer.

 If `*ptr` is `NULL` and `nmemb` &gt; 0, allocate a new block.

 @param[in,out] ptr   Pointer to a pointer to a memory block already
                      allocated with av_realloc(), or a pointer to `NULL`.
                      The pointer is updated on success, or freed on failure.
 @param[in]     nmemb Number of elements
 @param[in]     size  Size of the single element

 @return Zero on success, an AVERROR error code on failure

 @warning Unlike av_malloc(), the allocated memory is not guaranteed to be
          correctly aligned. *ptr must be freed after even if nmemb is zero.

</member>
        <member name="M:av_realloc_array(System.Void*,System.UInt64,System.UInt64)">
 Allocate, reallocate, or free an array.

 If `ptr` is `NULL` and `nmemb` &gt; 0, allocate a new block.

 @param ptr   Pointer to a memory block already allocated with
              av_realloc() or `NULL`
 @param nmemb Number of elements in the array
 @param size  Size of the single element of the array

 @return Pointer to a newly-reallocated block or NULL if the block
         cannot be reallocated

 @warning Unlike av_malloc(), the allocated memory is not guaranteed to be
          correctly aligned. The returned pointer must be freed after even if
          nmemb is zero.
 @see av_reallocp_array()

</member>
        <member name="M:av_realloc_f(System.Void*,System.UInt64,System.UInt64)">
 Allocate, reallocate, or free a block of memory.

 This function does the same thing as av_realloc(), except:
 - It takes two size arguments and allocates `nelem * elsize` bytes,
   after checking the result of the multiplication for integer overflow.
 - It frees the input block in case of failure, thus avoiding the memory
   leak with the classic
   @code{.c}
   buf = realloc(buf);
   if (!buf)
       return -1;
   @endcode
   pattern.

</member>
        <member name="M:av_reallocp(System.Void*,System.UInt64)">
 Allocate, reallocate, or free a block of memory through a pointer to a
 pointer.

 If `*ptr` is `NULL` and `size` &gt; 0, allocate a new block. If `size` is
 zero, free the memory block pointed to by `*ptr`. Otherwise, expand or
 shrink that block of memory according to `size`.

 @param[in,out] ptr  Pointer to a pointer to a memory block already allocated
                     with av_realloc(), or a pointer to `NULL`. The pointer
                     is updated on success, or freed on failure.
 @param[in]     size Size in bytes for the memory block to be allocated or
                     reallocated

 @return Zero on success, an AVERROR error code on failure

 @warning Unlike av_malloc(), the allocated memory is not guaranteed to be
          correctly aligned.

</member>
        <member name="M:av_realloc(System.Void*,System.UInt64)">
 Allocate, reallocate, or free a block of memory.

 If `ptr` is `NULL` and `size` &gt; 0, allocate a new block. Otherwise, expand or
 shrink that block of memory according to `size`.

 @param ptr  Pointer to a memory block already allocated with
             av_realloc() or `NULL`
 @param size Size in bytes of the memory block to be allocated or
             reallocated

 @return Pointer to a newly-reallocated block or `NULL` if the block
         cannot be reallocated

 @warning Unlike av_malloc(), the returned pointer is not guaranteed to be
          correctly aligned. The returned pointer must be freed after even
          if size is zero.
 @see av_fast_realloc()
 @see av_reallocp()

</member>
        <member name="M:av_mallocz_array(System.UInt64,System.UInt64)">
@deprecated use av_calloc()

</member>
        <member name="M:av_calloc(System.UInt64,System.UInt64)">
 Allocate a memory block for an array with av_mallocz().

 The allocated memory will have size `size * nmemb` bytes.

 @param nmemb Number of elements
 @param size  Size of the single element
 @return Pointer to the allocated block, or `NULL` if the block cannot
         be allocated

 @see av_mallocz()
 @see av_malloc_array()

</member>
        <member name="M:av_malloc_array(System.UInt64,System.UInt64)">
 Allocate a memory block for an array with av_malloc().

 The allocated memory will have size `size * nmemb` bytes.

 @param nmemb Number of element
 @param size  Size of a single element
 @return Pointer to the allocated block, or `NULL` if the block cannot
         be allocated
 @see av_malloc()

</member>
        <member name="M:av_mallocz(System.UInt64)">
 Allocate a memory block with alignment suitable for all memory accesses
 (including vectors if available on the CPU) and zero all the bytes of the
 block.

 @param size Size in bytes for the memory block to be allocated
 @return Pointer to the allocated block, or `NULL` if it cannot be allocated
 @see av_malloc()

</member>
        <member name="M:av_malloc(System.UInt64)">
 Convert a UTF-8 character (up to 4 bytes) to its 32-bit UCS-4 encoded form.

 @param val      Output value, must be an lvalue of type uint32_t.
 @param GET_BYTE Expression reading one byte from the input.
                 Evaluated up to 7 times (4 for the currently
                 assigned Unicode range).  With a memory buffer
                 input, this could be *ptr++, or if you want to make sure
                 that *ptr stops at the end of a NULL terminated string then
                 *ptr ? *ptr++ : 0
 @param ERROR    Expression to be evaluated on invalid input,
                 typically a goto statement.

 @warning ERROR should not contain a loop control statement which
 could interact with the internal while loop, and should force an
 exit from the macro code (e.g. through a goto or a return) in order
 to prevent undefined results.

 Convert a UTF-16 character (2 or 4 bytes) to its 32-bit UCS-4 encoded form.

 @param val       Output value, must be an lvalue of type uint32_t.
 @param GET_16BIT Expression returning two bytes of UTF-16 data converted
                  to native byte order.  Evaluated one or two times.
 @param ERROR     Expression to be evaluated on invalid input,
                  typically a goto statement.

@def PUT_UTF8(val, tmp, PUT_BYTE)
Convert a 32-bit Unicode character to its UTF-8 encoded form (up to 4 bytes long).
@param val is an input-only argument and should be of type uint32_t. It holds
a UCS-4 encoded Unicode character that is to be converted to UTF-8. If
val is given as a function it is executed only once.
@param tmp is a temporary variable and should be of type uint8_t. It
represents an intermediate value during conversion that is to be
output by PUT_BYTE.
@param PUT_BYTE writes the converted UTF-8 bytes to any proper destination.
It could be a function or a statement, and uses tmp as the input byte.
For example, PUT_BYTE could be "*output++ = tmp;" PUT_BYTE will be
executed up to 4 times for values in the valid UTF-8 range and up to
7 times in the general case, depending on the length of the converted
Unicode character.

@def PUT_UTF16(val, tmp, PUT_16BIT)
Convert a 32-bit Unicode character to its UTF-16 encoded form (2 or 4 bytes).
@param val is an input-only argument and should be of type uint32_t. It holds
a UCS-4 encoded Unicode character that is to be converted to UTF-16. If
val is given as a function it is executed only once.
@param tmp is a temporary variable and should be of type uint16_t. It
represents an intermediate value during conversion that is to be
output by PUT_16BIT.
@param PUT_16BIT writes the converted UTF-16 data to any proper destination
in desired endianness. It could be a function or a statement, and uses tmp
as the input byte.  For example, PUT_BYTE could be "*output++ = tmp;"
PUT_BYTE will be executed 1 or 2 times depending on input character.

@file
@ingroup lavu_mem
Memory handling functions

@file
@ingroup lavu
Libavutil version macros

 @addtogroup version_utils

 Useful to check and match library version in order to maintain
 backward compatibility.

 The FFmpeg libraries follow a versioning sheme very similar to
 Semantic Versioning (http://semver.org/)
 The difference is that the component called PATCH is called MICRO in FFmpeg
 and its value is reset to 100 instead of 0 to keep it above or equal to 100.
 Also we do not increase MICRO for every bugfix or change in git master.

 Prior to FFmpeg 3.2 point releases did not change any lib version number to
 avoid aliassing different git master checkouts.
 Starting with FFmpeg 3.2, the released library versions will occupy
 a separate MAJOR.MINOR that is not used on the master development branch.
 That is if we branch a release of master 55.10.123 we will bump to 55.11.100
 for the release and master will continue at 55.12.100 after it. Each new
 point release will then bump the MICRO improving the usefulness of the lib
 versions.

 @{

Extract version components from the full ::AV_VERSION_INT int as returned
by functions like ::avformat_version() and ::avcodec_version()

@}

 @defgroup lavu_ver Version and Build diagnostics

 Macros and function useful to check at compiletime and at runtime
 which version of libavutil is in use.

 @{

 @defgroup lavu_depr_guards Deprecation Guards
 FF_API_* defines may be placed below to indicate public API that will be
 dropped at a future version bump. The defines themselves are not part of
 the public API and may change, break or disappear at any time.

 @note, when bumping the major version it is recommended to manually
 disable each FF_API_* in its own commit instead of disabling them all
 at once through the bump. This improves the git bisect-ability of the change.

 @{

@}
@}

 @addtogroup lavu_mem
 Utilities for manipulating memory.

 FFmpeg has several applications of memory that are not required of a typical
 program. For example, the computing-heavy components like video decoding and
 encoding can be sped up significantly through the use of aligned memory.

 However, for each of FFmpeg's applications of memory, there might not be a
 recognized or standardized API for that specific use. Memory alignment, for
 instance, varies wildly depending on operating systems, architectures, and
 compilers. Hence, this component of @ref libavutil is created to make
 dealing with memory consistently possible on all platforms.

 @{


 @defgroup lavu_mem_macros Alignment Macros
 Helper macros for declaring aligned variables.
 @{

 @def DECLARE_ALIGNED(n,t,v)
 Declare a variable that is aligned in memory.

 @code{.c}
 DECLARE_ALIGNED(16, uint16_t, aligned_int) = 42;
 DECLARE_ALIGNED(32, uint8_t, aligned_array)[128];

 // The default-alignment equivalent would be
 uint16_t aligned_int = 42;
 uint8_t aligned_array[128];
 @endcode

 @param n Minimum alignment in bytes
 @param t Type of the variable (or array element)
 @param v Name of the variable

 @def DECLARE_ASM_ALIGNED(n,t,v)
 Declare an aligned variable appropriate for use in inline assembly code.

 @code{.c}
 DECLARE_ASM_ALIGNED(16, uint64_t, pw_08) = UINT64_C(0x0008000800080008);
 @endcode

 @param n Minimum alignment in bytes
 @param t Type of the variable (or array element)
 @param v Name of the variable

 @def DECLARE_ASM_CONST(n,t,v)
 Declare a static constant aligned variable appropriate for use in inline
 assembly code.

 @code{.c}
 DECLARE_ASM_CONST(16, uint64_t, pw_08) = UINT64_C(0x0008000800080008);
 @endcode

 @param n Minimum alignment in bytes
 @param t Type of the variable (or array element)
 @param v Name of the variable

@}

 @defgroup lavu_mem_attrs Function Attributes
 Function attributes applicable to memory handling functions.

 These function attributes can help compilers emit more useful warnings, or
 generate better code.
 @{

 @def av_malloc_attrib
 Function attribute denoting a malloc-like function.

 @see <a href="https://gcc.gnu.org/onlinedocs/gcc/Common-Function-Attributes.html#index-g_t_0040code_007bmalloc_007d-function-attribute-3251">Function attribute `malloc` in GCC's documentation</a>

 @def av_alloc_size(...)
 Function attribute used on a function that allocates memory, whose size is
 given by the specified parameter(s).

 @code{.c}
 void *av_malloc(size_t size) av_alloc_size(1);
 void *av_calloc(size_t nmemb, size_t size) av_alloc_size(1, 2);
 @endcode

 @param ... One or two parameter indexes, separated by a comma

 @see <a href="https://gcc.gnu.org/onlinedocs/gcc/Common-Function-Attributes.html#index-g_t_0040code_007balloc_005fsize_007d-function-attribute-3220">Function attribute `alloc_size` in GCC's documentation</a>

@}

 @defgroup lavu_mem_funcs Heap Management
 Functions responsible for allocating, freeing, and copying memory.

 All memory allocation functions have a built-in upper limit of `INT_MAX`
 bytes. This may be changed with av_max_alloc(), although exercise extreme
 caution when doing so.

 @{

 Allocate a memory block with alignment suitable for all memory accesses
 (including vectors if available on the CPU).

 @param size Size in bytes for the memory block to be allocated
 @return Pointer to the allocated block, or `NULL` if the block cannot
         be allocated
 @see av_mallocz()

</member>
        <member name="M:av_popcount64_c(System.UInt64)">
Count number of bits set to one in x
@param x value to count bits of
@return the number of bits set to one in x

</member>
        <member name="M:av_popcount_c(System.UInt32)">
Count number of bits set to one in x
@param x value to count bits of
@return the number of bits set to one in x

</member>
        <member name="M:av_ceil_log2_c(System.Int32)">
Compute ceil(log2(x)).
 * @param x value used to compute ceil(log2(x))
 * @return computed ceiling of log2(x)

</member>
        <member name="M:av_clipd_c(System.Double,System.Double,System.Double)">
Clip a double value into the amin-amax range.
If a is nan or -inf amin will be returned.
If a is +inf amax will be returned.
@param a value to clip
@param amin minimum value of the clip range
@param amax maximum value of the clip range
@return clipped value

</member>
        <member name="M:av_clipf_c(System.Single,System.Single,System.Single)">
Clip a float value into the amin-amax range.
If a is nan or -inf amin will be returned.
If a is +inf amax will be returned.
@param a value to clip
@param amin minimum value of the clip range
@param amax maximum value of the clip range
@return clipped value

</member>
        <member name="M:av_sat_sub64_c(System.Int64,System.Int64)">
 Subtract two signed 64-bit values with saturation.

 @param  a one value
 @param  b another value
 @return difference with signed saturation

</member>
        <member name="M:av_sat_add64_c(System.Int64,System.Int64)">
 Add two signed 64-bit values with saturation.

 @param  a one value
 @param  b another value
 @return sum with signed saturation

</member>
        <member name="M:av_sat_dsub32_c(System.Int32,System.Int32)">
 Subtract a doubled value from another value with saturation at both stages.

 @param  a first value
 @param  b value doubled and subtracted from a
 @return difference sat(a - sat(2*b)) with signed saturation

</member>
        <member name="M:av_sat_sub32_c(System.Int32,System.Int32)">
 Subtract two signed 32-bit values with saturation.

 @param  a one value
 @param  b another value
 @return difference with signed saturation

</member>
        <member name="M:av_sat_dadd32_c(System.Int32,System.Int32)">
 Add a doubled value to another value with saturation at both stages.

 @param  a first value
 @param  b value doubled and added to a
 @return sum sat(a + sat(2*b)) with signed saturation

</member>
        <member name="M:av_sat_add32_c(System.Int32,System.Int32)">
 Add two signed 32-bit values with saturation.

 @param  a one value
 @param  b another value
 @return sum with signed saturation

</member>
        <member name="M:av_mod_uintp2_c(System.UInt32,System.UInt32)">
Clear high bits from an unsigned integer starting with specific bit position
@param  a value to clip
@param  p bit position to clip at
@return clipped value

</member>
        <member name="M:av_clip_uintp2_c(System.Int32,System.Int32)">
Clip a signed integer to an unsigned power of two range.
@param  a value to clip
@param  p bit position to clip at
@return clipped value

</member>
        <member name="M:av_clip_intp2_c(System.Int32,System.Int32)">
Clip a signed integer into the -(2^p),(2^p-1) range.
@param  a value to clip
@param  p bit position to clip at
@return clipped value

</member>
        <member name="M:av_clipl_int32_c(System.Int64)">
Clip a signed 64-bit integer value into the -2147483648,2147483647 range.
@param a value to clip
@return clipped value

</member>
        <member name="M:av_clip_int16_c(System.Int32)">
Clip a signed integer value into the -32768,32767 range.
@param a value to clip
@return clipped value

</member>
        <member name="M:av_clip_uint16_c(System.Int32)">
Clip a signed integer value into the 0-65535 range.
@param a value to clip
@return clipped value

</member>
        <member name="M:av_clip_int8_c(System.Int32)">
Clip a signed integer value into the -128,127 range.
@param a value to clip
@return clipped value

</member>
        <member name="M:av_clip_uint8_c(System.Int32)">
Clip a signed integer value into the 0-255 range.
@param a value to clip
@return clipped value

</member>
        <member name="M:av_clip64_c(System.Int64,System.Int64,System.Int64)">
Clip a signed 64bit integer value into the amin-amax range.
@param a value to clip
@param amin minimum value of the clip range
@param amax maximum value of the clip range
@return clipped value

</member>
        <member name="M:av_clip_c(System.Int32,System.Int32,System.Int32)">
Clip a signed integer value into the amin-amax range.
@param a value to clip
@param amin minimum value of the clip range
@param amax maximum value of the clip range
@return clipped value

</member>
        <member name="T:AVPictureType">
 @defgroup lavu_const Constants
 @{

 @defgroup lavu_enc Encoding specific

 @note those definition should move to avcodec
 @{

 @}
 @defgroup lavu_time Timestamp specific

 FFmpeg internal timebase and timestamp definitions

 @{

 @brief Undefined timestamp value

 Usually reported by demuxer that work on containers that do not provide
 either pts or dts.

Internal time base represented as integer

Internal time base represented as fractional value

 @}
 @}
 @defgroup lavu_picture Image related

 AVPicture types, pixel formats and basic image planes manipulation.

 @{


 Return a single letter to describe the given picture type
 pict_type.

 @param[in] pict_type the picture type @return a single character
 representing the picture type, '?' if pict_type is unknown


Picture type of the frame.

</member>
        <member name="M:avutil_license">
Return the libavutil license.

</member>
        <member name="M:avutil_configuration">
Return the libavutil build-time configuration.

</member>
        <member name="M:av_version_info">
Return an informative version string. This usually is the actual release
version number or a git commit description. This string has no fixed format
and can change any time. It should never be parsed by code.

</member>
        <member name="M:avutil_version">
@}
@}

@file
Macro definitions for various function/variable attributes

Disable warnings about deprecated features
This is useful for sections of code kept for backward compatibility and
scheduled for removal.

Mark a variable as used and prevent the compiler from optimizing it
away.  This is useful for variables accessed only from inline
assembler without the compiler being aware.

@file
@ingroup lavu
Convenience header that includes @ref lavu "libavutil"'s core.

 @mainpage

 @section ffmpeg_intro Introduction

 This document describes the usage of the different libraries
 provided by FFmpeg.

 @li @ref libavc "libavcodec" encoding/decoding library
 @li @ref lavfi "libavfilter" graph-based frame editing library
 @li @ref libavf "libavformat" I/O and muxing/demuxing library
 @li @ref lavd "libavdevice" special devices muxing/demuxing library
 @li @ref lavu "libavutil" common utility library
 @li @ref lswr "libswresample" audio resampling, format conversion and mixing
 @li @ref lpp  "libpostproc" post processing library
 @li @ref libsws "libswscale" color conversion and scaling library

 @section ffmpeg_versioning Versioning and compatibility

 Each of the FFmpeg libraries contains a version.h header, which defines a
 major, minor and micro version number with the
 <em>LIBRARYNAME_VERSION_{MAJOR,MINOR,MICRO}</em> macros. The major version
 number is incremented with backward incompatible changes - e.g. removing
 parts of the public API, reordering public struct members, etc. The minor
 version number is incremented for backward compatible API changes or major
 new features - e.g. adding a new public function or a new decoder. The micro
 version number is incremented for smaller changes that a calling program
 might still want to check for - e.g. changing behavior in a previously
 unspecified situation.

 FFmpeg guarantees backward API and ABI compatibility for each library as long
 as its major version number is unchanged. This means that no public symbols
 will be removed or renamed. Types and names of the public struct members and
 values of public macros and enums will remain the same (unless they were
 explicitly declared as not part of the public API). Documented behavior will
 not change.

 In other words, any correct program that works with a given FFmpeg snapshot
 should work just as well without any changes with any later snapshot with the
 same major versions. This applies to both rebuilding the program against new
 FFmpeg versions or to replacing the dynamic FFmpeg libraries that a program
 links against.

 However, new public symbols may be added and new members may be appended to
 public structs whose size is not part of public ABI (most public structs in
 FFmpeg). New macros and enum values may be added. Behavior in undocumented
 situations may change slightly (and be documented). All those are accompanied
 by an entry in doc/APIchanges and incrementing either the minor or micro
 version number.

 @defgroup lavu libavutil
 Common code shared across all FFmpeg libraries.

 @note
 libavutil is designed to be modular. In most cases, in order to use the
 functions provided by one component of libavutil you must explicitly include
 the specific header containing that feature. If you are only using
 media-related components, you could simply include libavutil/avutil.h, which
 brings in most of the "core" components.

 @{

 @defgroup lavu_crypto Crypto and Hashing

 @{
 @}

 @defgroup lavu_math Mathematics
 @{

 @}

 @defgroup lavu_string String Manipulation

 @{

 @}

 @defgroup lavu_mem Memory Management

 @{

 @}

 @defgroup lavu_data Data Structures
 @{

 @}

 @defgroup lavu_video Video related

 @{

 @}

 @defgroup lavu_audio Audio related

 @{

 @}

 @defgroup lavu_error Error Codes

 @{

 @}

 @defgroup lavu_log Logging Facility

 @{

 @}

 @defgroup lavu_misc Other

 @{

 @defgroup preproc_misc Preprocessor String Macros

 @{

 @}

 @defgroup version_utils Library Version Macros

 @{

 @}

@addtogroup lavu_ver
@{

Return the LIBAVUTIL_VERSION_INT constant.

</member>
        <member name="M:AudioFilter.AlocSourceAndSync(AVFrame*)">
There are 2 mandatory filters: the source, the sink.
</member>
        <member name="M:av_buffersrc_close(AVFilterContext*,System.Int64,System.UInt32)">
 Close the buffer source after EOF.

 This is similar to passing NULL to av_buffersrc_add_frame_flags()
 except it takes the timestamp of the EOF, i.e. the timestamp of the end
 of the last frame.

</member>
        <member name="M:av_buffersrc_add_frame_flags(AVFilterContext*,AVFrame*,System.Int32)">
 Add a frame to the buffer source.

 By default, if the frame is reference-counted, this function will take
 ownership of the reference(s) and reset the frame. This can be controlled
 using the flags.

 If this function returns an error, the input frame is not touched.

 @param buffer_src  pointer to a buffer source context
 @param frame       a frame, or NULL to mark EOF
 @param flags       a combination of AV_BUFFERSRC_FLAG_*
 @return            &gt;= 0 in case of success, a negative AVERROR code
                    in case of failure

</member>
        <member name="M:av_buffersrc_add_frame(AVFilterContext*,AVFrame*)">
 Add a frame to the buffer source.

 @param ctx   an instance of the buffersrc filter
 @param frame frame to be added. If the frame is reference counted, this
 function will take ownership of the reference(s) and reset the frame.
 Otherwise the frame data will be copied. If this function returns an error,
 the input frame is not touched.

 @return 0 on success, a negative AVERROR on error.

 @note the difference between this function and av_buffersrc_write_frame() is
 that av_buffersrc_write_frame() creates a new reference to the input frame,
 while this function takes ownership of the reference passed to it.

 This function is equivalent to av_buffersrc_add_frame_flags() without the
 AV_BUFFERSRC_FLAG_KEEP_REF flag.

</member>
        <member name="M:av_buffersrc_write_frame(AVFilterContext*,AVFrame)">
 Add a frame to the buffer source.

 @param ctx   an instance of the buffersrc filter
 @param frame frame to be added. If the frame is reference counted, this
 function will make a new reference to it. Otherwise the frame data will be
 copied.

 @return 0 on success, a negative AVERROR on error

 This function is equivalent to av_buffersrc_add_frame_flags() with the
 AV_BUFFERSRC_FLAG_KEEP_REF flag.

</member>
        <member name="M:av_buffersrc_parameters_set(AVFilterContext*,AVBufferSrcParameters*)">
 Initialize the buffersrc or abuffersrc filter with the provided parameters.
 This function may be called multiple times, the later calls override the
 previous ones. Some of the parameters may also be set through AVOptions, then
 whatever method is used last takes precedence.

 @param ctx an instance of the buffersrc or abuffersrc filter
 @param param the stream parameters. The frames later passed to this filter
              must conform to those parameters. All the allocated fields in
              param remain owned by the caller, libavfilter will make internal
              copies or references when necessary.
 @return 0 on success, a negative AVERROR code on failure.

</member>
        <member name="M:av_buffersrc_parameters_alloc">
Allocate a new AVBufferSrcParameters instance. It should be freed by the
caller with av_free().

</member>
        <member name="F:AVBufferSrcParameters.ch_layout">
Audio only, the audio channel layout

</member>
        <member name="F:AVBufferSrcParameters.channel_layout">
Audio only, the audio channel layout
@deprecated use ch_layout

</member>
        <member name="F:AVBufferSrcParameters.sample_rate">
Audio only, the audio sampling rate in samples per second.

</member>
        <member name="F:AVBufferSrcParameters.hw_frames_ctx">
Video with a hwaccel pixel format only. This should be a reference to an
AVHWFramesContext instance describing the input frames.

</member>
        <member name="F:AVBufferSrcParameters.frame_rate">
Video only, the frame rate of the input video. This field must only be
set to a non-zero value if input stream has a known constant framerate
and should be left at its initial value if the framerate is variable or
unknown.

</member>
        <member name="F:AVBufferSrcParameters.sample_aspect_ratio">
Video only, the sample (pixel) aspect ratio.

</member>
        <member name="F:AVBufferSrcParameters.width">
Video only, the display dimensions of the input frames.

</member>
        <member name="F:AVBufferSrcParameters.time_base">
The timebase to be used for the timestamps on the input frames.

</member>
        <member name="F:AVBufferSrcParameters.format">
video: the pixel format, value corresponds to enum AVPixelFormat
audio: the sample format, value corresponds to enum AVSampleFormat

</member>
        <member name="T:AVBufferSrcParameters">
 This structure contains the parameters describing the frames that will be
 passed to this filter.

 It should be allocated with av_buffersrc_parameters_alloc() and freed with
 av_free(). All the allocated fields in it remain owned by the caller.

</member>
        <member name="M:av_buffersrc_get_nb_failed_requests(AVFilterContext*)">
 Get the number of failed requests.

 A failed request is when the request_frame method is called while no
 frame is present in the buffer.
 The number is reset when a frame is added.

</member>
        <member name="F:AV_BUFFERSRC_FLAG_KEEP_REF">
Keep a reference to the frame.
If the frame if reference-counted, create a new reference; otherwise
copy the frame data.

</member>
        <member name="F:AV_BUFFERSRC_FLAG_PUSH">
Immediately push the frame to the output.

</member>
        <member name="F:AV_BUFFERSRC_FLAG_NO_CHECK_FORMAT">
Do not check for format changes.

</member>
        <member name="M:av_buffersink_get_samples(AVFilterContext*,AVFrame*,System.Int32)">
 Same as av_buffersink_get_frame(), but with the ability to specify the number
 of samples read. This function is less efficient than
 av_buffersink_get_frame(), because it copies the data around.

 @param ctx pointer to a context of the abuffersink AVFilter.
 @param frame pointer to an allocated frame that will be filled with data.
              The data must be freed using av_frame_unref() / av_frame_free()
              frame will contain exactly nb_samples audio samples, except at
              the end of stream, when it can contain less than nb_samples.

 @return The return codes have the same meaning as for
         av_buffersink_get_frame().

 @warning do not mix this function with av_buffersink_get_frame(). Use only one or
 the other with a single sink, not both.

</member>
        <member name="M:av_buffersink_get_frame(AVFilterContext*,AVFrame*)">
@} 
 Get a frame with filtered data from sink and put it in frame.

 @param ctx pointer to a context of a buffersink or abuffersink AVFilter.
 @param frame pointer to an allocated frame that will be filled with data.
              The data must be freed using av_frame_unref() / av_frame_free()

 @return
         - &gt;= 0 if a frame was successfully returned.
         - AVERROR(EAGAIN) if no frames are available at this point; more
           input frames must be added to the filtergraph to get more output.
         - AVERROR_EOF if there will be no more output frames on this sink.
         - A different negative AVERROR code in other failure cases.

</member>
        <member name="M:av_buffersink_set_frame_size(AVFilterContext*,System.UInt32)">
 Set the frame size for an audio buffer sink.

 All calls to av_buffersink_get_buffer_ref will return a buffer with
 exactly the specified number of samples, or AVERROR(EAGAIN) if there is
 not enough. The last buffer at EOF will be padded with 0.

</member>
        <member name="M:av_abuffersink_params_alloc">
 Create an AVABufferSinkParams structure.

 Must be freed with av_free().

</member>
        <member name="T:AVABufferSinkParams">
Deprecated and unused struct to use for initializing an abuffersink context.

</member>
        <member name="M:av_buffersink_params_alloc">
 Create an AVBufferSinkParams structure.

 Must be freed with av_free().

</member>
        <member name="T:AVBufferSinkParams">
Tell av_buffersink_get_buffer_ref() to read video/samples buffer
reference, but not remove it from the buffer. This is useful if you
need only to read a video/samples buffer, without to fetch it.

Tell av_buffersink_get_buffer_ref() not to request a frame from its input.
If a frame is already buffered, it is read (and removed from the buffer),
but if no frame is present, return AVERROR(EAGAIN).

Deprecated and unused struct to use for initializing a buffersink context.

</member>
        <member name="M:FFmpegInteropX.implementation.FrameGrabber.ExtractNextVideoFrameAsync">
            <summary>Extracts the next consecutive video frame in the file. Returns <c>null</c> at end of stream.</summary>
        </member>
        <member name="M:FFmpegInteropX.implementation.FrameGrabber.ExtractVideoFrameAsync(System.TimeSpan)">
            <summary>Extracts a video frame at the specififed position.</summary>
            <param name="position">The position of the requested frame.</param>
            <remarks>The IAsyncOperation result supports cancellation, so long running frame requests (exactSeek=true) can be interrupted.</remarks>
        </member>
        <member name="M:FFmpegInteropX.implementation.FrameGrabber.ExtractVideoFrameAsync(System.TimeSpan,System.Boolean)">
            <summary>Extracts a video frame at the specififed position.</summary>
            <param name="position">The position of the requested frame.</param>
            <param name="exactSeek">If set to false, this will decode the closest previous key frame, which is faster but not as precise.</param>
        </member>
        <member name="M:FFmpegInteropX.implementation.FrameGrabber.ExtractVideoFrameAsync(System.TimeSpan,System.Boolean,System.Int32)">
            <summary>Extracts a video frame at the specififed position.</summary>
            <param name="position">The position of the requested frame.</param>
            <param name="exactSeek">If set to false, this will decode the closest previous key frame, which is faster but not as precise.</param>
            <param name="maxFrameSkip">If exactSeek=true, this limits the number of frames to decode after the key frame.</param>
            <remarks>The IAsyncOperation result supports cancellation, so long running frame requests (exactSeek=true) can be interrupted.</remarks>
        </member>
        <member name="M:FFmpegInteropX.implementation.FrameGrabber.ExtractNextVideoFrameAsync(Windows.Storage.Streams.IBuffer)">
            <summary>Extracts the next consecutive video frame in the file. Returns <c>null</c> at end of stream.</summary>
            <param name="targetBuffer">The target buffer which shall contain the decoded pixel data.</param>
        </member>
        <member name="M:FFmpegInteropX.implementation.FrameGrabber.ExtractVideoFrameAsync(System.TimeSpan,System.Boolean,System.Int32,Windows.Storage.Streams.IBuffer)">
            <summary>Extracts a video frame at the specififed position.</summary>
            <param name="position">The position of the requested frame.</param>
            <param name="exactSeek">If set to false, this will decode the closest previous key frame, which is faster but not as precise.</param>
            <param name="maxFrameSkip">If exactSeek=true, this limits the number of frames to decode after the key frame.</param>
            <param name="targetBuffer">The target buffer which shall contain the decoded pixel data.</param>
            <remarks>The IAsyncOperation result supports cancellation, so long running frame requests (exactSeek=true) can be interrupted.</remarks>
        </member>
        <member name="M:FFmpegInteropX.implementation.FrameGrabber.CurrentVideoStream">
            <summary>Gets the current video stream information.</summary>
        </member>
        <member name="M:FFmpegInteropX.implementation.FrameGrabber.DecodePixelHeight">
            <summary>Gets or sets the decode pixel height.</summary>
        </member>
        <member name="M:FFmpegInteropX.implementation.FrameGrabber.DecodePixelWidth">
            <summary>Gets or sets the decode pixel width.</summary>
        </member>
        <member name="M:FFmpegInteropX.implementation.FrameGrabber.Duration">
            <summary>The duration of the video stream.</summary>
        </member>
        <member name="M:FFmpegInteropX.implementation.FrameGrabber.CreateFromUriAsync(System.String)">
            <summary>Creates a new FrameGrabber from the specified uri.</summary>
        </member>
        <member name="M:FFmpegInteropX.implementation.FrameGrabber.CreateFromStreamAsync(Windows.Storage.Streams.IRandomAccessStream)">
            <summary>Creates a new FrameGrabber from the specified stream.</summary>
        </member>
        <member name="M:av_buffersink_get_frame_flags(AVFilterContext*,AVFrame*,System.Int32)">
@}

</member>
        <member name="M:avfilter_graph_request_oldest(AVFilterGraph*)">
 Request a frame on the oldest sink link.

 If the request returns AVERROR_EOF, try the next.

 Note that this function is not meant to be the sole scheduling mechanism
 of a filtergraph, only a convenience function to help drain a filtergraph
 in a balanced way under normal circumstances.

 Also note that AVERROR_EOF does not mean that frames did not arrive on
 some of the sinks during the process.
 When there are multiple sink links, in case the requested link
 returns an EOF, this may cause a filter to flush pending frames
 which are sent to another sink link, although unrequested.

 @return  the return value of ff_request_frame(),
          or AVERROR_EOF if all links returned AVERROR_EOF

</member>
        <member name="M:avfilter_graph_dump(AVFilterGraph*,System.SByte!System.Runtime.CompilerServices.IsSignUnspecifiedByte)">
 Dump a graph into a human-readable string representation.

 @param graph    the graph to dump
 @param options  formatting options; currently ignored
 @return  a string, or NULL in case of memory allocation failure;
          the string must be freed using av_free

</member>
        <member name="M:avfilter_graph_queue_command(AVFilterGraph*,System.SByte!System.Runtime.CompilerServices.IsSignUnspecifiedByte,System.SByte!System.Runtime.CompilerServices.IsSignUnspecifiedByte,System.SByte!System.Runtime.CompilerServices.IsSignUnspecifiedByte,System.Int32,System.Double)">
 Queue a command for one or more filter instances.

 @param graph  the filter graph
 @param target the filter(s) to which the command should be sent
               "all" sends to all filters
               otherwise it can be a filter or filter instance name
               which will send the command to all matching filters.
 @param cmd    the command to sent, for handling simplicity all commands must be alphanumeric only
 @param arg    the argument for the command
 @param ts     time at which the command should be sent to the filter

 @note As this executes commands after this function returns, no return code
       from the filter is provided, also AVFILTER_CMD_FLAG_ONE is not supported.

</member>
        <member name="M:avfilter_graph_send_command(AVFilterGraph*,System.SByte!System.Runtime.CompilerServices.IsSignUnspecifiedByte,System.SByte!System.Runtime.CompilerServices.IsSignUnspecifiedByte,System.SByte!System.Runtime.CompilerServices.IsSignUnspecifiedByte,System.SByte!System.Runtime.CompilerServices.IsSignUnspecifiedByte*,System.Int32,System.Int32)">
 Send a command to one or more filter instances.

 @param graph  the filter graph
 @param target the filter(s) to which the command should be sent
               "all" sends to all filters
               otherwise it can be a filter or filter instance name
               which will send the command to all matching filters.
 @param cmd    the command to send, for handling simplicity all commands must be alphanumeric only
 @param arg    the argument for the command
 @param res    a buffer with size res_size where the filter(s) can return a response.

 @returns &gt;=0 on success otherwise an error code.
              AVERROR(ENOSYS) on unsupported commands

</member>
        <member name="M:avfilter_graph_parse2(AVFilterGraph*,System.SByte!System.Runtime.CompilerServices.IsSignUnspecifiedByte,AVFilterInOut**,AVFilterInOut**)">
 Add a graph described by a string to a graph.

 @param[in]  graph   the filter graph where to link the parsed graph context
 @param[in]  filters string to be parsed
 @param[out] inputs  a linked list of all free (unlinked) inputs of the
                     parsed graph will be returned here. It is to be freed
                     by the caller using avfilter_inout_free().
 @param[out] outputs a linked list of all free (unlinked) outputs of the
                     parsed graph will be returned here. It is to be freed by the
                     caller using avfilter_inout_free().
 @return zero on success, a negative AVERROR code on error

 @note This function returns the inputs and outputs that are left
 unlinked after parsing the graph and the caller then deals with
 them.
 @note This function makes no reference whatsoever to already
 existing parts of the graph and the inputs parameter will on return
 contain inputs of the newly parsed part of the graph.  Analogously
 the outputs parameter will contain outputs of the newly created
 filters.

</member>
        <member name="M:avfilter_graph_parse_ptr(AVFilterGraph*,System.SByte!System.Runtime.CompilerServices.IsSignUnspecifiedByte,AVFilterInOut**,AVFilterInOut**,System.Void*)">
 Add a graph described by a string to a graph.

 In the graph filters description, if the input label of the first
 filter is not specified, "in" is assumed; if the output label of
 the last filter is not specified, "out" is assumed.

 @param graph   the filter graph where to link the parsed graph context
 @param filters string to be parsed
 @param inputs  pointer to a linked list to the inputs of the graph, may be NULL.
                If non-NULL, *inputs is updated to contain the list of open inputs
                after the parsing, should be freed with avfilter_inout_free().
 @param outputs pointer to a linked list to the outputs of the graph, may be NULL.
                If non-NULL, *outputs is updated to contain the list of open outputs
                after the parsing, should be freed with avfilter_inout_free().
 @return non negative on success, a negative AVERROR code on error

</member>
        <member name="M:avfilter_graph_parse(AVFilterGraph*,System.SByte!System.Runtime.CompilerServices.IsSignUnspecifiedByte,AVFilterInOut*,AVFilterInOut*,System.Void*)">
 Add a graph described by a string to a graph.

 @note The caller must provide the lists of inputs and outputs,
 which therefore must be known before calling the function.

 @note The inputs parameter describes inputs of the already existing
 part of the graph; i.e. from the point of view of the newly created
 part, they are outputs. Similarly the outputs parameter describes
 outputs of the already existing filters, which are provided as
 inputs to the parsed filters.

 @param graph   the filter graph where to link the parsed graph context
 @param filters string to be parsed
 @param inputs  linked list to the inputs of the graph
 @param outputs linked list to the outputs of the graph
 @return zero on success, a negative AVERROR code on error

</member>
        <member name="M:avfilter_inout_free(AVFilterInOut**)">
Free the supplied list of AVFilterInOut and set *inout to NULL.
If *inout is NULL, do nothing.

</member>
        <member name="M:avfilter_inout_alloc">
Allocate a single AVFilterInOut entry.
Must be freed with avfilter_inout_free().
@return allocated AVFilterInOut on success, NULL on failure.

</member>
        <member name="F:AVFilterInOut.pad_idx">
index of the filt_ctx pad to use for linking 
</member>
        <member name="F:AVFilterInOut.filter_ctx">
filter context associated to this input/output 
</member>
        <member name="F:AVFilterInOut.name">
unique name for this input/output in the list 
</member>
        <member name="T:AVFilterInOut">
 A linked-list of the inputs/outputs of the filter chain.

 This is mainly useful for avfilter_graph_parse() / avfilter_graph_parse2(),
 where it is used to communicate open (unlinked) inputs and outputs from and
 to the caller.
 This struct specifies, per each not connected pad contained in the graph, the
 filter context and the pad index required for establishing a link.


next input/input in the list, NULL if this is the last 
</member>
        <member name="M:avfilter_graph_free(AVFilterGraph**)">
Free a graph, destroy its links, and set *graph to NULL.
If *graph is NULL, do nothing.

</member>
        <member name="M:avfilter_graph_config(AVFilterGraph*,System.Void*)">
 Check validity and configure all the links and formats in the graph.

 @param graphctx the filter graph
 @param log_ctx context used for logging
 @return &gt;= 0 in case of success, a negative AVERROR code otherwise

</member>
        <member name="M:avfilter_graph_set_auto_convert(AVFilterGraph*,System.UInt32)">
 Enable or disable automatic format conversion inside the graph.

 Note that format conversion can still happen inside explicitly inserted
 scale and aresample filters.

 @param flags  any of the AVFILTER_AUTO_CONVERT_* constants

</member>
        <member name="M:avfilter_graph_create_filter(AVFilterContext**,AVFilter,System.SByte!System.Runtime.CompilerServices.IsSignUnspecifiedByte,System.SByte!System.Runtime.CompilerServices.IsSignUnspecifiedByte,System.Void*,AVFilterGraph*)">
 Create and add a filter instance into an existing graph.
 The filter instance is created from the filter filt and inited
 with the parameter args. opaque is currently ignored.

 In case of success put in *filt_ctx the pointer to the created
 filter instance, otherwise set *filt_ctx to NULL.

 @param name the instance name to give to the created filter instance
 @param graph_ctx the filter graph
 @return a negative AVERROR error code in case of failure, a non
 negative value otherwise

</member>
        <member name="M:avfilter_graph_get_filter(AVFilterGraph*,System.SByte!System.Runtime.CompilerServices.IsSignUnspecifiedByte)">
 Get a filter instance identified by instance name from graph.

 @param graph filter graph to search through.
 @param name filter instance name (should be unique in the graph).
 @return the pointer to the found filter instance or NULL if it
 cannot be found.

</member>
        <member name="M:avfilter_graph_alloc_filter(AVFilterGraph*,AVFilter,System.SByte!System.Runtime.CompilerServices.IsSignUnspecifiedByte)">
 Create a new filter instance in a filter graph.

 @param graph graph in which the new filter will be used
 @param filter the filter to create an instance of
 @param name Name to give to the new instance (will be copied to
             AVFilterContext.name). This may be used by the caller to identify
             different filters, libavfilter itself assigns no semantics to
             this parameter. May be NULL.

 @return the context of the newly created filter instance (note that it is
         also retrievable directly through AVFilterGraph.filters or with
         avfilter_graph_get_filter()) on success or NULL on failure.

</member>
        <member name="M:avfilter_graph_alloc">
 Allocate a filter graph.

 @return the allocated filter graph on success or NULL.

</member>
        <member name="F:AVFilterGraph.sink_links">
 Private fields

 The following fields are for internal use only.
 Their type, offset, number and semantic can change without notice.

</member>
        <member name="F:AVFilterGraph.execute">
 This callback may be set by the caller immediately after allocating the
 graph and before adding any filters to it, to provide a custom
 multithreading implementation.

 If set, filters with slice threading capability will call this callback
 to execute multiple jobs in parallel.

 If this field is left unset, libavfilter will use its internal
 implementation, which may or may not be multithreaded depending on the
 platform and build options.

</member>
        <member name="F:AVFilterGraph.opaque">
Opaque user data. May be set by the caller to an arbitrary value, e.g. to
be used from callbacks like @ref AVFilterGraph.execute.
Libavfilter will not touch this field in any way.

</member>
        <member name="F:AVFilterGraph.internal">
Opaque object for libavfilter internal use.

</member>
        <member name="F:AVFilterGraph.nb_threads">
Maximum number of threads used by filters in this graph. May be set by
the caller before adding any filters to the filtergraph. Zero (the
default) means that the number of threads is determined automatically.

</member>
        <member name="F:AVFilterGraph.thread_type">
 Type of multithreading allowed for filters in this graph. A combination
 of AVFILTER_THREAD_* flags.

 May be set by the caller at any point, the setting will apply to all
 filters initialized after that. The default is allowing everything.

 When a filter in this graph is initialized, this field is combined using
 bit AND with AVFilterContext.thread_type to get the final mask used for
 determining allowed threading types. I.e. a threading type needs to be
 set in both to be allowed.

</member>
        <member name="D:avfilter_execute_func">
 A function executing multiple jobs, possibly in parallel.

 @param ctx the filter context to which the jobs belong
 @param func the function to be called multiple times
 @param arg the argument to be passed to func
 @param ret a nb_jobs-sized array to be filled with return values from each
            invocation of func
 @param nb_jobs the number of jobs to execute

 @return 0 on success, a negative AVERROR on error

</member>
        <member name="D:avfilter_action_func">
 A function pointer passed to the @ref AVFilterGraph.execute callback to be
 executed multiple times, possibly in parallel.

 @param ctx the filter context the job belongs to
 @param arg an opaque parameter passed through from @ref
            AVFilterGraph.execute
 @param jobnr the index of the job being executed
 @param nb_jobs the total number of jobs

 @return 0 on success, a negative AVERROR on error

</member>
        <member name="M:avfilter_get_class">
 @return AVClass for AVFilterContext.

 @see av_opt_find().

</member>
        <member name="M:avfilter_insert_filter(AVFilterLink*,AVFilterContext*,System.UInt32,System.UInt32)">
 Insert a filter in the middle of an existing link.

 @param link the link into which the filter should be inserted
 @param filt the filter to be inserted
 @param filt_srcpad_idx the input pad on the filter to connect
 @param filt_dstpad_idx the output pad on the filter to connect
 @return     zero on success

</member>
        <member name="M:avfilter_free(AVFilterContext*)">
 Free a filter context. This will also remove the filter from its
 filtergraph's list of filters.

 @param filter the filter to free

</member>
        <member name="M:avfilter_init_dict(AVFilterContext*,AVDictionary**)">
 Initialize a filter with the supplied dictionary of options.

 @param ctx     uninitialized filter context to initialize
 @param options An AVDictionary filled with options for this filter. On
                return this parameter will be destroyed and replaced with
                a dict containing options that were not found. This dictionary
                must be freed by the caller.
                May be NULL, then this function is equivalent to
                avfilter_init_str() with the second parameter set to NULL.
 @return 0 on success, a negative AVERROR on failure

 @note This function and avfilter_init_str() do essentially the same thing,
 the difference is in manner in which the options are passed. It is up to the
 calling code to choose whichever is more preferable. The two functions also
 behave differently when some of the provided options are not declared as
 supported by the filter. In such a case, avfilter_init_str() will fail, but
 this function will leave those extra options in the options AVDictionary and
 continue as usual.

</member>
        <member name="M:avfilter_init_str(AVFilterContext*,System.SByte!System.Runtime.CompilerServices.IsSignUnspecifiedByte)">
 Initialize a filter with the supplied parameters.

 @param ctx  uninitialized filter context to initialize
 @param args Options to initialize the filter with. This must be a
             ':'-separated list of options in the 'key=value' form.
             May be NULL if the options have been set directly using the
             AVOptions API or there are no options that need to be set.
 @return 0 on success, a negative AVERROR on failure

</member>
        <member name="M:avfilter_get_by_name(System.SByte!System.Runtime.CompilerServices.IsSignUnspecifiedByte)">
 Get a filter definition matching the given name.

 @param name the filter name to find
 @return     the filter definition, if any matching one is registered.
             NULL if none found.

</member>
        <member name="M:av_filter_iterate(System.Void**)">
 Iterate over all registered filters.

 @param opaque a pointer where libavfilter will store the iteration state. Must
               point to NULL to start the iteration.

 @return the next registered filter or NULL when the iteration is
         finished

</member>
        <member name="M:avfilter_process_command(AVFilterContext*,System.SByte!System.Runtime.CompilerServices.IsSignUnspecifiedByte,System.SByte!System.Runtime.CompilerServices.IsSignUnspecifiedByte,System.SByte!System.Runtime.CompilerServices.IsSignUnspecifiedByte*,System.Int32,System.Int32)">
Make the filter instance process a command.
It is recommended to use avfilter_graph_send_command().

</member>
        <member name="M:avfilter_config_links(AVFilterContext*)">
 Negotiate the media format, dimensions, etc of all inputs to a filter.

 @param filter the filter to negotiate the properties for its inputs
 @return       zero on successful negotiation

</member>
        <member name="M:avfilter_link_free(AVFilterLink**)">
Free the link in *link, and set its pointer to NULL.

</member>
        <member name="M:avfilter_link(AVFilterContext*,System.UInt32,AVFilterContext*,System.UInt32)">
 Link two filters together.

 @param src    the source filter
 @param srcpad index of the output pad on the source filter
 @param dst    the destination filter
 @param dstpad index of the input pad on the destination filter
 @return       zero on success

</member>
        <member name="F:AVFilterLink.reserved">
Internal structure members.
The fields below this limit are internal for libavfilter's use
and must in no way be accessed by applications.

</member>
        <member name="F:AVFilterLink.hw_frames_ctx">
For hwaccel pixel formats, this should be a reference to the
AVHWFramesContext describing the frames.

</member>
        <member name="F:AVFilterLink.frame_wanted_out">
True if a frame is currently wanted on the output of this filter.
Set when ff_request_frame() is called by the output,
cleared when a frame is filtered.

</member>
        <member name="F:AVFilterLink.frame_pool">
A pointer to a FFFramePool struct.

</member>
        <member name="F:AVFilterLink.sample_count_in">
Number of past samples sent through the link.

</member>
        <member name="F:AVFilterLink.frame_count_in">
Number of past frames sent through the link.

</member>
        <member name="F:AVFilterLink.max_samples">
Maximum number of samples to filter at once. If filter_frame() is
called with more samples, it will split them.

</member>
        <member name="F:AVFilterLink.min_samples">
Minimum number of samples to filter at once. If filter_frame() is
called with fewer samples, it will accumulate them in fifo.
This field and the related ones must not be changed after filtering
has started.
If 0, all related fields are ignored.

</member>
        <member name="F:AVFilterLink.frame_rate">
 Frame rate of the stream on the link, or 1/0 if unknown or variable;
 if left to 0/0, will be automatically copied from the first input
 of the source filter if it exists.

 Sources should set it to the best estimation of the real frame rate.
 If the source frame rate is unknown or variable, set this to 1/0.
 Filters should update it if necessary depending on their function.
 Sinks can use it to set a default output frame rate.
 It is similar to the r_frame_rate field in AVStream.

</member>
        <member name="F:AVFilterLink.age_index">
Index in the age array.

</member>
        <member name="F:AVFilterLink.current_pts_us">
Current timestamp of the link, as defined by the most recent
frame(s), in AV_TIME_BASE units.

</member>
        <member name="F:AVFilterLink.current_pts">
Current timestamp of the link, as defined by the most recent
frame(s), in link time_base units.

</member>
        <member name="T:AVFilterGraph">
Graph the filter belongs to.

</member>
        <member name="F:AVFilterLink.outcfg">
Lists of supported formats / etc. supported by the output filter.

</member>
        <member name="F:AVFilterLink.incfg">
Lists of supported formats / etc. supported by the input filter.

</member>
        <member name="F:AVFilterLink.time_base">
Define the time base used by the PTS of the frames/samples
which will pass through this link.
During the configuration stage, each filter is supposed to
change only the output timebase, while the timebase of the
input link is assumed to be an unchangeable property.

</member>
        <member name="F:AVFilterLink.channel_layout">
channel layout of current buffer (see libavutil/channel_layout.h)
@deprecated use ch_layout

</member>
        <member name="T:AVFilterLink">
 A link between two filters. This contains pointers to the source and
 destination filters between which this link exists, and the indexes of
 the pads involved. In addition, this link also contains the parameters
 which have been negotiated and agreed upon between the filter, such as
 image dimensions, format, etc.

 Applications must not normally access the link structure directly.
 Use the buffersrc and buffersink API instead.
 In the future, access to the header may be reserved for filters
 implementation.

</member>
        <member name="F:AVFilterFormatsConfig.channel_layouts">
Lists of supported channel layouts, only for audio.

</member>
        <member name="F:AVFilterFormatsConfig.samplerates">
Lists of supported sample rates, only for audio.

</member>
        <member name="F:AVFilterFormatsConfig.formats">
List of supported formats (pixel or sample).

</member>
        <member name="T:AVFilterFormatsConfig">
 * Lists of formats / etc. supported by an end of a link.
 *
 * This structure is directly part of AVFilterLink, in two copies:
 * one for the source filter, one for the destination filter.

 * These lists are used for negotiating the format to actually be used,
 * which will be loaded into the format and channel_layout members of
 * AVFilterLink, when chosen.

</member>
        <member name="F:AVFilterContext.extra_hw_frames">
 Sets the number of extra hardware frames which the filter will
 allocate on its output links for use in following filters or by
 the caller.

 Some hardware filters require all frames that they will use for
 output to be defined in advance before filtering starts.  For such
 filters, any hardware frame pools used for output must therefore be
 of fixed size.  The extra frames set here are on top of any number
 that the filter needs internally in order to operate normally.

 This field must be set before the graph containing this filter is
 configured.

</member>
        <member name="F:AVFilterContext.ready">
Ready status of the filter.
A non-0 value means that the filter needs activating;
a higher value suggests a more urgent activation.

</member>
        <member name="F:AVFilterContext.hw_device_ctx">
For filters which will create hardware frames, sets the device the
filter should create them in.  All other filters will ignore this field:
in particular, a filter which consumes or processes hardware frames will
instead use the hw_frames_ctx field in AVFilterLink to carry the
hardware context information.

</member>
        <member name="F:AVFilterContext.internal">
An opaque struct for libavfilter internal use.

</member>
        <member name="F:AVFilterContext.thread_type">
 Type of multithreading being allowed/used. A combination of
 AVFILTER_THREAD_* flags.

 May be set by the caller before initializing the filter to forbid some
 or all kinds of multithreading for this filter. The default is allowing
 everything.

 When the filter is initialized, this field is combined using bit AND with
 AVFilterGraph.thread_type to get the final mask used for determining
 allowed threading types. I.e. a threading type needs to be set in both
 to be allowed.

 After the filter is initialized, libavfilter sets this field to the
 threading type that is actually used (0 for no multithreading).

</member>
        <member name="T:AVFilterContext">
An instance of a filter 
</member>
        <member name="T:AVFilterInternal">
Process multiple parts of the frame concurrently.

</member>
        <member name="M:avfilter_filter_pad_count(AVFilter,System.Int32)">
Get the number of elements in an AVFilter's inputs or outputs array.

</member>
        <member name="F:AVFilter.activate">
 Filter activation function.

 Called when any processing is needed from the filter, instead of any
 filter_frame and request_frame on pads.

 The function must examine inlinks and outlinks and perform a single
 step of processing. If there is nothing to do, the function must do
 nothing and not return an error. If more steps are or may be
 possible, it must use ff_filter_set_ready() to schedule another
 activation.

</member>
        <member name="F:AVFilter.process_command">
 Make the filter instance process a command.

 @param cmd    the command to process, for handling simplicity all commands must be alphanumeric only
 @param arg    the argument for the command
 @param res    a buffer with size res_size where the filter(s) can return a response. This must not change when the command is not supported.
 @param flags  if AVFILTER_CMD_FLAG_FAST is set and the command would be
               time consuming then a filter should treat it like an unsupported command

 @returns &gt;=0 on success otherwise an error code.
          AVERROR(ENOSYS) on unsupported commands

</member>
        <member name="T:AVSampleFormat">
 Analogous to pixels, but delimited by AV_SAMPLE_FMT_NONE
 and restricted to filters that only have AVMEDIA_TYPE_AUDIO
 inputs and outputs.

 In addition to that the generic code will mark all inputs
 and all outputs as supporting all sample rates and every
 channel count and channel layout, as long as all inputs
 and outputs use the same sample rate and channel count/layout.


Equivalent to { sample_fmt, AV_SAMPLE_FMT_NONE } as samples_list.


 @addtogroup lavu_audio
 @{

 @defgroup lavu_sampfmts Audio sample formats

 Audio sample format enumeration and related convenience functions.
 @{

 Audio sample formats

 - The data described by the sample format is always in native-endian order.
   Sample values can be expressed by native C types, hence the lack of a signed
   24-bit sample format even though it is a common raw audio data format.

 - The floating-point formats are based on full volume being in the range
   [-1.0, 1.0]. Any values outside this range are beyond full volume level.

 - The data layout as used in av_samples_fill_arrays() and elsewhere in FFmpeg
   (such as AVFrame in libavcodec) is as follows:

 @par
 For planar sample formats, each audio channel is in a separate data plane,
 and linesize is the buffer size, in bytes, for a single plane. All data
 planes must be the same size. For packed sample formats, only the first data
 plane is used, and samples for each channel are interleaved. In this case,
 linesize is the buffer size, in bytes, for the 1 plane.



Return the name of sample_fmt, or NULL if sample_fmt is not
recognized.


Return a sample format corresponding to name, or AV_SAMPLE_FMT_NONE
on error.


 * Get the packed alternative form of the given sample format.
 *
 * If the passed sample_fmt is already in packed format, the format returned is
 * the same as the input.
 *
 * @return  the packed alternative form of the given sample format or
            AV_SAMPLE_FMT_NONE on error.


 * Get the planar alternative form of the given sample format.
 *
 * If the passed sample_fmt is already in planar format, the format returned is
 * the same as the input.
 *
 * @return  the planar alternative form of the given sample format or
            AV_SAMPLE_FMT_NONE on error.


 Generate a string corresponding to the sample format with
 sample_fmt, or a header if sample_fmt is negative.

 @param buf the buffer where to write the string
 @param buf_size the size of buf
 @param sample_fmt the number of the sample format to print the
 corresponding info string, or a negative value to print the
 corresponding header.
 @return the pointer to the filled buffer or NULL if sample_fmt is
 unknown or in case of other errors


 Return number of bytes per sample.

 @param sample_fmt the sample format
 @return number of bytes per sample or zero if unknown for the given
 sample format


 Check if the sample format is planar.

 @param sample_fmt the sample format to inspect
 @return 1 if the sample format is planar, 0 if it is interleaved


 Get the required buffer size for the given audio parameters.

 @param[out] linesize calculated linesize, may be NULL
 @param nb_channels   the number of channels
 @param nb_samples    the number of samples in a single channel
 @param sample_fmt    the sample format
 @param align         buffer size alignment (0 = default, 1 = no alignment)
 @return              required buffer size, or negative error code on failure


 @}

 @defgroup lavu_sampmanip Samples manipulation

 Functions that manipulate audio samples
 @{

 Fill plane data pointers and linesize for samples with sample
 format sample_fmt.

 The audio_data array is filled with the pointers to the samples data planes:
 for planar, set the start point of each channel's data within the buffer,
 for packed, set the start point of the entire buffer only.

 The value pointed to by linesize is set to the aligned size of each
 channel's data buffer for planar layout, or to the aligned size of the
 buffer for all channels for packed layout.

 The buffer in buf must be big enough to contain all the samples
 (use av_samples_get_buffer_size() to compute its minimum size),
 otherwise the audio_data pointers will point to invalid data.

 @see enum AVSampleFormat
 The documentation for AVSampleFormat describes the data layout.

 @param[out] audio_data  array to be filled with the pointer for each channel
 @param[out] linesize    calculated linesize, may be NULL
 @param buf              the pointer to a buffer containing the samples
 @param nb_channels      the number of channels
 @param nb_samples       the number of samples in a single channel
 @param sample_fmt       the sample format
 @param align            buffer size alignment (0 = default, 1 = no alignment)
 @return                 minimum size in bytes required for the buffer on success,
                         or a negative error code on failure


 Allocate a data pointers array, samples buffer for nb_samples
 samples, and fill data pointers and linesize accordingly.

 This is the same as av_samples_alloc(), but also allocates the data
 pointers array.

 @see av_samples_alloc()


 Copy samples from src to dst.

 @param dst destination array of pointers to data planes
 @param src source array of pointers to data planes
 @param dst_offset offset in samples at which the data will be written to dst
 @param src_offset offset in samples at which the data will be read from src
 @param nb_samples number of samples to be copied
 @param nb_channels number of audio channels
 @param sample_fmt audio sample format


 Fill an audio buffer with silence.

 @param audio_data  array of pointers to data planes
 @param offset      offset in samples at which to start filling
 @param nb_samples  number of samples to fill
 @param nb_channels number of audio channels
 @param sample_fmt  audio sample format

</member>
        <member name="T:AVPixelFormat">
 A pointer to an array of admissible pixel formats delimited
 by AV_PIX_FMT_NONE. The generic code will use this list
 to indicate that this filter supports each of these pixel formats,
 provided that all inputs and outputs use the same pixel format.

 This list must never be NULL if the union is in this state.
 The type of all inputs and outputs of filters using this must
 be AVMEDIA_TYPE_VIDEO.


Equivalent to { pix_fmt, AV_PIX_FMT_NONE } as pixels_list.


 The pixel format identifying the underlying HW surface type.

 Must be a hwaccel format, i.e. the corresponding descriptor must have the
 AV_PIX_FMT_FLAG_HWACCEL flag set.

 Must be set by the user before calling av_hwframe_ctx_init().


 The pixel format identifying the actual data layout of the hardware
 frames.

 Must be set by the caller before calling av_hwframe_ctx_init().

 @note when the underlying API does not provide the exact data layout, but
 only the colorspace/bit depth, this field should be set to the fully
 planar version of that format (e.g. for 8-bit 420 YUV it should be
 AV_PIX_FMT_YUV420P, not AV_PIX_FMT_NV12 or anything else).


A list of possible values for format in the hw_frames_ctx,
terminated by AV_PIX_FMT_NONE.  This member will always be filled.


A list of possible values for sw_format in the hw_frames_ctx,
terminated by AV_PIX_FMT_NONE.  Can be NULL if this information is
not known.


 Create and initialise an AVHWFramesContext as a mapping of another existing
 AVHWFramesContext on a different device.

 av_hwframe_ctx_init() should not be called after this.

 @param derived_frame_ctx  On success, a reference to the newly created
                           AVHWFramesContext.
 @param derived_device_ctx A reference to the device to create the new
                           AVHWFramesContext on.
 @param source_frame_ctx   A reference to an existing AVHWFramesContext
                           which will be mapped to the derived context.
 @param flags  Some combination of AV_HWFRAME_MAP_* flags, defining the
               mapping parameters to apply to frames which are allocated
               in the derived device.
 @return       Zero on success, negative AVERROR code on failure.


 For decoders, a hardware pixel format which that decoder may be
 able to decode to if suitable hardware is available.

 For encoders, a pixel format which the encoder may be able to
 accept.  If set to AV_PIX_FMT_NONE, this applies to all pixel
 formats supported by the codec.


@return a pixel format descriptor for provided pixel format or NULL if
this pixel format is unknown.


@return an AVPixelFormat id described by desc, or AV_PIX_FMT_NONE if desc
is not a valid pointer to a pixel format descriptor.


 Utility function to access log2_chroma_w log2_chroma_h from
 the pixel format AVPixFmtDescriptor.

 @param[in]  pix_fmt the pixel format
 @param[out] h_shift store log2_chroma_w (horizontal/width shift)
 @param[out] v_shift store log2_chroma_h (vertical/height shift)

 @return 0 on success, AVERROR(ENOSYS) on invalid or unknown pixel format


@return number of planes in pix_fmt, a negative AVERROR if pix_fmt is not a
valid pixel format.


 Return the pixel format corresponding to name.

 If there is no pixel format with name name, then looks for a
 pixel format with the name corresponding to the native endian
 format of name.
 For example in a little-endian system, first looks for "gray16",
 then for "gray16le".

 Finally if no pixel format has been found, returns AV_PIX_FMT_NONE.


 Return the short name for a pixel format, NULL in case pix_fmt is
 unknown.

 @see av_get_pix_fmt(), av_get_pix_fmt_string()


 Print in buf the string corresponding to the pixel format with
 number pix_fmt, or a header if pix_fmt is negative.

 @param buf the buffer where to write the string
 @param buf_size the size of buf
 @param pix_fmt the number of the pixel format to print the
 corresponding info string, or a negative value to print the
 corresponding header.


 Utility function to swap the endianness of a pixel format.

 @param[in]  pix_fmt the pixel format

 @return pixel format with swapped endianness if it exists,
 otherwise AV_PIX_FMT_NONE


 Compute what kind of losses will occur when converting from one specific
 pixel format to another.
 When converting from one pixel format to another, information loss may occur.
 For example, when converting from RGB24 to GRAY, the color information will
 be lost. Similarly, other losses occur when converting from some formats to
 other formats. These losses can involve loss of chroma, but also loss of
 resolution, loss of color depth, loss due to the color space conversion, loss
 of the alpha bits or loss due to color quantization.
 av_get_fix_fmt_loss() informs you about the various types of losses
 which will occur when converting from one pixel format to another.

 @param[in] dst_pix_fmt destination pixel format
 @param[in] src_pix_fmt source pixel format
 @param[in] has_alpha Whether the source pixel format alpha channel is used.
 @return Combination of flags informing you what kind of losses will occur
 (maximum loss for an invalid dst_pix_fmt).


 Compute what kind of losses will occur when converting from one specific
 pixel format to another.
 When converting from one pixel format to another, information loss may occur.
 For example, when converting from RGB24 to GRAY, the color information will
 be lost. Similarly, other losses occur when converting from some formats to
 other formats. These losses can involve loss of chroma, but also loss of
 resolution, loss of color depth, loss due to the color space conversion, loss
 of the alpha bits or loss due to color quantization.
 av_get_fix_fmt_loss() informs you about the various types of losses
 which will occur when converting from one pixel format to another.

 @param[in] dst_pix_fmt destination pixel format
 @param[in] src_pix_fmt source pixel format
 @param[in] has_alpha Whether the source pixel format alpha channel is used.
 @return Combination of flags informing you what kind of losses will occur
 (maximum loss for an invalid dst_pix_fmt).

</member>
        <member name="F:AVFilter.uninit">
 Filter uninitialization function.

 Called only once right before the filter is freed. Should deallocate any
 memory held by the filter, release any buffer references, etc. It does
 not need to deallocate the AVFilterContext.priv memory itself.

 This callback may be called even if @ref AVFilter.init "init" was not
 called or failed, so it must be prepared to handle such a situation.

</member>
        <member name="F:AVFilter.init_dict">
 Should be set instead of @ref AVFilter.init "init" by the filters that
 want to pass a dictionary of AVOptions to nested contexts that are
 allocated during init.

 On return, the options dict should be freed and replaced with one that
 contains all the options which could not be processed by this filter (or
 with NULL if all the options were processed).

 Otherwise the semantics is the same as for @ref AVFilter.init "init".

</member>
        <member name="F:AVFilter.init">
 Filter initialization function.

 This callback will be called only once during the filter lifetime, after
 all the options have been set, but before links between filters are
 established and format negotiation is done.

 Basic filter initialization should be done here. Filters with dynamic
 inputs and/or outputs should create those inputs/outputs here based on
 provided options. No more changes to this filter's inputs/outputs can be
 done after this callback.

 This callback must not assume that the filter links exist or frame
 parameters are known.

 @ref AVFilter.uninit "uninit" is guaranteed to be called even if
 initialization fails, so this callback does not have to clean up on
 failure.

 @return 0 on success, a negative AVERROR on failure

</member>
        <member name="F:AVFilter.preinit">
 Filter pre-initialization function

 This callback will be called immediately after the filter context is
 allocated, to allow allocating and initing sub-objects.

 If this callback is not NULL, the uninit callback will be called on
 allocation failure.

 @return 0 on success,
         AVERROR code on failure (but the code will be
           dropped and treated as ENOMEM by the calling code)

</member>
        <member name="F:AVFilter.formats_state">
This field determines the state of the formats union.
It is an enum FilterFormatsState value.

</member>
        <member name="F:AVFilter.nb_outputs">
The number of entries in the list of outputs.

</member>
        <member name="F:AVFilter.nb_inputs">
The number of entries in the list of inputs.

</member>
        <member name="F:AVFilter.flags">
A combination of AVFILTER_FLAG_*

</member>
        <member name="F:AVFilter.priv_class">
 A class for the private data, used to declare filter private AVOptions.
 This field is NULL for filters that do not declare any options.

 If this field is non-NULL, the first member of the filter private data
 must be a pointer to AVClass, which will be set by libavfilter generic
 code to this class.

</member>
        <member name="F:AVFilter.outputs">
 List of static outputs.

 NULL if there are no (static) outputs. Instances of filters with
 AVFILTER_FLAG_DYNAMIC_OUTPUTS set may have more outputs than present in
 this list.

</member>
        <member name="F:AVFilter.inputs">
 List of static inputs.

 NULL if there are no (static) inputs. Instances of filters with
 AVFILTER_FLAG_DYNAMIC_INPUTS set may have more inputs than present in
 this list.

</member>
        <member name="F:AVFilter.description">
 A description of the filter. May be NULL.

 You should use the NULL_IF_CONFIG_SMALL() macro to define it.

</member>
        <member name="F:AVFilter.name">
Filter name. Must be non-NULL and unique among filters.

</member>
        <member name="T:AVFilter">
The number of the filter inputs is not determined just by AVFilter.inputs.
The filter might add additional inputs during initialization depending on the
options supplied to it.

The number of the filter outputs is not determined just by AVFilter.outputs.
The filter might add additional outputs during initialization depending on
the options supplied to it.

The filter supports multithreading by splitting frames into multiple parts
and processing them concurrently.

 The filter is a "metadata" filter - it does not modify the frame data in any
 way. It may only affect the metadata (i.e. those fields copied by
 av_frame_copy_props()).

 More precisely, this means:
 - video: the data of any frame output by the filter must be exactly equal to
   some frame that is received on one of its inputs. Furthermore, all frames
   produced on a given output must correspond to frames received on the same
   input and their order must be unchanged. Note that the filter may still
   drop or duplicate the frames.
 - audio: the data produced by the filter on any of its outputs (viewed e.g.
   as an array of interleaved samples) must be exactly equal to the data
   received by the filter on one of its inputs.

Some filters support a generic "enable" expression option that can be used
to enable or disable a filter in the timeline. Filters supporting this
option have this flag set. When the enable expression is false, the default
no-op filter_frame() function is called in place of the filter_frame()
callback defined on each input pad, thus the frame is passed unchanged to
the next filters.

Same as AVFILTER_FLAG_SUPPORT_TIMELINE_GENERIC, except that the filter will
have its filter_frame() callback(s) called as usual even when the enable
expression is false. The filter will disable filtering within the
filter_frame() callback(s) itself, for example executing code depending on
the AVFilterContext-&gt;is_disabled value.

Handy mask to test whether the filter supports or no the timeline feature
(internally or generically).

Filter definition. This defines the pads a filter contains, and all the
callback functions used to interact with the filter.

</member>
        <member name="T:AVMediaType">
 Get the type of an AVFilterPad.

 @param pads an array of AVFilterPads
 @param pad_idx index of the pad in the array; it is the caller's
                responsibility to ensure the index is valid

 @return type of the pad_idx'th pad in pads


@defgroup lavfi_buffersink_accessors Buffer sink accessors
Get the properties of the stream
@{


@}

@addtogroup lavu_media Media Type
@brief Media Type


Return a string describing the media_type enum, NULL if media_type
is unknown.


Get the type of the given codec.


General type of the encoded data.

</member>
        <member name="M:avfilter_pad_get_name(AVFilterPad,System.Int32)">
 Get the name of an AVFilterPad.

 @param pads an array of AVFilterPads
 @param pad_idx index of the pad in the array; it is the caller's
                responsibility to ensure the index is valid

 @return name of the pad_idx'th pad in pads

</member>
        <member name="M:avfilter_pad_count(AVFilterPad)">
 Get the number of elements in an AVFilter's inputs or outputs array.

 @deprecated Use avfilter_filter_pad_count() instead.

</member>
        <member name="M:avfilter_license">
Return the libavfilter license.

</member>
        <member name="M:avfilter_configuration">
Return the libavfilter build-time configuration.

</member>
        <member name="M:avfilter_version">
@file
@ingroup lavfi
Main libavfilter public API header

 @defgroup lavfi libavfilter
 Graph-based frame editing library.

 @{

@file
@ingroup lavfi
Libavfilter version macros

FF_API_* defines may be placed below to indicate public API that will be
dropped at a future version bump. The defines themselves are not part of
the public API and may change, break or disappear at any time.

@file
@ingroup lavfi
Libavfilter version macros

Return the LIBAVFILTER_VERSION_INT constant.


@file
@ingroup lavfi_buffersink
memory buffer sink API for audio and video

@file
@ingroup lavfi
Main libavfilter public API header

 @defgroup lavfi libavfilter
 Graph-based frame editing library.

 @{

@file
@ingroup lavfi
Libavfilter version macros

FF_API_* defines may be placed below to indicate public API that will be
dropped at a future version bump. The defines themselves are not part of
the public API and may change, break or disappear at any time.

@file
@ingroup lavfi
Libavfilter version macros

Return the LIBAVFILTER_VERSION_INT constant.

</member>
        <member name="M:FFmpegInteropX.implementation.VideoEffectConfiguration.SharpnessThreshold">
            <summary>Adjusts which areas are sharpened. Default value is 0, allowed range 0 to 10.</summary>
        </member>
        <member name="M:FFmpegInteropX.implementation.VideoEffectConfiguration.Sharpness">
            <summary>Adjusts the sharpness of the image. Default value is 0, allowed range 0 to 10.</summary>
        </member>
        <member name="M:FFmpegInteropX.implementation.VideoEffectConfiguration.Tint">
            <summary>Adjusts the tint of the image. Default value is 0, allowed range -1 to 1.</summary>
        </member>
        <member name="M:FFmpegInteropX.implementation.VideoEffectConfiguration.Temperature">
            <summary>Adjusts the color temperature of the image. Default value is 0, allowed range -1 to 1.</summary>
        </member>
        <member name="M:FFmpegInteropX.implementation.VideoEffectConfiguration.Saturation">
            <summary>Adjusts the saturation of the image. Default value is 0, recommended range -1 to 1.</summary>
        </member>
        <member name="M:FFmpegInteropX.implementation.VideoEffectConfiguration.Contrast">
            <summary>Adjusts the contrast of the image. Default value is 0, recommended range -1 to 1.</summary>
        </member>
        <member name="M:FFmpegInteropX.implementation.VideoEffectConfiguration.Brightness">
            <summary>Adjusts the brightness of the image. Default value is 0, recommended range -1 to 1.</summary>
        </member>
        <member name="M:av_display_matrix_flip(System.Int32*,System.Int32,System.Int32)">
 Flip the input matrix horizontally and/or vertically.

 @param matrix an allocated transformation matrix
 @param hflip whether the matrix should be flipped horizontally
 @param vflip whether the matrix should be flipped vertically

</member>
        <member name="M:av_display_rotation_set(System.Int32*,System.Double)">
 Initialize a transformation matrix describing a pure clockwise
 rotation by the specified angle (in degrees).

 @param matrix an allocated transformation matrix (will be fully overwritten
               by this function)
 @param angle rotation angle in degrees.

</member>
        <member name="M:av_display_rotation_get(System.Int32)">
@file
Display matrix

 @addtogroup lavu_video
 @{

 @defgroup lavu_video_display Display transformation matrix functions
 @{

 @addtogroup lavu_video_display
 The display transformation matrix specifies an affine transformation that
 should be applied to video frames for correct presentation. It is compatible
 with the matrices stored in the ISO/IEC 14496-12 container format.

 The data is a 3x3 matrix represented as a 9-element array:

 @code{.unparsed}
                                  | a b u |
   (a, b, u, c, d, v, x, y, w) -&gt; | c d v |
                                  | x y w |
 @endcode

 All numbers are stored in native endianness, as 16.16 fixed-point values,
 except for u, v and w, which are stored as 2.30 fixed-point values.

 The transformation maps a point (p, q) in the source (pre-transformation)
 frame to the point (p', q') in the destination (post-transformation) frame as
 follows:

 @code{.unparsed}
               | a b u |
   (p, q, 1) . | c d v | = z * (p', q', 1)
               | x y w |
 @endcode

 The transformation can also be more explicitly written in components as
 follows:

 @code{.unparsed}
   p' = (a * p + c * q + x) / z;
   q' = (b * p + d * q + y) / z;
   z  =  u * p + v * q + w
 @endcode

 Extract the rotation component of the transformation matrix.

 @param matrix the transformation matrix
 @return the angle (in degrees) by which the transformation rotates the frame
         counterclockwise. The angle will be in range [-180.0, 180.0],
         or NaN if the matrix is singular.

 @note floating point numbers are inherently inexact, so callers are
       recommended to round the return value to nearest integer before use.

</member>
        <member name="M:FFmpegInteropX.implementation.FFmpegMediaSource.GetStreamDelay(FFmpegInteropX.IStreamInfo)">
            <summary>Gets the presentation timestamp delay for the given stream. </summary>
        </member>
        <member name="M:FFmpegInteropX.implementation.FFmpegMediaSource.SetStreamDelay(FFmpegInteropX.IStreamInfo,System.TimeSpan)">
            <summary>Sets a presentation timestamp delay for the given stream. Audio, video and subtitle synchronisation can be achieved this way. A positive value will cause samples (or subtitles) to be rendered at a later time. A negative value will make rendering come sooner</summary>
        </member>
        <member name="M:FFmpegInteropX.implementation.FFmpegMediaSource.GetCurrentVideoFilters">
            <summary>Gets the current video filters</summary>
            <remarks>Returns null when no filters are applied. The string uses ffmpeg filter notation.</remarks>
        </member>
        <member name="M:FFmpegInteropX.implementation.FFmpegMediaSource.GetCurrentAudioFilters">
            <summary>Gets the current audio filters</summary>
            <remarks>Returns null when no filters are applied. The string uses ffmpeg filter notation.</remarks>
        </member>
        <member name="M:FFmpegInteropX.implementation.FFmpegMediaSource.PlaybackSession">
            <summary>Gets or sets the MediaPlaybackSession associated with this FFmpeg source. Used when FastSeek is enabled.</summary>
            <remarks>After playback has started, please assign MediaPlayer.PlaybackSession to this .</remarks>
        </member>
        <member name="M:FFmpegInteropX.implementation.FFmpegMediaSource.BufferTime">
            <summary>Gets or sets the BufferTime of the MediaStreamSource.</summary>
            <remarks>A value of 0 is recommended for local files, streaming sources should use higher values.</remarks>
        </member>
        <member name="M:FFmpegInteropX.implementation.FFmpegMediaSource.SubtitleDelay">
            <summary>The current subtitle delay used by this instance.</summary>
        </member>
        <member name="M:FFmpegInteropX.implementation.FFmpegMediaSource.PlaybackItem">
            <summary>Gets the MediaPlaybackItem that was created before by using CreateMediaPlaybackItem.</summary>
        </member>
        <member name="M:FFmpegInteropX.implementation.FFmpegMediaSource.HasThumbnail">
            <summary>Gets a boolean indication if a thumbnail is embedded in the file.</summary>
        </member>
        <member name="M:FFmpegInteropX.implementation.FFmpegMediaSource.FormatInfo">
            <summary>Gets format information.</summary>
        </member>
        <member name="M:FFmpegInteropX.implementation.FFmpegMediaSource.ChapterInfos">
            <summary>Gets chapter information.</summary>
        </member>
        <member name="M:FFmpegInteropX.implementation.FFmpegMediaSource.SubtitleStreams">
            <summary>Gets subtitle stream information.</summary>
        </member>
        <member name="M:FFmpegInteropX.implementation.FFmpegMediaSource.AudioStreams">
            <summary>Gets audio stream information.</summary>
        </member>
        <member name="M:FFmpegInteropX.implementation.FFmpegMediaSource.VideoStreams">
            <summary>Gets video stream information</summary>
        </member>
        <member name="M:FFmpegInteropX.implementation.FFmpegMediaSource.CurrentAudioStream">
            <summary>Gets the current audio stream information.</summary>
        </member>
        <member name="M:FFmpegInteropX.implementation.FFmpegMediaSource.CurrentVideoStream">
            <summary>Gets the current video stream information.</summary>
        </member>
        <member name="M:FFmpegInteropX.implementation.FFmpegMediaSource.Duration">
            <summary>Gets the duration of the stream. Returns zero, if this is streaming media.</summary>
        </member>
        <member name="M:FFmpegInteropX.implementation.FFmpegMediaSource.MetadataTags">
            <summary>Gets the metadata tags available in the file.</summary>
        </member>
        <member name="M:FFmpegInteropX.implementation.FFmpegMediaSource.Configuration">
            <summary>Gets the configuration that has been passed when creating the MSS instance.</summary>
        </member>
        <member name="M:FFmpegInteropX.implementation.FFmpegMediaSource.StartBuffering">
            <summary>Starts filling the read-ahead buffer, if enabled in the configuration.</summary>
            <remarks>Let the stream buffer fill before starting playback.</remarks>
        </member>
        <member name="M:FFmpegInteropX.implementation.FFmpegMediaSource.AddExternalSubtitleAsync(Windows.Storage.Streams.IRandomAccessStream)">
            <summary>Adds an external subtitle from a stream.</summary>
            <param name="stream">The subtitle stream.</param>
        </member>
        <member name="M:FFmpegInteropX.implementation.FFmpegMediaSource.AddExternalSubtitleAsync(Windows.Storage.Streams.IRandomAccessStream,System.String)">
            <summary>Adds an external subtitle from a stream.</summary>
            <param name="stream">The subtitle stream.</param>
            <param name="streamName">The name to use for the subtitle.</param>
        </member>
        <member name="M:FFmpegInteropX.implementation.FFmpegMediaSource.OpenWithMediaPlayerAsync(Windows.Media.Playback.MediaPlayer)">
            <summary>Creates a MediaPlaybackItem, assigns it to MediaPlayer.Source and waits for MediaOpened or MediaFailed (throws in that case).</summary>
            <remarks>This will also automatically cleanup resources, if MediaPlayer switches to a different file, or it's Source property is assigned null.</remarks>
        </member>
        <member name="M:FFmpegInteropX.implementation.FFmpegMediaSource.CreateMediaPlaybackItem(System.TimeSpan,System.TimeSpan)">
            <summary>Creates a MediaPlaybackItem for playback which starts at the specified stream offset and ends after the specified duration.</summary>
        </member>
        <member name="M:FFmpegInteropX.implementation.FFmpegMediaSource.CreateMediaPlaybackItem(System.TimeSpan)">
            <summary>Creates a MediaPlaybackItem for playback which starts at the specified stream offset.</summary>
        </member>
        <member name="M:FFmpegInteropX.implementation.FFmpegMediaSource.CreateMediaPlaybackItem">
            <summary>Creates a MediaPlaybackItem for playback.</summary>
        </member>
        <member name="M:FFmpegInteropX.implementation.FFmpegMediaSource.GetMediaStreamSource">
            <summary>Gets the MediaStreamSource. Using the MediaStreamSource will prevent subtitles from working. Please use CreateMediaPlaybackItem instead.</summary>
        </member>
        <member name="M:FFmpegInteropX.implementation.FFmpegMediaSource.ExtractThumbnail">
            <summary>Extracts an embedded thumbnail, if one is available (see HasThumbnail).</summary>
        </member>
        <member name="M:FFmpegInteropX.implementation.FFmpegMediaSource.GetFFmpegVideoFilters(FFmpegInteropX.VideoStreamInfo)">
            <summary>Gets video filters for the specified video stream.</summary>
        </member>
        <member name="M:FFmpegInteropX.implementation.FFmpegMediaSource.GetFFmpegAudioFilters(FFmpegInteropX.AudioStreamInfo)">
            <summary>Gets audio filters for the specified audio stream.</summary>
        </member>
        <member name="M:FFmpegInteropX.implementation.FFmpegMediaSource.ClearFFmpegVideoFilters(FFmpegInteropX.VideoStreamInfo)">
            <summary>Disables audio filters for the specified video stream.</summary>
        </member>
        <member name="M:FFmpegInteropX.implementation.FFmpegMediaSource.ClearFFmpegVideoFilters">
            <summary>Clears video filters.</summary>
        </member>
        <member name="M:FFmpegInteropX.implementation.FFmpegMediaSource.DisableVideoEffects">
            <summary>Disables video filters.</summary>
        </member>
        <member name="M:FFmpegInteropX.implementation.FFmpegMediaSource.ClearFFmpegAudioFilters(FFmpegInteropX.AudioStreamInfo)">
            <summary>Disables audio filters for the specified audio stream.</summary>
        </member>
        <member name="M:FFmpegInteropX.implementation.FFmpegMediaSource.ClearFFmpegAudioFilters">
            <summary>Disables audio filters.</summary>
        </member>
        <member name="M:FFmpegInteropX.implementation.FFmpegMediaSource.DisableAudioEffects">
            <summary>Disables audio filters.</summary>
        </member>
        <member name="M:FFmpegInteropX.implementation.FFmpegMediaSource.SetFFmpegVideoFilters(System.String,FFmpegInteropX.VideoStreamInfo)">
            <summary>Sets FFmpeg video filters for the video stream specified by videoStreamIndex. This replaces any filters which were already set.</summary>
            <remarks>Using FFmpeg video filters will degrade playback performance, since they run on the CPU and not on the GPU.</remarks>
        </member>
        <member name="M:FFmpegInteropX.implementation.FFmpegMediaSource.SetFFmpegVideoFilters(System.String)">
            <summary>Sets FFmpeg video filters. This replaces any filters which were already set.</summary>
            <remarks>Using FFmpeg video filters will degrade playback performance, since they run on the CPU and not on the GPU.</remarks>
        </member>
        <member name="M:FFmpegInteropX.implementation.FFmpegMediaSource.SetFFmpegAudioFilters(System.String,FFmpegInteropX.AudioStreamInfo)">
            <summary>Sets FFmpeg audio filters for audio stream specified by audioStreamIndex. This replaces any filters which were already set.</summary>
        </member>
        <member name="M:FFmpegInteropX.implementation.FFmpegMediaSource.SetFFmpegAudioFilters(System.String)">
            <summary>Sets FFmpeg audio filters. This replaces any filters which were already set.</summary>
        </member>
        <member name="M:FFmpegInteropX.implementation.FFmpegMediaSource.SetSubtitleDelay(System.TimeSpan)">
            <summary>Sets the subtitle delay for all subtitle streams. Use negative values to speed them up, positive values to delay them.</summary>
        </member>
        <member name="M:FFmpegInteropX.implementation.FFmpegMediaSource.CreateFromUriAsync(System.String)">
            <summary>Creates a FFmpegMediaSource from a Uri.</summary>
        </member>
        <member name="M:FFmpegInteropX.implementation.FFmpegMediaSource.CreateFromUriAsync(System.String,FFmpegInteropX.MediaSourceConfig)">
            <summary>Creates a FFmpegMediaSource from a Uri.</summary>
        </member>
        <member name="M:FFmpegInteropX.implementation.FFmpegMediaSource.CreateFromStreamAsync(Windows.Storage.Streams.IRandomAccessStream)">
            <summary>Creates a FFmpegMediaSource from a stream.</summary>
        </member>
        <member name="M:FFmpegInteropX.implementation.FFmpegMediaSource.CreateFromStreamAsync(Windows.Storage.Streams.IRandomAccessStream,FFmpegInteropX.MediaSourceConfig)">
            <summary>Creates a FFmpegMediaSource from a stream.</summary>
        </member>
        <member name="M:FFmpegInteropX.implementation.CodecChecker.RefreshAsync">
            <summary>This will refresh the hardware acceleration status.</summary>
            <remarks>Call this after installing a codec or after a change of the active GPU.</remarks>
        </member>
        <member name="M:FFmpegInteropX.implementation.CodecChecker.InitializeAsync">
            <summary>This will pre-initialize the hardware acceleration status.</summary>
            <remarks>This can be called on app startup, but it is not required.</remarks>
        </member>
        <member name="M:FFmpegInteropX.implementation.CodecChecker.CodecRequired(Windows.Foundation.EventHandler&lt;FFmpegInteropX.CodecRequiredEventArgs&gt;)">
            <summary>This event is raised if a codec is required to improve playback experience.</summary>
            <remarks>The event is only raised once per codec. It will be raised again after a call to RefreshAsync().</remarks>
        </member>
        <!-- Discarding badly formed XML document comment for member 'F:AVFilterContext.nb_threads'. -->
        <!-- Discarding badly formed XML document comment for member 'F:AVFilterContext.nb_threads'. -->
        <!-- Discarding badly formed XML document comment for member 'T:AVSampleFormat'. -->
        <!-- Discarding badly formed XML document comment for member 'T:AVSampleFormat'. -->
        <!-- Discarding badly formed XML document comment for member 'M:av_log2(System.UInt32)'. -->
        <!-- Discarding badly formed XML document comment for member 'M:av_fast_realloc(System.Void*,System.UInt32*,System.UInt64)'. -->
        <!-- Discarding badly formed XML document comment for member 'M:av_fast_malloc(System.Void*,System.UInt32*,System.UInt64)'. -->
        <!-- Discarding badly formed XML document comment for member 'M:av_freep(System.Void*)'. -->
        <!-- Discarding badly formed XML document comment for member 'M:av_dynarray_add(System.Void*,System.Int32*,System.Void*)'. -->
        <!-- Discarding badly formed XML document comment for member 'T:AVRational'. -->
        <!-- Discarding badly formed XML document comment for member 'M:av_cmp_q(AVRational,AVRational)'. -->
        <!-- Discarding badly formed XML document comment for member 'M:av_reduce(System.Int32*,System.Int32*,System.Int64,System.Int64,System.Int64)'. -->
        <!-- Discarding badly formed XML document comment for member 'M:av_compare_mod(System.UInt64,System.UInt64,System.UInt64)'. -->
        <!-- Discarding badly formed XML document comment for member 'F:AVClass.category'. -->
        <!-- Discarding badly formed XML document comment for member 'F:AVClass.get_category'. -->
        <!-- Discarding badly formed XML document comment for member 'T:AVPixelFormat'. -->
        <!-- Discarding badly formed XML document comment for member 'T:AVDictionaryEntry'. -->
        <!-- Discarding badly formed XML document comment for member 'M:av_dict_set(AVDictionary**,System.SByte!System.Runtime.CompilerServices.IsSignUnspecifiedByte,System.SByte!System.Runtime.CompilerServices.IsSignUnspecifiedByte,System.Int32)'. -->
        <!-- Discarding badly formed XML document comment for member 'F:AV_CHAN_NONE'. -->
        <!-- Discarding badly formed XML document comment for member 'F:AV_CHAN_AMBISONIC_BASE'. -->
        <!-- Discarding badly formed XML document comment for member 'M:av_get_channel_layout_string(System.SByte!System.Runtime.CompilerServices.IsSignUnspecifiedByte*,System.Int32,System.Int32,System.UInt64)'. -->
        <!-- Discarding badly formed XML document comment for member 'M:av_get_standard_channel_layout(System.UInt32,System.UInt64*,System.SByte!System.Runtime.CompilerServices.IsSignUnspecifiedByte*)'. -->
        <!-- Discarding badly formed XML document comment for member 'F:AVFrame.buf'. -->
        <!-- Discarding badly formed XML document comment for member 'F:AVCodec.wrapper_name'. -->
        <!-- Discarding badly formed XML document comment for member 'T:AVDiscard'. -->
        <!-- Discarding badly formed XML document comment for member 'F:AV_PKT_DATA_PARAM_CHANGE'. -->
        <!-- Discarding badly formed XML document comment for member 'T:AVPacketSideDataType'. -->
        <!-- Discarding badly formed XML document comment for member 'M:av_packet_unpack_dictionary(System.Byte,System.UInt64,AVDictionary**)'. -->
        <!-- Discarding badly formed XML document comment for member 'M:avio_seek(AVIOContext*,System.Int64,System.Int32)'. -->
        <!-- Discarding badly formed XML document comment for member 'M:avio_vprintf(AVIOContext*,System.SByte!System.Runtime.CompilerServices.IsSignUnspecifiedByte,System.SByte!System.Runtime.CompilerServices.IsSignUnspecifiedByte*)'. -->
        <!-- Discarding badly formed XML document comment for member 'M:avio_printf(AVIOContext*,System.SByte!System.Runtime.CompilerServices.IsSignUnspecifiedByte,BTEllipsis)'. -->
        <!-- Discarding badly formed XML document comment for member 'M:avio_get_str(AVIOContext*,System.Int32,System.SByte!System.Runtime.CompilerServices.IsSignUnspecifiedByte*,System.Int32)'. -->
        <!-- Discarding badly formed XML document comment for member 'M:avio_get_str16le(AVIOContext*,System.Int32,System.SByte!System.Runtime.CompilerServices.IsSignUnspecifiedByte*,System.Int32)'. -->
        <!-- Discarding badly formed XML document comment for member 'M:avio_close(AVIOContext*)'. -->
        <!-- Discarding badly formed XML document comment for member 'M:avio_closep(AVIOContext**)'. -->
        <!-- Discarding badly formed XML document comment for member 'M:avio_handshake(AVIOContext*)'. -->
    </members>
</doc>
